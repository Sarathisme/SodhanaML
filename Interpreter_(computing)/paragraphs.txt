Incomputerscience,aninterpreterisacomputerprogramthatdirectlyexecutes,i.e.performs,instructionswritteninaprogrammingorscriptinglanguage,withoutrequiringthempreviouslytohavebeencompiledintoamachinelanguageprogram.Aninterpretergenerallyusesoneofthefollowingstrategiesforprogramexecution:\nEarlyversionsofLispprogramminglanguageandDartmouthBASICwouldbeexamplesofthefirsttype.Perl,Python,MATLAB,andRubyareexamplesofthesecond,whileUCSDPascalisanexampleofthethirdtype.Sourceprogramsarecompiledaheadoftimeandstoredasmachineindependentcode,whichisthenlinkedatrun-timeandexecutedbyaninterpreterand/orcompiler(forJITsystems).Somesystems,suchasSmalltalkandcontemporaryversionsofBASICandJavamayalsocombinetwoandthree.[2]Interpretersofvarioustypeshavealsobeenconstructedformanylanguagestraditionallyassociatedwithcompilation,suchasAlgol,Fortran,CobolandC/C++.\nWhileinterpretationandcompilationarethetwomainmeansbywhichprogramminglanguagesareimplemented,theyarenotmutuallyexclusive,asmostinterpretingsystemsalsoperformsometranslationwork,justlikecompilers.Theterms"interpretedlanguage"or"compiledlanguage"signifythatthecanonicalimplementationofthatlanguageisaninterpreteroracompiler,respectively.Ahighlevellanguageisideallyanabstractionindependentofparticularimplementations.\nInterpreterswereusedasearlyas1952toeaseprogrammingwithinthelimitationsofcomputersatthetime(e.g.ashortageofprogramstoragespace,ornonativesupportforfloatingpointnumbers).Interpreterswerealsousedtotranslatebetweenlow-levelmachinelanguages,allowingcodetobewrittenformachinesthatwerestillunderconstructionandtestedoncomputersthatalreadyexisted.[3]Thefirstinterpretedhigh-levellanguagewasLisp.Lispwasfirstimplementedin1958bySteveRussellonanIBM704computer.RussellhadreadJohnMcCarthy\'spaper,andrealized(toMcCarthy\'ssurprise)thattheLispevalfunctioncouldbeimplementedinmachinecode.[4]TheresultwasaworkingLispinterpreterwhichcouldbeusedtorunLispprograms,ormoreproperly,"evaluateLispexpressions".\nProgramswritteninahighlevellanguageareeitherdirectlyexecutedbysomekindofinterpreterorconvertedintomachinecodebyacompiler(andassemblerandlinker)fortheCPUtoexecute.\nWhilecompilers(andassemblers)generallyproducemachinecodedirectlyexecutablebycomputerhardware,theycanoften(optionally)produceanintermediateformcalledobjectcode.Thisisbasicallythesamemachinespecificcodebutaugmentedwithasymboltablewithnamesandtagstomakeexecutableblocks(ormodules)identifiableandrelocatable.Compiledprogramswilltypicallyusebuildingblocks(functions)keptinalibraryofsuchobjectcodemodules.Alinkerisusedtocombine(pre-made)libraryfileswiththeobjectfile(s)oftheapplicationtoformasingleexecutablefile.Theobjectfilesthatareusedtogenerateanexecutablefilearethusoftenproducedatdifferenttimes,andsometimesevenbydifferentlanguages(capableofgeneratingthesameobjectformat).\nAsimpleinterpreterwritteninalowlevellanguage(e.g.assembly)mayhavesimilarmachinecodeblocksimplementingfunctionsofthehighlevellanguagestored,andexecutedwhenafunction\'sentryinalookuptablepointstothatcode.However,aninterpreterwritteninahighlevellanguagetypicallyusesanotherapproach,suchasgeneratingandthenwalkingaparsetree,orbygeneratingandexecutingintermediatesoftware-definedinstructions,orboth.\nThus,bothcompilersandinterpretersgenerallyturnsourcecode(textfiles)intotokens,bothmay(ormaynot)generateaparsetree,andbothmaygenerateimmediateinstructions(forastackmachine,quadruplecode,orbyothermeans).Thebasicdifferenceisthatacompilersystem,includinga(builtinorseparate)linker,generatesastand-alonemachinecodeprogram,whileaninterpretersysteminsteadperformstheactionsdescribedbythehighlevelprogram.\nAcompilercanthusmakealmostalltheconversionsfromsourcecodesemanticstothemachinelevelonceandforall(i.e.untiltheprogramhastobechanged)whileaninterpreterhastodosomeofthisconversionworkeverytimeastatementorfunctionisexecuted.However,inanefficientinterpreter,muchofthetranslationwork(includinganalysisoftypes,andsimilar)isfactoredoutanddoneonlythefirsttimeaprogram,module,function,orevenstatement,isrun,thusquiteakintohowacompilerworks.However,acompiledprogramstillrunsmuchfaster,undermostcircumstances,inpartbecausecompilersaredesignedtooptimizecode,andmaybegivenampletimeforthis.Thisisespeciallytrueforsimplerhighlevellanguageswithout(many)dynamicdatastructures,checks,ortype-checks.\nIntraditionalcompilation,theexecutableoutputofthelinkers(.exefilesor.dllfilesoralibrary,seepicture)istypicallyrelocatablewhenrununderageneraloperatingsystem,muchliketheobjectcodemodulesarebutwiththedifferencethatthisrelocationisdonedynamicallyatruntime,i.e.whentheprogramisloadedforexecution.Ontheotherhand,compiledandlinkedprogramsforsmallembeddedsystemsaretypicallystaticallyallocated,oftenhardcodedinaNORflashmemory,asthereisoftennosecondarystorageandnooperatingsysteminthissense.\nHistorically,mostinterpreter-systemshavehadaself-containededitorbuiltin.Thisisbecomingmorecommonalsoforcompilers(thenoftencalledanIDE),althoughsomeprogrammersprefertouseaneditoroftheirchoiceandrunthecompiler,linkerandothertoolsmanually.Historically,compilerspredateinterpretersbecausehardwareatthattimecouldnotsupportboththeinterpreterandinterpretedcodeandthetypicalbatchenvironmentofthetimelimitedtheadvantagesofinterpretation.[5]\nDuringthesoftwaredevelopmentcycle,programmersmakefrequentchangestosourcecode.Whenusingacompiler,eachtimeachangeismadetothesourcecode,theymustwaitforthecompilertotranslatethealteredsourcefilesandlinkallofthebinarycodefilestogetherbeforetheprogramcanbeexecuted.Thelargertheprogram,thelongerthewait.Bycontrast,aprogrammerusinganinterpreterdoesalotlesswaiting,astheinterpreterusuallyjustneedstotranslatethecodebeingworkedontoanintermediaterepresentation(ornottranslateitatall),thusrequiringmuchlesstimebeforethechangescanbetested.Effectsareevidentuponsavingthesourcecodeandreloadingtheprogram.Compiledcodeisgenerallylessreadilydebuggedasediting,compiling,andlinkingaresequentialprocessesthathavetobeconductedinthepropersequencewithapropersetofcommands.Forthisreason,manycompilersalsohaveanexecutiveaid,knownasaMakefileandprogram.TheMakefilelistscompilerandlinkercommandlinesandprogramsourcecodefiles,butmighttakeasimplecommandlinemenuinput(e.g."Make3")whichselectsthethirdgroup(set)ofinstructionsthenissuesthecommandstothecompiler,andlinkerfeedingthespecifiedsourcecodefiles.\nAcompilerconvertssourcecodeintobinaryinstructionforaspecificprocessor\'sarchitecture,thusmakingitlessportable.Thisconversionismadejustonce,onthedeveloper\'senvironment,andafterthatthesamebinarycanbedistributedtotheuser\'smachineswhereitcanbeexecutedwithoutfurthertranslation.Acrosscompilercangeneratebinarycodefortheusermachineevenifithasadifferentprocessorthanthemachinewherethecodeiscompiled.\nAninterpretedprogramcanbedistributedassourcecode.Itneedstobetranslatedineachfinalmachine,whichtakesmoretimebutmakestheprogramdistributionindependentofthemachine\'sarchitecture.However,theportabilityofinterpretedsourcecodeisdependentonthetargetmachineactuallyhavingasuitableinterpreter.Iftheinterpreterneedstobesuppliedalongwiththesource,theoverallinstallationprocessismorecomplexthandeliveryofamonolithicexecutablesincetheinterpreteritselfispartofwhatneedbeinstalled.\nThefactthatinterpretedcodecaneasilybereadandcopiedbyhumanscanbeofconcernfromthepointofviewofcopyright.However,varioussystemsofencryptionandobfuscationexist.Deliveryofintermediatecode,suchasbytecode,hasasimilareffecttoobfuscation,butbytecodecouldbedecodedwithadecompilerordisassembler.[citationneeded]\nThemaindisadvantageofinterpretersisthataninterpretedprogramtypicallyrunsslowerthanifithadbeencompiled.Thedifferenceinspeedscouldbetinyorgreat;oftenanorderofmagnitudeandsometimesmore.Itgenerallytakeslongertorunaprogramunderaninterpreterthantorunthecompiledcodebutitcantakelesstimetointerpretitthanthetotaltimerequiredtocompileandrunit.Thisisespeciallyimportantwhenprototypingandtestingcodewhenanedit-interpret-debugcyclecanoftenbemuchshorterthananedit-compile-run-debugcycle.[citationneeded]\nInterpretingcodeisslowerthanrunningthecompiledcodebecausetheinterpretermustanalyzeeachstatementintheprogrameachtimeitisexecutedandthenperformthedesiredaction,whereasthecompiledcodejustperformstheactionwithinafixedcontextdeterminedbythecompilation.Thisrun-timeanalysisisknownas"interpretiveoverhead".Accesstovariablesisalsoslowerinaninterpreterbecausethemappingofidentifierstostoragelocationsmustbedonerepeatedlyatrun-timeratherthanatcompiletime.[citationneeded]\nTherearevariouscompromisesbetweenthedevelopmentspeedwhenusinganinterpreterandtheexecutionspeedwhenusingacompiler.Somesystems(suchassomeLisps)allowinterpretedandcompiledcodetocalleachotherandtosharevariables.Thismeansthatoncearoutinehasbeentestedanddebuggedundertheinterpreteritcanbecompiledandthusbenefitfromfasterexecutionwhileotherroutinesarebeingdeveloped.[citationneeded]Manyinterpretersdonotexecutethesourcecodeasitstandsbutconvertitintosomemorecompactinternalform.ManyBASICinterpretersreplacekeywordswithsinglebytetokenswhichcanbeusedtofindtheinstructioninajumptable.Afewinterpreters,suchasthePBASICinterpreter,achieveevenhigherlevelsofprogramcompactionbyusingabit-orientedratherthanabyte-orientedprogrammemorystructure,wherecommandstokensoccupyperhaps5bits,nominally"16-bit"constantsarestoredinavariable-lengthcoderequiring3,6,10,or18bits,andaddressoperandsincludea"bitoffset".ManyBASICinterpreterscanstoreandreadbacktheirowntokenizedinternalrepresentation.\nAninterpretermightwellusethesamelexicalanalyzerandparserasthecompilerandtheninterprettheresultingabstractsyntaxtree.\nExampledatatypedefinitionsforthelatter,andatoyinterpreterforsyntaxtreesobtainedfromCexpressionsareshowninthebox.\nInterpretationcannotbeusedasthesolemethodofexecution:eventhoughaninterpretercanitselfbeinterpretedandsoon,adirectlyexecutedprogramisneededsomewhereatthebottomofthestackbecausethecodebeinginterpretedisnot,bydefinition,thesameasthemachinecodethattheCPUcanexecute.[6][7]\nThereisaspectrumofpossibilitiesbetweeninterpretingandcompiling,dependingontheamountofanalysisperformedbeforetheprogramisexecuted.Forexample,EmacsLispiscompiledtobytecode,whichisahighlycompressedandoptimizedrepresentationoftheLispsource,butisnotmachinecode(andthereforenottiedtoanyparticularhardware).This"compiled"codeistheninterpretedbyabytecodeinterpreter(itselfwritteninC).Thecompiledcodeinthiscaseismachinecodeforavirtualmachine,whichisimplementednotinhardware,butinthebytecodeinterpreter.Suchcompilinginterpretersaresometimesalsocalledcompreters.[8][9]Inabytecodeinterpretereachinstructionstartswithabyte,andthereforebytecodeinterpretershaveupto256instructions,althoughnotallmaybeused.Somebytecodesmaytakemultiplebytes,andmaybearbitrarilycomplicated.\nControltables-thatdonotnecessarilyeverneedtopassthroughacompilingphase-dictateappropriatealgorithmiccontrolflowviacustomizedinterpretersinsimilarfashiontobytecodeinterpreters.\nThreadedcodeinterpretersaresimilartobytecodeinterpretersbutinsteadofbytestheyusepointers.Each"instruction"isawordthatpointstoafunctionoraninstructionsequence,possiblyfollowedbyaparameter.Thethreadedcodeinterpretereitherloopsfetchinginstructionsandcallingthefunctionstheypointto,orfetchesthefirstinstructionandjumpstoit,andeveryinstructionsequenceendswithafetchandjumptothenextinstruction.Unlikebytecodethereisnoeffectivelimitonthenumberofdifferentinstructionsotherthanavailablememoryandaddressspace.TheclassicexampleofthreadedcodeistheForthcodeusedinOpenFirmwaresystems:thesourcelanguageiscompiledinto"Fcode"(abytecode),whichistheninterpretedbyavirtualmachine.[citationneeded]\nInthespectrumbetweeninterpretingandcompiling,anotherapproachistotransformthesourcecodeintoanoptimizedabstractsyntaxtree(AST),thenexecutetheprogramfollowingthistreestructure,oruseittogeneratenativecodejust-in-time.[10]Inthisapproach,eachsentenceneedstobeparsedjustonce.Asanadvantageoverbytecode,theASTkeepstheglobalprogramstructureandrelationsbetweenstatements(whichislostinabytecoderepresentation),andwhencompressedprovidesamorecompactrepresentation.[11]Thus,usingASThasbeenproposedasabetterintermediateformatforjust-in-timecompilersthanbytecode.Also,itallowsthesystemtoperformbetteranalysisduringruntime.\nHowever,forinterpreters,anASTcausesmoreoverheadthanabytecodeinterpreter,becauseofnodesrelatedtosyntaxperformingnousefulwork,ofalesssequentialrepresentation(requiringtraversalofmorepointers)andofoverheadvisitingthetree.[12]\nFurtherblurringthedistinctionbetweeninterpreters,bytecodeinterpretersandcompilationisjust-in-timecompilation(JIT),atechniqueinwhichtheintermediaterepresentationiscompiledtonativemachinecodeatruntime.Thisconferstheefficiencyofrunningnativecode,atthecostofstartuptimeandincreasedmemoryusewhenthebytecodeorASTisfirstcompiled.Adaptiveoptimizationisacomplementarytechniqueinwhichtheinterpreterprofilestherunningprogramandcompilesitsmostfrequentlyexecutedpartsintonativecode.Bothtechniquesareafewdecadesold,appearinginlanguagessuchasSmalltalkinthe1980s.[13]\nJust-in-timecompilationhasgainedmainstreamattentionamongstlanguageimplementersinrecentyears,withJava,the.NETFramework,mostmodernJavaScriptimplementations,andMatlabnowincludingJITs.[citationneeded]\nAself-interpreterisaprogramminglanguageinterpreterwritteninaprogramminglanguagewhichcaninterpretitself;anexampleisaBASICinterpreterwritteninBASIC.Self-interpretersarerelatedtoself-hostingcompilers.\nIfnocompilerexistsforthelanguagetobeinterpreted,creatingaself-interpreterrequirestheimplementationofthelanguageinahostlanguage(whichmaybeanotherprogramminglanguageorassembler).Byhavingafirstinterpretersuchasthis,thesystemisbootstrappedandnewversionsoftheinterpretercanbedevelopedinthelanguageitself.ItwasinthiswaythatDonaldKnuthdevelopedtheTANGLEinterpreterforthelanguageWEBoftheindustrialstandardTeXtypesettingsystem.\nDefiningacomputerlanguageisusuallydoneinrelationtoanabstractmachine(so-calledoperationalsemantics)orasamathematicalfunction(denotationalsemantics).Alanguagemayalsobedefinedbyaninterpreterinwhichthesemanticsofthehostlanguageisgiven.Thedefinitionofalanguagebyaself-interpreterisnotwell-founded(itcannotdefinealanguage),butaself-interpretertellsareaderabouttheexpressivenessandeleganceofalanguage.Italsoenablestheinterpretertointerpretitssourcecode,thefirststeptowardsreflectiveinterpreting.\nAnimportantdesigndimensionintheimplementationofaself-interpreteriswhetherafeatureoftheinterpretedlanguageisimplementedwiththesamefeatureintheinterpreter\'shostlanguage.AnexampleiswhetheraclosureinaLisp-likelanguageisimplementedusingclosuresintheinterpreterlanguageorimplemented"manually"withadatastructureexplicitlystoringtheenvironment.Themorefeaturesimplementedbythesamefeatureinthehostlanguage,thelesscontroltheprogrammeroftheinterpreterhas;adifferentbehaviorfordealingwithnumberoverflowscannotberealizedifthearithmeticoperationsaredelegatedtocorrespondingoperationsinthehostlanguage.\nSomelanguageshaveanelegantself-interpreter,suchasLisporProlog.[14]Muchresearchonself-interpreters(particularlyreflectiveinterpreters)hasbeenconductedintheSchemeprogramminglanguage,adialectofLisp.Ingeneral,however,anyTuring-completelanguageallowswritingofitsowninterpreter.Lispissuchalanguage,becauseLispprogramsarelistsofsymbolsandotherlists.XSLTissuchalanguage,becauseXSLTprogramsarewritteninXML.Asub-domainofmeta-programmingisthewritingofdomain-specificlanguages(DSLs).\nCliveGiffordintroduced[citationneeded]ameasurequalityofself-interpreter(theeigenratio),thelimitoftheratiobetweencomputertimespentrunningastackofNself-interpretersandtimespenttorunastackofN\xe2\x88\x921self-interpretersasNgoestoinfinity.Thisvaluedoesnotdependontheprogrambeingrun.\nThebookStructureandInterpretationofComputerProgramspresentsexamplesofmeta-circularinterpretationforSchemeanditsdialects.Otherexamplesoflanguageswithaself-interpreterareForthandPascal.\nMicrocodeisaverycommonlyusedtechnique"thatimposesaninterpreterbetweenthehardwareandthearchitecturallevelofacomputer".[15]Assuch,themicrocodeisalayerofhardware-levelinstructionsthatimplementhigher-levelmachinecodeinstructionsorinternalstatemachinesequencinginmanydigitalprocessingelements.Microcodeisusedingeneral-purposecentralprocessingunits,aswellasinmorespecializedprocessorssuchasmicrocontrollers,digitalsignalprocessors,channelcontrollers,diskcontrollers,networkinterfacecontrollers,networkprocessors,graphicsprocessingunits,andinotherhardware.\nMicrocodetypicallyresidesinspecialhigh-speedmemoryandtranslatesmachineinstructions,statemachinedataorotherinputintosequencesofdetailedcircuit-leveloperations.Itseparatesthemachineinstructionsfromtheunderlyingelectronicssothatinstructionscanbedesignedandalteredmorefreely.Italsofacilitatesthebuildingofcomplexmulti-stepinstructions,whilereducingthecomplexityofcomputercircuits.Writingmicrocodeisoftencalledmicroprogrammingandthemicrocodeinaparticularprocessorimplementationissometimescalledamicroprogram.\nMoreextensivemicrocodingallowssmallandsimplemicroarchitecturestoemulatemorepowerfularchitectureswithwiderwordlength,moreexecutionunitsandsoon,whichisarelativelysimplewaytoachievesoftwarecompatibilitybetweendifferentproductsinaprocessorfamily.\nThisarticleisbasedonmaterialtakenfromtheFreeOn-lineDictionaryofComputingpriorto1November2008andincorporatedunderthe"relicensing"termsoftheGFDL,version1.3orlater.\n