[<p><b>Automated planning and scheduling</b>, sometimes denoted as simply <b>AI Planning</b>,<sup class="reference" id="cite_ref-1"><a href="#cite_note-1">[1]</a></sup> is a branch of <a href="/wiki/Artificial_intelligence" title="Artificial intelligence">artificial intelligence</a> that concerns the realization of <a href="/wiki/Strategy" title="Strategy">strategies</a> or action sequences, typically for execution by <a href="/wiki/Intelligent_agent" title="Intelligent agent">intelligent agents</a>, <a href="/wiki/Autonomous_robot" title="Autonomous robot">autonomous robots</a> and <a href="/wiki/Unmanned_vehicle" title="Unmanned vehicle">unmanned vehicles</a>. Unlike classical <a href="/wiki/Control_system" title="Control system">control</a> and <a href="/wiki/Statistical_classification" title="Statistical classification">classification</a> problems, the solutions are complex and must be discovered and optimized in multidimensional space. Planning is also related to <a href="/wiki/Decision_theory" title="Decision theory">decision theory</a>.\n</p>, <p>In known environments with available models, planning can be done offline. Solutions can be found and evaluated prior to execution. In dynamically unknown environments, the <a href="/wiki/Strategy" title="Strategy">strategy</a> often needs to be revised online. Models and policies must be adapted. Solutions usually resort to iterative <a href="/wiki/Trial_and_error" title="Trial and error">trial and error</a> processes commonly seen in <a href="/wiki/Artificial_intelligence" title="Artificial intelligence">artificial intelligence</a>. These include <a href="/wiki/Dynamic_programming" title="Dynamic programming">dynamic programming</a>, <a href="/wiki/Reinforcement_learning" title="Reinforcement learning">reinforcement learning</a> and <a href="/wiki/Combinatorial_optimization" title="Combinatorial optimization">combinatorial optimization</a>. Languages used to describe planning and scheduling are often called <a href="/wiki/Action_language" title="Action language">action languages</a>.\n</p>, <p>Given a description of the possible initial states of the world, a description of the desired goals, and a description of a set of possible actions, the planning problem is to synthesise a plan that is guaranteed (when applied to any of the initial states) to generate a state which contains the desired goals (such a state is called a goal state).\n</p>, <p>The difficulty of planning is dependent on the simplifying assumptions employed. Several classes of planning problems can be identified depending on the properties the problems have in several dimensions.\n</p>, <p>The simplest possible planning problem, known as the Classical Planning Problem, is determined by:\n</p>, <p>Since the initial state is known unambiguously, and all actions are deterministic, the state of the world after any sequence of actions can be accurately predicted, and the question of observability is irrelevant for classical planning.\n</p>, <p>Further, plans can be defined as sequences of actions, because it is always known in advance which actions will be needed.\n</p>, <p>With nondeterministic actions or other events outside the control of the agent, the possible executions form a tree, and plans have to determine the appropriate actions for every node of the tree.\n</p>, <p>Discrete-time <a href="/wiki/Markov_decision_process" title="Markov decision process">Markov decision processes</a> (MDP) are planning problems with:\n</p>, <p>When full observability is replaced by partial observability, planning corresponds to <a href="/wiki/Partially_observable_Markov_decision_process" title="Partially observable Markov decision process">partially observable Markov decision process</a> (POMDP).\n</p>, <p>If there are more than one agent, we have <a href="/wiki/Multi-agent_planning" title="Multi-agent planning">multi-agent planning</a>, which is closely related to <a href="/wiki/Game_theory" title="Game theory">game theory</a>.\n</p>, <p>In AI Planning, planners typically input a domain model (a description of a set of possible actions which model the domain) as well as the specific problem to be solved specified by the initial state and goal, in contrast to those in which there is no input domain specified. Such planners are called "Domain Independent" to emphasis the fact that they can solve planning problems from a wide range of domains. Typical examples of domains are block stacking, logistics, workflow management, and robot task planning. Hence a single domain independent planner can be used to solve planning problems in all these various domains. On the other hand, a route planner is typical of a domain specific planner.\n</p>, <p>The most commonly used languages for representing planning domains and specific planning problems, such as <a href="/wiki/STRIPS" title="STRIPS">STRIPS</a> and <a href="/wiki/Planning_Domain_Definition_Language" title="Planning Domain Definition Language">PDDL</a> for Classical Planning, are based on state variables. Each possible state of the world is an assignment of values to the state variables, and actions determine how the values of the state variables change when that action is taken. Since a set of state variables induce a state space that has a size that is exponential in the set, planning, similarly to many other computational problems, suffers from the <a href="/wiki/Curse_of_dimensionality" title="Curse of dimensionality">curse of dimensionality</a> and the <a href="/wiki/Combinatorial_explosion" title="Combinatorial explosion">combinatorial explosion</a>.\n</p>, <p>An alternative language for describing planning problems is that of <a href="/wiki/Hierarchical_task_network" title="Hierarchical task network">hierarchical task networks</a>, in which a set of tasks is given, and each task can be either realized by a primitive action or decomposed into a set of other tasks. This does not necessarily involve state variables, although in more realistic applications state variables simplify the description of task networks.\n</p>, <p>Temporal planning can be solved with methods similar to classical planning. The main difference is, because of the possibility of several, temporally overlapping actions with a duration being taken concurrently,\nthat the definition of a state has to include information about the current absolute time and how far the execution of each active action has proceeded. Further, in planning with rational or real time, the state space may be infinite, unlike in classical planning or planning with integer time. Temporal planning is closely related to <a class="mw-redirect" href="/wiki/Scheduling" title="Scheduling">scheduling</a> problems.\nTemporal planning can also be understood in terms of <a href="/wiki/Timed_automaton" title="Timed automaton">timed automata</a>.\n</p>, <p>Probabilistic planning can be solved with iterative methods such as <a class="mw-redirect" href="/wiki/Value_iteration" title="Value iteration">value iteration</a> and <a class="mw-redirect" href="/wiki/Policy_iteration" title="Policy iteration">policy iteration</a>, when the state space is sufficiently small.\nWith partial observability, probabilistic planning is similarly solved with iterative methods, but using a representation of the value functions defined for the space of beliefs instead of states.\n</p>, <p>In preference-based planning, the objective is not only to produce a plan but also to satisfy user-specified <a href="/wiki/Preference" title="Preference">preferences</a>. A difference to the more common reward-based planning, for example corresponding to MDPs, preferences don\'t necessarily have a precise numerical value.\n</p>, <p>Deterministic planning was introduced with the <a href="/wiki/STRIPS" title="STRIPS">STRIPS</a> planning system, which is a hierarchical planner. Action names are ordered in a sequence and this is a plan for the robot. Hierarchical planning can be compared with an automatic generated <a href="/wiki/Behavior_tree_(artificial_intelligence,_robotics_and_control)" title="Behavior tree (artificial intelligence, robotics and control)">behavior tree</a>.<sup class="reference" id="cite_ref-2"><a href="#cite_note-2">[2]</a></sup> The disadvantage is, that a normal behavior tree is not so expressive like a computer program. That means, the notation of a behavior graph contains action commands, but no <a class="mw-redirect" href="/wiki/Loop_(computing)" title="Loop (computing)">loops</a> or if-then-statements. Conditional planning overcomes the bottleneck and introduces an elaborated notation which is similar to a <a href="/wiki/Control_flow" title="Control flow">control flow</a>, known from other programming languages like <a href="/wiki/Pascal_(programming_language)" title="Pascal (programming language)">Pascal</a>. It is very similar to <a href="/wiki/Program_synthesis" title="Program synthesis">program synthesis</a>, that means a planner generates sourcecode which can be executed by an interpreter.<sup class="reference" id="cite_ref-3"><a href="#cite_note-3">[3]</a></sup>\n</p>, <p>An early example of a conditional planner is \xe2\x80\x9cWarplan-C\xe2\x80\x9d which was introduced in the mid 1970s.<sup class="reference" id="cite_ref-4"><a href="#cite_note-4">[4]</a></sup> Until now, the question was not answered what the difference is between a normal sequence and a complicated plan, which contains if-then-statements. It has to do with uncertainty at <a href="/wiki/Run_time_(program_lifecycle_phase)" title="Run time (program lifecycle phase)">runtime</a> of a plan. The idea is, that a plan can react to <a href="/wiki/Soft_sensor" title="Soft sensor">sensor signals</a> which are unknown for the planner. The planner generates two choices in advance. For example, if an object was detected, then action A is executed, if an object is missing, then action B is executed.<sup class="reference" id="cite_ref-5"><a href="#cite_note-5">[5]</a></sup> A major advantage of conditional planning is the ability to handle <a href="/wiki/Partial-order_planning" title="Partial-order planning">partial plans</a>.<sup class="reference" id="cite_ref-6"><a href="#cite_note-6">[6]</a></sup> An agent is not forced to plan everything from start to finish but can divide the problem into <a class="mw-redirect" href="/wiki/Chunking_(computational_linguistics)" title="Chunking (computational linguistics)">chunks</a>. This helps to reduce the state space and solves much more complex problems.\n</p>]