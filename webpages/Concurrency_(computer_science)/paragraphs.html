[<p>In <a href="/wiki/Computer_science" title="Computer science">computer science</a>, <b>concurrency</b> refers to the ability of different parts or units of a program, algorithm, or problem to be executed out-of-order or in partial order, without affecting the final outcome.  This allows for parallel execution of the concurrent units, which can significantly improve overall speed of the execution in multi-processor and multi-core systems. In more technical terms, concurrency refers to the decomposability property of a program, algorithm, or problem into order-independent or partially-ordered components or units.<sup class="reference" id="cite_ref-1"><a href="#cite_note-1">[1]</a></sup> \n</p>, <p>A number of mathematical models have been developed for general concurrent computation including <a href="/wiki/Petri_net" title="Petri net">Petri nets</a>, <a class="mw-redirect" href="/wiki/Process_calculi" title="Process calculi">process calculi</a>, the <a href="/wiki/Parallel_random-access_machine" title="Parallel random-access machine">parallel random-access machine</a> model, the <a href="/wiki/Actor_model" title="Actor model">actor model</a> and the <a href="/wiki/Reo_Coordination_Language" title="Reo Coordination Language">Reo Coordination Language</a>.\n</p>, <p>As <a href="/wiki/Leslie_Lamport" title="Leslie Lamport">Leslie Lamport</a> (2015) notes, "While <a class="mw-redirect" href="/wiki/Concurrent_program" title="Concurrent program">concurrent program</a> execution had been considered for years, the computer science of concurrency began with <a class="mw-redirect" href="/wiki/Edsger_Dijkstra" title="Edsger Dijkstra">Edsger Dijkstra</a>\'s seminal 1965 paper that introduced the <a href="/wiki/Mutual_exclusion" title="Mutual exclusion">mutual exclusion</a> problem. ... The ensuing decades have seen a huge growth of interest in concurrency\xe2\x80\x94particularly in <a class="mw-redirect" href="/wiki/Distributed_system" title="Distributed system">distributed systems</a>. Looking back at the origins of the field, what stands out is the fundamental role played by Edsger Dijkstra".<sup class="reference" id="cite_ref-Lamport_(2015)_2-0"><a href="#cite_note-Lamport_(2015)-2">[2]</a></sup>\n</p>, <p>Because computations in a concurrent system can interact with each other while being executed, the number of possible execution paths in the system can be extremely large, and the resulting outcome can be <a href="/wiki/Indeterminacy_in_concurrent_computation" title="Indeterminacy in concurrent computation">indeterminate</a>. Concurrent use of shared <a class="mw-redirect" href="/wiki/Resource_(computer_science)" title="Resource (computer science)">resources</a> can be a source of indeterminacy leading to issues such as <a href="/wiki/Deadlock" title="Deadlock">deadlocks</a>, and <a class="mw-redirect" href="/wiki/Resource_starvation" title="Resource starvation">resource starvation</a>.<sup class="reference" id="cite_ref-cleaveland1996_3-0"><a href="#cite_note-cleaveland1996-3">[3]</a></sup>\n</p>, <p>Design of concurrent systems often entails finding reliable techniques for coordinating their execution, data exchange, <a class="mw-redirect" href="/wiki/Memory_allocation" title="Memory allocation">memory allocation</a>, and execution scheduling to minimize <a href="/wiki/Latency_(engineering)" title="Latency (engineering)">response time</a> and maximise <a href="/wiki/Throughput" title="Throughput">throughput</a>.<sup class="reference" id="cite_ref-4"><a href="#cite_note-4">[4]</a></sup>\n</p>, <p>Concurrency theory has been an active field of research in <a href="/wiki/Theoretical_computer_science" title="Theoretical computer science">theoretical computer science</a>.  One of the first proposals was  <a href="/wiki/Carl_Adam_Petri" title="Carl Adam Petri">Carl Adam Petri</a>\'s seminal work on <a href="/wiki/Petri_net" title="Petri net">Petri nets</a> in the early 1960s. In the years since, a wide variety of formalisms have been developed for modeling and reasoning about concurrency.\n</p>, <p>A number of formalisms for modeling and understanding concurrent systems have been developed, including:<sup class="reference" id="cite_ref-5"><a href="#cite_note-5">[5]</a></sup>\n</p>, <p>Some of these models of concurrency are primarily intended to support reasoning and specification, while others can be used through the entire development cycle, including design, implementation, proof, testing and simulation of concurrent systems. Some of these are based on <a href="/wiki/Message_passing" title="Message passing">message passing</a>, while others have different mechanisms for concurrency.\n</p>, <p>The proliferation of different models of concurrency has motivated some researchers to develop ways to unify these different theoretical models. For example, Lee and Sangiovanni-Vincentelli have demonstrated that a so-called "tagged-signal" model can be used to provide a common framework for defining the <a href="/wiki/Denotational_semantics" title="Denotational semantics">denotational semantics</a> of a variety of different models of concurrency,<sup class="reference" id="cite_ref-7"><a href="#cite_note-7">[7]</a></sup> while Nielsen, Sassone, and Winskel have demonstrated that <a href="/wiki/Category_theory" title="Category theory">category theory</a> can be used to provide a similar unified understanding of different models.<sup class="reference" id="cite_ref-8"><a href="#cite_note-8">[8]</a></sup>\n</p>, <p>The Concurrency Representation Theorem in the actor model provides a fairly general way to represent concurrent systems that are closed in the sense that they do not receive communications from outside. (Other concurrency systems, e.g., <a class="mw-redirect" href="/wiki/Process_calculi" title="Process calculi">process calculi</a> can be modeled in the actor model using a <a href="/wiki/Two-phase_commit_protocol" title="Two-phase commit protocol">two-phase commit protocol</a>.<sup class="reference" id="cite_ref-9"><a href="#cite_note-9">[9]</a></sup>) The mathematical denotation denoted by a closed system <tt>S</tt> is constructed increasingly better approximations from an initial behavior called <tt>\xe2\x8a\xa5<sub>S</sub></tt> using a behavior approximating function <tt><b>progression</b><sub>S</sub></tt> to construct a denotation (meaning ) for <tt>S</tt> as follows:<sup class="reference" id="cite_ref-clinger1981_10-0"><a href="#cite_note-clinger1981-10">[10]</a></sup>\n</p>, <p>In this way, <tt>S</tt> can be mathematically characterized in terms of all its possible behaviors.\n</p>, <p>Various types of <a href="/wiki/Temporal_logic" title="Temporal logic">temporal logic</a><sup class="reference" id="cite_ref-stirling_11-0"><a href="#cite_note-stirling-11">[11]</a></sup> can be used to help reason about concurrent systems. Some of these logics, such as <a href="/wiki/Linear_temporal_logic" title="Linear temporal logic">linear temporal logic</a> and <a href="/wiki/Computation_tree_logic" title="Computation tree logic">computation tree logic</a>, allow assertions to be made about the sequences of states that a concurrent system can pass through. Others, such as <a class="new" href="/w/index.php?title=Action_computational_tree_logic&amp;action=edit&amp;redlink=1" title="Action computational tree logic (page does not exist)">action computational tree logic</a>, <a href="/wiki/Hennessy%E2%80%93Milner_logic" title="Hennessy\xe2\x80\x93Milner logic">Hennessy\xe2\x80\x93Milner logic</a>, and <a href="/wiki/Leslie_Lamport" title="Leslie Lamport">Lamport\'s</a> <a href="/wiki/Temporal_logic_of_actions" title="Temporal logic of actions">temporal logic of actions</a>, build their assertions from sequences of <i>actions</i> (changes in state). The principal application of these logics is in writing specifications for concurrent systems.<sup class="reference" id="cite_ref-cleaveland1996_3-1"><a href="#cite_note-cleaveland1996-3">[3]</a></sup>\n</p>, <p><a class="mw-redirect" href="/wiki/Concurrent_programming" title="Concurrent programming">Concurrent programming</a> encompasses programming languages and algorithms used to implement concurrent systems.  Concurrent programming is usually considered to be more general than <a class="mw-redirect" href="/wiki/Parallel_programming" title="Parallel programming">parallel programming</a> because it can involve arbitrary and dynamic patterns of communication and interaction, whereas parallel systems generally have a predefined and well-structured communications pattern. The base goals of concurrent programming include <i>correctness</i>, <i>performance</i> and <i>robustness</i>. Concurrent systems such as <a href="/wiki/Operating_system" title="Operating system">Operating systems</a> and <a class="mw-redirect" href="/wiki/Database_management_system" title="Database management system">Database management systems</a> are generally designed to operate indefinitely, including automatic recovery from failure, and not terminate unexpectedly (see <a href="/wiki/Concurrency_control" title="Concurrency control">Concurrency control</a>). Some concurrent systems implement a form of transparent concurrency, in which concurrent computational entities may compete for and share a single resource, but the complexities of this competition and sharing are shielded from the programmer.\n</p>, <p>Because they use shared resources, concurrent systems in general require the inclusion of some kind of <a href="/wiki/Arbiter_(electronics)" title="Arbiter (electronics)">arbiter</a> somewhere in their implementation (often in the underlying hardware), to control access to those resources. The use of arbiters introduces the possibility of <a href="/wiki/Indeterminacy_in_concurrent_computation" title="Indeterminacy in concurrent computation">indeterminacy in concurrent computation</a> which has major implications for practice including correctness and performance.  For example, arbitration introduces <a href="/wiki/Unbounded_nondeterminism" title="Unbounded nondeterminism">unbounded nondeterminism</a> which raises issues with <a href="/wiki/Model_checking" title="Model checking">model checking</a> because it causes explosion in the state space and can even cause models to have an infinite number of states.\n</p>, <p>Some concurrent programming models include <a href="/wiki/Coprocess" title="Coprocess">coprocesses</a> and <a class="mw-redirect" href="/wiki/Deterministic_concurrency" title="Deterministic concurrency">deterministic concurrency</a>. In these models, threads of control explicitly <a href="/wiki/Yield_(multithreading)" title="Yield (multithreading)">yield</a> their timeslices, either to the system or to another process.\n</p>]