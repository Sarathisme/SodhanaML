[<p><b>Mixed reality</b> (<b>MR</b>), sometimes referred to as <b>hybrid reality</b>,<sup class="reference" id="cite_ref-ciyscapes_1-0"><a href="#cite_note-ciyscapes-1">[1]</a></sup> is the merging of real and <a href="/wiki/Virtual_world" title="Virtual world">virtual worlds</a> to produce new environments and visualizations where physical and digital objects co-exist and interact in real time. Mixed reality takes place not only in the physical world or the virtual world,<sup class="reference" id="cite_ref-ciyscapes_1-1"><a href="#cite_note-ciyscapes-1">[1]</a></sup> but is a mix of <a href="/wiki/Reality" title="Reality">reality</a> and <a href="/wiki/Virtual_reality" title="Virtual reality">virtual reality</a>, encompassing both <a href="/wiki/Augmented_reality" title="Augmented reality">augmented reality</a> and <a class="mw-redirect" href="/wiki/Augmented_virtuality" title="Augmented virtuality">augmented virtuality</a><sup class="reference" id="cite_ref-continuum_2-0"><a href="#cite_note-continuum-2">[2]</a></sup> via <a href="/wiki/Immersive_technology" title="Immersive technology">immersive technology</a>. The first immersive mixed reality system, providing enveloping sight, sound, and touch was the <a href="/wiki/Virtual_fixture" title="Virtual fixture">Virtual Fixtures</a> platform developed at the U.S. Air Force\'s <a class="mw-redirect" href="/wiki/Armstrong_Labs" title="Armstrong Labs">Armstrong Laboratories</a> in the early 1990s. In a study published in 1992, the Virtual Fixtures project at the U.S. Air Force demonstrated for the first time that human performance could be significantly amplified by the introduction of spatially registered virtual objects overlaid on top of a person\'s direct view of a real physical environment.<sup class="reference" id="cite_ref-3"><a href="#cite_note-3">[3]</a></sup>\n</p>, <p>The definitions in the modern contemporary economy makes the distinction between VR, AR and MR very clear:<sup class="reference" id="cite_ref-4"><a href="#cite_note-4">[4]</a></sup>\n</p>, <p>In 1994 Paul Milgram and Fumio Kishino defined a <b>mixed reality</b> as "...anywhere between the extrema of the <i>virtuality continuum</i>" (VC),<sup class="reference" id="cite_ref-continuum_2-1"><a href="#cite_note-continuum-2">[2]</a></sup> where the <a class="mw-redirect" href="/wiki/Virtuality_continuum" title="Virtuality continuum">virtuality continuum</a> extends from the completely real through to the completely virtual environment with <a href="/wiki/Augmented_reality" title="Augmented reality">augmented reality</a> and <a class="mw-redirect" href="/wiki/Augmented_virtuality" title="Augmented virtuality">augmented virtuality</a> ranging between.  The first fully immersive mixed reality system was the <a href="/wiki/Virtual_fixture" title="Virtual fixture">Virtual Fixtures</a> platform developed at US Air Force, <a href="/wiki/Armstrong_Laboratory" title="Armstrong Laboratory">Armstrong Labs</a> in 1992 by <a href="/wiki/Louis_B._Rosenberg" title="Louis B. Rosenberg">Louis Rosenberg</a> to enable human users to control robots in real-world environments that included real physical objects and 3D virtual overlays called "fixtures" that were added enhance human performance of manipulation tasks.  Published studies showed that by introducing virtual objects into the real world, significant performance increases could be achieved by human operators.<sup class="reference" id="cite_ref-6"><a href="#cite_note-6">[6]</a></sup><sup class="reference" id="cite_ref-7"><a href="#cite_note-7">[7]</a></sup>\n</p>, <p>The continuum of mixed reality is one of the two axes in\n<a href="/wiki/Steve_Mann" title="Steve Mann">Steve Mann</a>\'s concept of <a class="mw-redirect" href="/wiki/Mediated_reality" title="Mediated reality">mediated reality</a> as implemented by various welding helmets and wearable computers and wearable photographic systems he created in the 1970s and early 1980s,<sup class="reference" id="cite_ref-8"><a href="#cite_note-8">[8]</a></sup><sup class="reference" id="cite_ref-9"><a href="#cite_note-9">[9]</a></sup><sup class="reference" id="cite_ref-10"><a href="#cite_note-10">[10]</a></sup><sup class="reference" id="cite_ref-11"><a href="#cite_note-11">[11]</a></sup><sup class="reference" id="cite_ref-12"><a href="#cite_note-12">[12]</a></sup> the second axis being the <i>mediality continuum</i>, which includes, for example, Diminished Reality (as implemented in a welding helmet or eyeglasses that can block out advertising or replace real-world ads with useful information)<sup class="reference" id="cite_ref-13"><a href="#cite_note-13">[13]</a></sup><sup class="reference" id="cite_ref-14"><a href="#cite_note-14">[14]</a></sup>\n</p>, <p>"The conventionally held view of a Virtual Reality (VR) environment is one in which the participant-observer is totally immersed in, and able to interact with, a completely synthetic world. Such a world may mimic the properties of some real-world environments, either existing or fictional; however, it can also exceed the bounds of physical reality by creating a world in which the physical laws ordinarily governing space, time, mechanics, material properties, etc. no longer hold. What may be overlooked in this view, however, is that the VR label is also frequently used in association with a variety of other environments, to which total immersion and complete synthesis do not necessarily pertain, but which fall somewhere along a virtuality continuum. In this paper we focus on a particular subclass of VR related technologies that involve the merging of real and virtual worlds, which we refer to generically as Mixed Reality (MR)."\n</p>, <p>In a physics context, the term "interreality system"<sup class="reference" id="cite_ref-15"><a href="#cite_note-15">[15]</a></sup> refers to a virtual reality system coupled to its real-world counterpart.  A paper in the May 2007 issue of Physical Review E<sup class="reference" id="cite_ref-16"><a href="#cite_note-16">[16]</a></sup> describes an interreality system comprising a real physical pendulum coupled to a pendulum that only exists in virtual reality.  This system apparently has two stable states of motion: a "Dual Reality" state in which the motion of the two pendula are uncorrelated and a "Mixed Reality" state in which the pendula exhibit stable phase-locked motion which is highly correlated.  The use of the terms "mixed reality" and "interreality" in the context of physics is clearly defined but may be slightly different in other fields.\n</p>, <p><b>Augmented virtuality</b> (<b>AV</b>), is a subcategory of mixed reality which refers to the merging of real world objects into virtual worlds.<sup class="reference" id="cite_ref-18"><a href="#cite_note-18">[18]</a></sup>\n</p>, <p>As an intermediate case in the <a class="mw-redirect" href="/wiki/Virtuality_continuum" title="Virtuality continuum">virtuality continuum</a>, it refers to predominantly virtual spaces, where physical elements, e.g. physical objects or people, are dynamically integrated into, and can interact with, the virtual world in real time. This integration is achieved with the use of various techniques. Often streaming video from physical spaces (e.g., via webcam)<sup class="reference" id="cite_ref-19"><a href="#cite_note-19">[19]</a></sup> or using 3-dimensional digitalisation of physical objects.<sup class="reference" id="cite_ref-20"><a href="#cite_note-20">[20]</a></sup>\n</p>, <p>The use of real-world sensor information (e.g., gyroscopes) to control a virtual environment is an additional form of augmented virtuality, in which external inputs provide context for the virtual view.\n</p>, <p>A topic of much research, MR has found its way into a number of applications, evident in the arts and entertainment industries. However, MR is also branching out into the business, manufacturing and education worlds with systems such as these:\n</p>, <p>Moving from static product catalogs to interactive 3D smart digital replicas. Solution consists of application software products with scalable license model.\n</p>, <p>Moving from e-learning to s-learning\xe2\x80\x94state of the art in knowledge transfer for education. Simulation/VR based training, interactive experiential learning. Software and display solutions with scalable licensed curriculum development model.\n</p>, <p>Combat reality is simulated and represented in complex layered data through HMD.\n</p>, <p>One of the possible applications mixed realities is for training military soldiers. Training solutions are often built on Commercial Off the Shelf (COTS) technologies. Examples of technologies used by the Army are <a href="/wiki/VBS3" title="VBS3">Virtual Battlespace 3</a> and VirTra. As of 2018, the VirTra technology is being purchased by both the civilian and military law enforcement to train personnel in a variety of scenarios. These scenarios include active shooter; domestic violence; military traffic stops, etc.<sup class="reference" id="cite_ref-21"><a href="#cite_note-21">[21]</a></sup><sup class="reference" id="cite_ref-22"><a href="#cite_note-22">[22]</a></sup> Â Mixed reality technologies have been used by <a href="/wiki/United_States_Army_Research_Laboratory" title="United States Army Research Laboratory">U.S. Army Research Laboratory</a> scientists to study how this stress affects decision making. With mixed reality, researchers may safely study military service men and women in scenarios where soldiers would not likely survive.<sup class="reference" id="cite_ref-23"><a href="#cite_note-23">[23]</a></sup>\n</p>, <p>As of 2017, the U.S. Army was developing the Synthetic Training Environment (STE). STE is a collection of technologies for training purposes that has been estimated to include mixed reality. As of 2018, STE was still in development without a projected completion date. Some recorded goals of the simulation were to increase simulation training capabilities, and the availability of the environment to other systems, and to enhance realism.<sup class="reference" id="cite_ref-24"><a href="#cite_note-24">[24]</a></sup> It was claimed that training costs to be reduced with mixed reality environments like STE.<sup class="reference" id="cite_ref-25"><a href="#cite_note-25">[25]</a></sup><sup class="reference" id="cite_ref-26"><a href="#cite_note-26">[26]</a></sup> For example, using mixed environments could reduce the amount of munition expended during training.<sup class="reference" id="cite_ref-27"><a href="#cite_note-27">[27]</a></sup> It was reported in 2018 that STE would include representation of any part of the world\'s terrain for training purposes.<sup class="reference" id="cite_ref-28"><a href="#cite_note-28">[28]</a></sup> STE would offer a variety of training opportunities for squad brigade and combat teams, including, but not limited to <a href="/wiki/Stryker" title="Stryker">Stryker</a>, armory, and infantry.<sup class="reference" id="cite_ref-29"><a href="#cite_note-29">[29]</a></sup> It is estimated that STE will eventually replace the Army\'s <a href="/wiki/Virtual_reality#Live,_Virtual,_Constructed-_Integrated_Architecture_(LVC-IA)" title="Virtual reality">Live, Virtual, Constructive \xe2\x80\x93 Integrated Architecture</a> (LVC-IA).<sup class="reference" id="cite_ref-30"><a href="#cite_note-30">[30]</a></sup>\n</p>, <p>3D Models of Manufacturing Assets (for example process manufacturing machinery) are incorporated into a virtual environment and then linked to real-time data associated with that asset. Avatars allow for multidisciplinary collaboration and decision making based on the data presented in the virtual environment. This example of Mixed Reality was pioneered and demonstrated by Kevyn Renner of Chevron Corporation for which a United States Patent 8,589,809, B2 "Methods and Systems for Conducting a Meeting in a Virtual Environment" was granted November 19, 2013.<sup class="reference" id="cite_ref-31"><a href="#cite_note-31">[31]</a></sup>\nOne of the earliest patents describing mixed reality is shown by Michael DeLuca in United States Patent 6,064,354 "Stereoscopic user interface method and apparatus"  granted May 16, 2000.<sup class="reference" id="cite_ref-32"><a href="#cite_note-32">[32]</a></sup>\n</p>, <p>Mixed reality allows a global workforce of remote teams to work together and tackle an organization\'s business challenges. No matter where they are physically located, an employee can strap on their headset and noise-canceling headphones and enter a collaborative, immersive virtual environment. Language barriers will become irrelevant as AR applications are able to accurately translate in real time. It also means a more flexible workforce. While many employers still use inflexible models of fixed working time and location, there is evidence that employees are more productive if they have greater autonomy over where, when and how they work. Some employees prefer loud work spaces, others need silence. Some work best in the morning, others at night. Employees also benefit from autonomy in how they work because everyone processes information differently. The classic VAK model for learning styles differentiates Visual, Auditory and Kinesthetic learners.<sup class="reference" id="cite_ref-33"><a href="#cite_note-33">[33]</a></sup>\n</p>, <p>Machine maintenance is also a subject that can be executed with the help of mixed reality. Larger companies that have multiple manufacturing locations with a lot of machinery can use mixed reality to educate and instruct their employee. The machines need regular checkups and have to be adjusted every now and then. These adjustments are mostly done by humans, so these employees need to be informed about every small adjustment that needs to be done. By using mixed reality, employees from multiple locations can put on a headset, and get live instructions about the changes. Instructors can operate the representation that every employee sees and can glide through the production area, zooming in to technical details and explain every change of a machine. It has shown that a five-minute training session with such a mixed reality program has the same results as the employees reading a 50-page training manual.<sup class="reference" id="cite_ref-34"><a href="#cite_note-34">[34]</a></sup>\n</p>, <p>Surgical and ultrasound simulations are used as a training exercise for healthcare professionals. Medical mannequins are brought to life to generate unlimited training scenarios and teach empathy to healthcare professionals.<sup class="reference" id="cite_ref-35"><a href="#cite_note-35">[35]</a></sup>   \n</p>, <p>Virtual models are used to allowed scientists and engineers to interact with a possible future creation before it touches the factory floor. These models provide the opportunity to gain an intuitive understanding of the exact product, including real size and constructions details that allow a closer inspection of interior parts. These virtual models are also used to find hidden problems and reduce time and money.<sup class="reference" id="cite_ref-36"><a href="#cite_note-36">[36]</a></sup>\n</p>, <p>Mixed reality is applied in the industrial field in order to build mockups that combine physical and digital elements.<sup class="reference" id="cite_ref-37"><a href="#cite_note-37">[37]</a></sup>\n</p>, <p>By making use of mixed reality organizations can make use of rapid prototyping or early trial and test methods, since designers are able to preview prototype designs at scale and reconstruct these previewed 3D models. This form of rapid prototyping will probably lead to an increase of quality in products, relatively lower R&amp;D costs and improved efficiency.\n</p>, <p>Architecture firms can use mixed reality to project virtual representations of buildings they are working on over the real world with applications like SketchUp Viewer.<sup class="reference" id="cite_ref-38"><a href="#cite_note-38">[38]</a></sup> This means that the architecture firm itself as well as the client can prematurely view what the building will look like in the real world, and adjust accordingly. This is already done by some companies and is mainly done with the Microsoft HoloLens.<sup class="reference" id="cite_ref-39"><a href="#cite_note-39">[39]</a></sup>\n</p>, <p>There are already some applications that let consumers (re)design their own homes by making a <a href="/wiki/3D_scanning" title="3D scanning">3D scan</a> of the room. The consumers can then within that application relocate doors or windows and add all kinds of virtual furniture to the real-life room.<sup class="reference" id="cite_ref-40"><a href="#cite_note-40">[40]</a></sup>\n</p>, <p>It has been hypothesised that a hybrid of mixed and <a href="/wiki/Virtual_reality" title="Virtual reality">virtual reality</a> could pave the way for human consciousness to be transferred into digital form entirely - a concept known as <a href="/wiki/Virternity" title="Virternity">Virternity</a>, which would leverage <a href="/wiki/Blockchain" title="Blockchain">blockchain</a> to create its main platform. <sup class="reference" id="cite_ref-41"><a href="#cite_note-41">[41]</a></sup> <sup class="reference" id="cite_ref-42"><a href="#cite_note-42">[42]</a></sup>\n</p>, <p>Here are some more commonly used MR display technologies:\n</p>, <p><a class="mw-redirect" href="/wiki/Cave_Automatic_Virtual_Environment" title="Cave Automatic Virtual Environment">Cave Automatic Virtual Environment</a>\n</p>, <p><a href="/wiki/Head-up_display" title="Head-up display">Head-up display</a>\n</p>, <p><a href="/wiki/Head-mounted_display" title="Head-mounted display">Head-mounted display</a>\n</p>, <p><a href="/wiki/Tablet_computer" title="Tablet computer">Tablet PC</a>\n</p>, <p><a class="mw-redirect" href="/wiki/Computer_display" title="Computer display">Computer display</a>\n</p>, <p><a class="mw-redirect" href="/wiki/Personal_Digital_Assistant" title="Personal Digital Assistant">Personal Digital Assistant</a>\n</p>, <p><a class="mw-redirect" href="/wiki/Mobile_phones" title="Mobile phones">Mobile phones</a>\n</p>, <p><a href="/wiki/Handheld_PC" title="Handheld PC">Handheld PC</a>\n</p>, <p><a class="image" href="/wiki/File:Commons-logo.svg"><img alt="" class="noviewer" data-file-height="1376" data-file-width="1024" height="16" src="//upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/12px-Commons-logo.svg.png" srcset="//upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/18px-Commons-logo.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/24px-Commons-logo.svg.png 2x" width="12"/></a> Media related to <a class="extiw" href="https://commons.wikimedia.org/wiki/Category:Mixed_reality" title="commons:Category:Mixed reality">Mixed reality </a> at Wikimedia Commons\n</p>]