[<p>A <b>graphics processing unit</b> (<b>GPU</b>) is a specialized <a href="/wiki/Electronic_circuit" title="Electronic circuit">electronic circuit</a> designed to rapidly manipulate and alter <a class="mw-redirect" href="/wiki/Memory_(computing)" title="Memory (computing)">memory</a> to accelerate the creation of <a href="/wiki/Image" title="Image">images</a> in a <a class="mw-redirect" href="/wiki/Frame_buffer" title="Frame buffer">frame buffer</a> intended for output to a <a href="/wiki/Display_device" title="Display device">display device</a>. GPUs are used in <a href="/wiki/Embedded_system" title="Embedded system">embedded systems</a>, <a href="/wiki/Mobile_phone" title="Mobile phone">mobile phones</a>, <a href="/wiki/Personal_computer" title="Personal computer">personal computers</a>, <a href="/wiki/Workstation" title="Workstation">workstations</a>, and <a class="mw-redirect" href="/wiki/Game_console" title="Game console">game consoles</a>. Modern GPUs are very efficient at manipulating <a href="/wiki/Computer_graphics" title="Computer graphics">computer graphics</a> and <a class="mw-redirect" href="/wiki/Image_processing" title="Image processing">image processing</a>. Their highly parallel structure makes them more efficient than general-purpose <a href="/wiki/Central_processing_unit" title="Central processing unit">CPUs</a> for <a href="/wiki/Algorithm" title="Algorithm">algorithms</a> that process large blocks of data in parallel. In a personal computer, a GPU can be present on a <a href="/wiki/Video_card" title="Video card">video card</a> or embedded on the <a href="/wiki/Motherboard" title="Motherboard">motherboard</a>. In certain CPUs, they are embedded on the CPU <a href="/wiki/Die_(integrated_circuit)" title="Die (integrated circuit)">die</a>.<sup class="reference" id="cite_ref-1"><a href="#cite_note-1">[1]</a></sup>\n</p>, <p>The term GPU has been used from at least the 1980s,<sup class="reference" id="cite_ref-gpu_2-0"><a href="#cite_note-gpu-2">[2]</a></sup> it was popularized by <a href="/wiki/Nvidia" title="Nvidia">Nvidia</a> in 1999, who marketed the <a href="/wiki/GeForce_256" title="GeForce 256">GeForce 256</a> as "the world\'s first GPU".<sup class="reference" id="cite_ref-3"><a href="#cite_note-3">[3]</a></sup> It was presented as a "single-chip processor with integrated <a href="/wiki/Transform,_clipping,_and_lighting" title="Transform, clipping, and lighting">transform, lighting, triangle setup/clipping</a>, and rendering engines".<sup class="reference" id="cite_ref-4"><a href="#cite_note-4">[4]</a></sup> Rival <a href="/wiki/ATI_Technologies" title="ATI Technologies">ATI Technologies</a> coined the term "<b>visual processing unit</b>" or <b>VPU</b> with the release of the <a class="mw-redirect" href="/wiki/R300" title="R300">Radeon 9700</a> in 2002.<sup class="reference" id="cite_ref-5"><a href="#cite_note-5">[5]</a></sup>\n</p>, <p><a href="/wiki/Arcade_system_board" title="Arcade system board">Arcade system boards</a> have been using specialized graphics chips since the 1970s. In early video game hardware, the <a href="/wiki/Random-access_memory" title="Random-access memory">RAM</a> for frame buffers was expensive, so video chips composited data together as the display was being scanned out on the monitor.<sup class="reference" id="cite_ref-6"><a href="#cite_note-6">[6]</a></sup>\n</p>, <p><a href="/wiki/Fujitsu" title="Fujitsu">Fujitsu</a>\'s MB14241 <a href="/wiki/Video_display_controller" title="Video display controller">video shifter</a> was used to accelerate the drawing of <a href="/wiki/Sprite_(computer_graphics)" title="Sprite (computer graphics)">sprite</a> graphics for various 1970s <a href="/wiki/Arcade_game" title="Arcade game">arcade games</a> from <a href="/wiki/Taito" title="Taito">Taito</a> and <a href="/wiki/Midway_Games" title="Midway Games">Midway</a>, such as <i><a href="/wiki/Gun_Fight" title="Gun Fight">Gun Fight</a></i> (1975), <i><a href="/wiki/Sea_Wolf_(video_game)" title="Sea Wolf (video game)">Sea Wolf</a></i> (1976) and <i><a href="/wiki/Space_Invaders" title="Space Invaders">Space Invaders</a></i> (1978).<sup class="reference" id="cite_ref-7"><a href="#cite_note-7">[7]</a></sup><sup class="reference" id="cite_ref-8"><a href="#cite_note-8">[8]</a></sup><sup class="reference" id="cite_ref-9"><a href="#cite_note-9">[9]</a></sup> The <a href="/wiki/Namco_Galaxian" title="Namco Galaxian">Namco Galaxian</a> arcade system in 1979 used specialized <a href="/wiki/Graphics_hardware" title="Graphics hardware">graphics hardware</a> supporting <a href="/wiki/RGB_color_model" title="RGB color model">RGB color</a>, multi-colored sprites and <a class="mw-redirect" href="/wiki/Tile_engine" title="Tile engine">tilemap</a> backgrounds.<sup class="reference" id="cite_ref-10"><a href="#cite_note-10">[10]</a></sup> The Galaxian hardware was widely used during the <a href="/wiki/Golden_age_of_arcade_video_games" title="Golden age of arcade video games">golden age of arcade video games</a>, by game companies such as <a href="/wiki/Namco" title="Namco">Namco</a>, <a href="/wiki/Centuri" title="Centuri">Centuri</a>, <a href="/wiki/Gremlin_Industries" title="Gremlin Industries">Gremlin</a>, <a href="/wiki/Irem" title="Irem">Irem</a>, <a href="/wiki/Konami" title="Konami">Konami</a>, <a href="/wiki/Midway_Games" title="Midway Games">Midway</a>, <a class="mw-redirect" href="/wiki/Nichibutsu" title="Nichibutsu">Nichibutsu</a>, <a href="/wiki/Sega" title="Sega">Sega</a> and <a class="mw-redirect" href="/wiki/Taito_Corporation" title="Taito Corporation">Taito</a>.<sup class="reference" id="cite_ref-11"><a href="#cite_note-11">[11]</a></sup><sup class="reference" id="cite_ref-12"><a href="#cite_note-12">[12]</a></sup>\n</p>, <p>In the home market, the <a href="/wiki/Atari_2600" title="Atari 2600">Atari 2600</a> in 1977 used a video shifter called the <a href="/wiki/Television_Interface_Adaptor" title="Television Interface Adaptor">Television Interface Adaptor</a>.<sup class="reference" id="cite_ref-13"><a href="#cite_note-13">[13]</a></sup> The <a href="/wiki/Atari_8-bit_family" title="Atari 8-bit family">Atari 8-bit computers</a> (1979) had <a href="/wiki/ANTIC" title="ANTIC">ANTIC</a>, a video processor which interpreted instructions describing a "display list"—the way the scan lines map to specific <a class="mw-redirect" href="/wiki/Bitmapped" title="Bitmapped">bitmapped</a> or character modes and where the memory is stored (so there did not need to be a contiguous frame buffer).<sup class="reference" id="cite_ref-14"><a href="#cite_note-14">[14]</a></sup> <a class="mw-redirect" href="/wiki/6502" title="6502">6502</a> <a href="/wiki/Machine_code" title="Machine code">machine code</a> <a href="/wiki/Subroutine" title="Subroutine">subroutines</a> could be triggered on <a href="/wiki/Scan_line" title="Scan line">scan lines</a> by setting a bit on a display list instruction.<sup class="reference" id="cite_ref-15"><a href="#cite_note-15">[15]</a></sup> ANTIC also supported smooth <a class="mw-redirect" href="/wiki/Vertical_scrolling" title="Vertical scrolling">vertical</a> and <a class="mw-redirect" href="/wiki/Horizontal_scrolling" title="Horizontal scrolling">horizontal scrolling</a> independent of the CPU.<sup class="reference" id="cite_ref-16"><a href="#cite_note-16">[16]</a></sup>\n</p>, <p>The <a href="/wiki/NEC_%C2%B5PD7220" title="NEC \xc2\xb5PD7220">NEC \xc2\xb5PD7220</a> was one of the first implementations of a graphics display controller as a single <a class="mw-redirect" href="/wiki/Large_Scale_Integration" title="Large Scale Integration">Large Scale Integration</a> (LSI) <a href="/wiki/Integrated_circuit" title="Integrated circuit">integrated circuit</a> chip, enabling the design of low-cost, high-performance video graphics cards such as those from <a href="/wiki/Number_Nine_Visual_Technology" title="Number Nine Visual Technology">Number Nine Visual Technology</a>. It became one of the best known of what were known as graphics processing units in the 1980s.<sup class="reference" id="cite_ref-gpu_2-1"><a href="#cite_note-gpu-2">[2]</a></sup>\n</p>, <p>The Williams Electronics arcade games <i><a class="mw-redirect" href="/wiki/Robotron_2084" title="Robotron 2084">Robotron 2084</a></i>, <i><a href="/wiki/Joust_(video_game)" title="Joust (video game)">Joust</a></i>, <i><a href="/wiki/Sinistar" title="Sinistar">Sinistar</a></i>, and <i><a href="/wiki/Bubbles_(video_game)" title="Bubbles (video game)">Bubbles</a></i>, all released in 1982, contain custom <a href="/wiki/Blitter" title="Blitter">blitter</a> chips for operating on 16-color bitmaps.<sup class="reference" id="cite_ref-17"><a href="#cite_note-17">[17]</a></sup><sup class="reference" id="cite_ref-18"><a href="#cite_note-18">[18]</a></sup>\n</p>, <p>In 1985, the <a class="mw-redirect" href="/wiki/Commodore_Amiga" title="Commodore Amiga">Commodore Amiga</a> featured a custom graphics chip, with a <a href="/wiki/Blitter" title="Blitter">blitter unit</a> accelerating bitmap manipulation, line draw, and area fill functions. Also included is a <a href="/wiki/Coprocessor" title="Coprocessor">coprocessor</a> (commonly referred to as "The Copper") with its own primitive instruction set, capable of manipulating graphics hardware registers in sync with the video beam (e.g. for per-scanline palette switches, sprite multiplexing, and hardware windowing), or driving the blitter.\n</p>, <p>In 1986, <a href="/wiki/Texas_Instruments" title="Texas Instruments">Texas Instruments</a> released the <a href="/wiki/TMS34010" title="TMS34010">TMS34010</a>, the first microprocessor with on-chip graphics capabilities. It could run general-purpose code, but it had a very graphics-oriented instruction set.  In 1990-1992, this chip would become the basis of the <a href="/wiki/Texas_Instruments_Graphics_Architecture" title="Texas Instruments Graphics Architecture">Texas Instruments Graphics Architecture</a> ("TIGA") <a href="/wiki/Windows_accelerator" title="Windows accelerator">Windows accelerator</a> cards.\n</p>, <p>In 1987, the <a href="/wiki/IBM_8514" title="IBM 8514">IBM 8514</a> graphics system was released as one of<sup class="noprint Inline-Template" style="white-space:nowrap;">[<i><a href="/wiki/Wikipedia:Vagueness" title="Wikipedia:Vagueness"><span title="This information is too vague. (November 2015)">vague</span></a></i>]</sup> the first video cards for <a href="/wiki/IBM_PC_compatible" title="IBM PC compatible">IBM PC compatibles</a> to implement <a href="/wiki/Fixed-function" title="Fixed-function">fixed-function</a> 2D primitives in <a href="/wiki/Electronic_hardware" title="Electronic hardware">electronic hardware</a>. The same year, <a href="/wiki/Sharp_Corporation" title="Sharp Corporation">Sharp</a> released the <a href="/wiki/X68000" title="X68000">X68000</a>, which used a custom graphics chipset<sup class="reference" id="cite_ref-19"><a href="#cite_note-19">[19]</a></sup> that was powerful for a home computer at the time, with a 65,536 color palette and hardware support for sprites, scrolling and multiple playfields,<sup class="reference" id="cite_ref-20"><a href="#cite_note-20">[20]</a></sup> eventually serving as a development machine for <a href="/wiki/Capcom" title="Capcom">Capcom</a>\'s <a href="/wiki/CP_System" title="CP System">CP System</a> arcade board. Fujitsu later competed with the <a href="/wiki/FM_Towns" title="FM Towns">FM Towns</a> computer, released in 1989 with support for a full 16,777,216 color palette.<sup class="reference" id="cite_ref-21"><a href="#cite_note-21">[21]</a></sup>\n</p>, <p>In 1988, the first dedicated <a href="/wiki/3D_computer_graphics" title="3D computer graphics">polygonal 3D</a> graphics boards were introduced in arcades with the <a href="/wiki/Namco_System_21" title="Namco System 21">Namco System 21</a><sup class="reference" id="cite_ref-22"><a href="#cite_note-22">[22]</a></sup> and <a class="mw-redirect" href="/wiki/Taito_Corporation" title="Taito Corporation">Taito</a> Air System.<sup class="reference" id="cite_ref-23"><a href="#cite_note-23">[23]</a></sup>\n</p>, <p>In 1991, <a href="/wiki/S3_Graphics" title="S3 Graphics">S3 Graphics</a> introduced the <i><a href="/wiki/S3_Graphics" title="S3 Graphics">S3 86C911</a></i>, which its designers named after the <a href="/wiki/Porsche_911" title="Porsche 911">Porsche 911</a> as an indication of the performance increase it promised.<sup class="reference" id="cite_ref-24"><a href="#cite_note-24">[24]</a></sup> The 86C911 spawned a host of imitators: by 1995, all major PC graphics chip makers had added 2D acceleration support to their chips.<sup class="reference" id="cite_ref-25"><a href="#cite_note-25">[25]</a></sup><sup class="reference" id="cite_ref-26"><a href="#cite_note-26">[26]</a></sup> By this time, fixed-function <i>Windows accelerators</i> had surpassed expensive general-purpose graphics coprocessors in Windows performance, and these coprocessors faded away from the PC market.\n</p>, <p>Throughout the 1990s, 2D <a href="/wiki/Graphical_user_interface" title="Graphical user interface">GUI</a>  acceleration continued to evolve. As manufacturing capabilities improved, so did the level of integration of graphics chips. Additional <a href="/wiki/Application_programming_interface" title="Application programming interface">application programming interfaces</a> (APIs) arrived for a variety of tasks, such as Microsoft\'s <a href="/wiki/WinG" title="WinG">WinG</a> <a href="/wiki/Graphics_library" title="Graphics library">graphics library</a> for <a href="/wiki/Windows_3.1x" title="Windows 3.1x">Windows 3.x</a>, and their later <a href="/wiki/DirectDraw" title="DirectDraw">DirectDraw</a> interface for <a href="/wiki/Hardware_acceleration" title="Hardware acceleration">hardware acceleration</a> of 2D games within <a href="/wiki/Windows_95" title="Windows 95">Windows 95</a> and later.\n</p>, <p>In the early- and mid-1990s, real-time 3D graphics were becoming increasingly common in arcade, computer and console games, which led to an increasing public demand for <a class="mw-redirect" href="/wiki/3D_acceleration" title="3D acceleration">hardware-accelerated 3D graphics</a>. Early examples of mass-market 3D graphics hardware can be found in arcade system boards such as the <a class="mw-redirect" href="/wiki/Sega_Model_1" title="Sega Model 1">Sega Model 1</a>, <a href="/wiki/Namco_System_22" title="Namco System 22">Namco System 22</a>, and <a class="mw-redirect" href="/wiki/Sega_Model_2" title="Sega Model 2">Sega Model 2</a>, and the <a class="mw-redirect" href="/wiki/History_of_video_game_consoles_(fifth_generation)" title="History of video game consoles (fifth generation)">fifth-generation video game consoles</a> such as the <a href="/wiki/Sega_Saturn" title="Sega Saturn">Saturn</a>, <a href="/wiki/PlayStation" title="PlayStation">PlayStation</a> and <a href="/wiki/Nintendo_64" title="Nintendo 64">Nintendo 64</a>. Arcade systems such as the Sega Model 2 and Namco Magic Edge Hornet Simulator in 1993 were capable of hardware T&amp;L (<a href="/wiki/Transform,_clipping,_and_lighting" title="Transform, clipping, and lighting">transform, clipping, and lighting</a>) years before appearing in consumer graphics cards.<sup class="reference" id="cite_ref-27"><a href="#cite_note-27">[27]</a></sup><sup class="reference" id="cite_ref-28"><a href="#cite_note-28">[28]</a></sup> Some systems used <a href="/wiki/Digital_signal_processor" title="Digital signal processor">DSPs</a> to accelerate transformations. Fujitsu, which worked on the Sega Model 2 arcade system,<sup class="reference" id="cite_ref-29"><a href="#cite_note-29">[29]</a></sup> began working on integrating T&amp;L into a single <a href="/wiki/Integrated_circuit" title="Integrated circuit">LSI</a> solution for use in home computers in 1995;<sup class="reference" id="cite_ref-30"><a href="#cite_note-30">[30]</a></sup><sup class="reference" id="cite_ref-31"><a href="#cite_note-31">[31]</a></sup> the Fujitsu Pinolite, the first 3D geometry processor for personal computers, released in 1997.<sup class="reference" id="cite_ref-32"><a href="#cite_note-32">[32]</a></sup> The first hardware T&amp;L GPU on <a class="mw-redirect" href="/wiki/Home_console" title="Home console">home</a> <a href="/wiki/Video_game_console" title="Video game console">video game consoles</a> was the <a href="/wiki/Nintendo_64" title="Nintendo 64">Nintendo 64</a>\'s <a href="/wiki/Reality_Coprocessor" title="Reality Coprocessor">Reality Coprocessor</a>, released in 1996.<sup class="reference" id="cite_ref-33"><a href="#cite_note-33">[33]</a></sup> In 1997, <a href="/wiki/Mitsubishi" title="Mitsubishi">Mitsubishi</a> released the <a href="/wiki/AMD_FirePro" title="AMD FirePro">3Dpro/2MP</a>, a fully featured GPU capable of transformation and lighting, for <a class="mw-redirect" href="/wiki/Workstations" title="Workstations">workstations</a> and <a href="/wiki/Windows_NT" title="Windows NT">Windows NT</a> desktops;<sup class="reference" id="cite_ref-34"><a href="#cite_note-34">[34]</a></sup> <a class="mw-redirect" href="/wiki/ATi" title="ATi">ATi</a> utilized it for their <a class="mw-redirect" href="/wiki/FireGL" title="FireGL">FireGL 4000</a> <a class="mw-redirect" href="/wiki/Graphics_card" title="Graphics card">graphics card</a>, released in 1997.<sup class="reference" id="cite_ref-35"><a href="#cite_note-35">[35]</a></sup>\n</p>, <p>In the PC world, notable failed first tries for low-cost 3D graphics chips were the <a href="/wiki/S3_Graphics" title="S3 Graphics">S3</a> <i><a class="mw-redirect" href="/wiki/ViRGE" title="ViRGE">ViRGE</a></i>, <a href="/wiki/ATI_Technologies" title="ATI Technologies">ATI</a> <i>Rage</i>, and <a href="/wiki/Matrox" title="Matrox">Matrox</a> <i>Mystique</i>. These chips were essentially previous-generation 2D accelerators with 3D features bolted on. Many were even <a class="mw-redirect" href="/wiki/Pin-compatibility" title="Pin-compatibility">pin-compatible</a> with the earlier-generation chips for ease of implementation and minimal cost. Initially, performance 3D graphics were possible only with discrete boards dedicated to accelerating 3D functions (and lacking 2D GUI acceleration entirely) such as the <a href="/wiki/PowerVR" title="PowerVR">PowerVR</a> and the <a class="mw-redirect" href="/wiki/3dfx" title="3dfx">3dfx</a> <i>Voodoo</i>. However, as manufacturing technology continued to progress, video, 2D GUI acceleration and 3D functionality were all integrated into one chip. <a href="/wiki/Rendition_(company)" title="Rendition (company)">Rendition\'s</a> <i>Verite</i> chipsets were among the first to do this well enough to be worthy of note. In 1997, Rendition went a step further by collaborating with <a href="/wiki/Hercules_Computer_Technology" title="Hercules Computer Technology">Hercules</a> and Fujitsu on a "Thriller Conspiracy" project which combined a Fujitsu FXG-1 Pinolite geometry processor with a V\xc3\xa9rit\xc3\xa9 V2200 core to create a graphics card with a full T&amp;L engine years before Nvidia\'s GeForce 256. This card, designed to reduce the load placed upon the system\'s CPU, never made it to market.<sup class="noprint Inline-Template Template-Fact" style="white-space:nowrap;">[<i><a href="/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources. (June 2018)">citation needed</span></a></i>]</sup>\n</p>, <p><a href="/wiki/OpenGL" title="OpenGL">OpenGL</a> appeared in the early \'90s as a professional graphics API, but originally suffered from performance issues which allowed the <a class="mw-redirect" href="/wiki/Glide_API" title="Glide API">Glide API</a> to step in and become a dominant force on the PC in the late \'90s.<sup class="reference" id="cite_ref-3dfxGlideAPIAdvantages_36-0"><a href="#cite_note-3dfxGlideAPIAdvantages-36">[36]</a></sup> However, these issues were quickly overcome and the Glide API fell by the wayside. Software implementations of OpenGL were common during this time, although the influence of OpenGL eventually led to widespread hardware support. Over time, a parity emerged between features offered in hardware and those offered in OpenGL. <a href="/wiki/DirectX" title="DirectX">DirectX</a> became popular among <a href="/wiki/Microsoft_Windows" title="Microsoft Windows">Windows</a> game developers during the late 90s. Unlike OpenGL, Microsoft insisted on providing strict one-to-one support of hardware. The approach made DirectX less popular as a standalone graphics API initially, since many GPUs provided their own specific features, which existing OpenGL applications were already able to benefit from, leaving DirectX often one generation behind. (See: <a href="/wiki/Comparison_of_OpenGL_and_Direct3D" title="Comparison of OpenGL and Direct3D">Comparison of OpenGL and Direct3D</a>.)\n</p>, <p>Over time, Microsoft began to work more closely with hardware developers, and started to target the releases of DirectX to coincide with those of the supporting graphics hardware. <a href="/wiki/Direct3D" title="Direct3D">Direct3D</a> 5.0 was the first version of the burgeoning API to gain widespread adoption in the gaming market, and it competed directly with many more-hardware-specific, often proprietary graphics libraries, while OpenGL maintained a strong following. Direct3D 7.0 introduced support for hardware-accelerated <a class="mw-redirect" href="/wiki/Transform_and_lighting" title="Transform and lighting">transform and lighting</a> (T&amp;L) for Direct3D, while OpenGL had this capability already exposed from its inception. 3D accelerator cards moved beyond being just simple <a href="/wiki/Rasterisation" title="Rasterisation">rasterizers</a> to add another significant hardware stage to the 3D rendering pipeline. The <a href="/wiki/Nvidia" title="Nvidia">Nvidia</a> <i><a href="/wiki/GeForce_256" title="GeForce 256">GeForce 256</a></i> (also known as NV10) was the first consumer-level card released on the market with hardware-accelerated T&amp;L, while professional 3D cards already had this capability. Hardware transform and lighting, both already existing features of OpenGL, came to consumer-level hardware in the \'90s and set the precedent for later <a class="mw-redirect" href="/wiki/Pixel_shader" title="Pixel shader">pixel shader</a> and <a class="mw-redirect" href="/wiki/Vertex_shader" title="Vertex shader">vertex shader</a> units which were far more flexible and programmable.\n</p>, <p>Nvidia was first to produce a chip capable of programmable <a class="mw-redirect" href="/wiki/Pixel_shader" title="Pixel shader">shading</a>, the <i><a class="mw-redirect" href="/wiki/GeForce_3" title="GeForce 3">GeForce 3</a></i> (code named NV20). Each pixel could now be processed by a short "program" that could include additional image textures as inputs, and each geometric vertex could likewise be processed by a short program before it was projected onto the screen. Used in the <a href="/wiki/Xbox" title="Xbox">Xbox</a> console, it competed with the <a href="/wiki/PlayStation_2" title="PlayStation 2">PlayStation 2</a> (which used a custom vector DSP for hardware accelerated vertex processing; commonly referred to VU0/VU1). The earliest incarnations of shader execution engines used in <a href="/wiki/Xbox" title="Xbox">Xbox</a> were not general purpose and could not execute arbitrary pixel code. Vertices and pixels were processed by different units which had their own resources with pixel shaders having much tighter constraints (being as they are executed at much higher frequencies than with vertices). Pixel shading engines were actually more akin to a highly customizable function block and didn\'t really "run" a program. Many of these disparities between vertex and pixel shading wouldn\'t be addressed until much later with the <a class="mw-redirect" href="/wiki/Unified_Shader_Model" title="Unified Shader Model">Unified Shader Model</a>.\n</p>, <p>By October 2002, with the introduction of the <a href="/wiki/ATI_Technologies" title="ATI Technologies">ATI</a> <i><a class="mw-redirect" href="/wiki/Radeon_9700_core" title="Radeon 9700 core">Radeon 9700</a></i> (also known as R300), the world\'s first Direct3D 9.0 accelerator, pixel and vertex shaders could implement <a class="mw-redirect" href="/wiki/Loop_(computing)" title="Loop (computing)">looping</a> and lengthy <a class="mw-redirect" href="/wiki/Floating_point" title="Floating point">floating point</a> math, and were quickly becoming as flexible as CPUs, yet orders of magnitude faster for image-array operations. Pixel shading is often used for <a href="/wiki/Bump_mapping" title="Bump mapping">bump mapping</a>, which adds texture, to make an object look shiny, dull, rough, or even round or extruded.<sup class="reference" id="cite_ref-37"><a href="#cite_note-37">[37]</a></sup>\n</p>, <p>With the introduction of the <a href="/wiki/GeForce_8_series" title="GeForce 8 series">GeForce 8 series</a>, which was produced by Nvidia, and then new generic stream processing unit GPUs became a more generalized computing device. Today, <a href="/wiki/Parallel_computing" title="Parallel computing">parallel</a> GPUs have begun making computational inroads against the CPU, and a subfield of research, dubbed GPU Computing or <a class="mw-redirect" href="/wiki/GPGPU" title="GPGPU">GPGPU</a> for <i>General Purpose Computing on GPU</i>, has found its way into fields as diverse as <a href="/wiki/Machine_learning" title="Machine learning">machine learning</a>,<sup class="reference" id="cite_ref-38"><a href="#cite_note-38">[38]</a></sup> <a class="mw-redirect" href="/wiki/Oil_exploration" title="Oil exploration">oil exploration</a>, scientific <a class="mw-redirect" href="/wiki/Image_processing" title="Image processing">image processing</a>, <a href="/wiki/Linear_algebra" title="Linear algebra">linear algebra</a>,<sup class="reference" id="cite_ref-39"><a href="#cite_note-39">[39]</a></sup> <a href="/wiki/Statistics" title="Statistics">statistics</a>,<sup class="reference" id="cite_ref-40"><a href="#cite_note-40">[40]</a></sup> <a href="/wiki/3D_reconstruction" title="3D reconstruction">3D reconstruction</a> and even <a class="mw-redirect" href="/wiki/Stock_options" title="Stock options">stock options</a> pricing determination. <a class="mw-redirect" href="/wiki/GPGPU" title="GPGPU">GPGPU</a> at the time was the precursor to what we now call compute shaders (e.g. CUDA, OpenCL, DirectCompute) and actually abused the hardware to a degree by treating the data passed to algorithms as texture maps and executing algorithms by drawing a triangle or quad with an appropriate pixel shader. This obviously entails some overheads since we involve units like the <a class="mw-redirect" href="/wiki/Rasterization" title="Rasterization">Scan Converter</a> where they aren\'t really needed (nor do we even care about the triangles, except to invoke the pixel shader). Over the years, the energy consumption of GPUs has increased and to manage it, several techniques have been proposed.<sup class="reference" id="cite_ref-41"><a href="#cite_note-41">[41]</a></sup>\n</p>, <p>Nvidia\'s <a href="/wiki/CUDA" title="CUDA">CUDA</a> platform, first introduced in 2007,<sup class="reference" id="cite_ref-42"><a href="#cite_note-42">[42]</a></sup> was the earliest widely adopted programming model for GPU computing.  More recently <a href="/wiki/OpenCL" title="OpenCL">OpenCL</a> has become broadly supported. OpenCL is an open standard defined by the Khronos Group which allows for the development of code for both GPUs and CPUs with an emphasis on portability.<sup class="reference" id="cite_ref-43"><a href="#cite_note-43">[43]</a></sup> OpenCL solutions are supported by Intel, AMD, Nvidia, and ARM, and according to a recent report by Evan\'s Data, OpenCL is the GPGPU development platform most widely used by developers in both the US and Asia Pacific.<sup class="noprint Inline-Template Template-Fact" style="white-space:nowrap;">[<i><a href="/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources. (June 2018)">citation needed</span></a></i>]</sup>\n</p>, <p>In 2010, Nvidia began a partnership with <a href="/wiki/Audi" title="Audi">Audi</a> to power their cars\' dashboards. These <a href="/wiki/Tegra" title="Tegra">Tegra</a> GPUs were powering the cars\' dashboard, offering increased functionality to cars\' navigation and entertainment systems.<sup class="reference" id="cite_ref-44"><a href="#cite_note-44">[44]</a></sup> Advancements in GPU technology in cars has helped push <a class="mw-redirect" href="/wiki/Autonomous_car" title="Autonomous car">self-driving technology</a>.<sup class="reference" id="cite_ref-45"><a href="#cite_note-45">[45]</a></sup> AMD\'s <a href="/wiki/Radeon_HD_6000_Series" title="Radeon HD 6000 Series">Radeon HD 6000 Series</a> cards were released in 2010 and in 2011, AMD released their 6000M Series discrete GPUs to be used in mobile devices.<sup class="reference" id="cite_ref-46"><a href="#cite_note-46">[46]</a></sup> The Kepler line of graphics cards by Nvidia came out in 2012 and were used in the Nvidia\'s 600 and 700 series cards. A new feature in this new GPU microarchitecture included GPU boost, a technology adjusts the clock-speed of a video card to increase or decrease it according to its power draw.<sup class="reference" id="cite_ref-47"><a href="#cite_note-47">[47]</a></sup> The <a href="/wiki/Kepler_(microarchitecture)" title="Kepler (microarchitecture)">Kepler microarchitecture</a> was manufactured on the 28 nm process.\n</p>, <p>The <a href="/wiki/PlayStation_4_technical_specifications" title="PlayStation 4 technical specifications">PS4</a> and <a href="/wiki/Xbox_One" title="Xbox One">Xbox One</a> were released in 2013, they both use GPUs based on AMD\'s Radeon HD 7850 and 7790. Nvidia\'s Kepler line of GPUs was followed by the <a href="/wiki/Maxwell_(microarchitecture)" title="Maxwell (microarchitecture)">Maxwell</a> line, manufactured on the same process. 28 nm chips by Nvidia were manufactured by TSMC, the Taiwan Semiconductor Manufacturing Company, that was manufacturing using the 28 nm process at the time. Compared to the 40 nm technology from the past, this new manufacturing process allowed a 20 percent boost in performance while drawing less power.<sup class="reference" id="cite_ref-48"><a href="#cite_note-48">[48]</a></sup><sup class="reference" id="cite_ref-49"><a href="#cite_note-49">[49]</a></sup> <a href="/wiki/Virtual_reality" title="Virtual reality">Virtual reality</a> <a href="/wiki/Virtual_reality_headset" title="Virtual reality headset">headsets</a> like the <a href="/wiki/Oculus_Rift" title="Oculus Rift">Oculus Rift</a> and the <a href="/wiki/HTC_Vive" title="HTC Vive">HTC Vive</a> have very high system requirements. VR headset manufacturers recommended the GTX 970 and the R9 290X or better at the time of their release.<sup class="reference" id="cite_ref-50"><a href="#cite_note-50">[50]</a></sup><sup class="reference" id="cite_ref-51"><a href="#cite_note-51">[51]</a></sup> <a href="/wiki/Pascal_(microarchitecture)" title="Pascal (microarchitecture)">Pascal</a> is the next generation of consumer graphics cards by Nvidia released in 2016. The <a href="/wiki/GeForce_10_series" title="GeForce 10 series">GeForce 10 series</a> of cards are under this generation of graphics cards. They are made using the 16 nm manufacturing process which improves upon previous microarchitectures.<sup class="reference" id="cite_ref-52"><a href="#cite_note-52">[52]</a></sup> Nvidia has released one non-consumer card under the new <a href="/wiki/Volta_(microarchitecture)" title="Volta (microarchitecture)">Volta</a> architecture, the Titan V. Changes from the Titan XP, Pascal\'s high-end card, include an increase in the number of CUDA cores, the addition of tensor cores, and <a href="/wiki/High_Bandwidth_Memory" title="High Bandwidth Memory">high-bandwidth memory</a>. Tensor cores are cores specially designed for deep learning, while high-bandwidth memory is on-die, stacked, lower-clocked memory that offers an extremely wide memory bus that is useful for the Titan V\'s intended purpose. To emphasize that the Titan V is not a gaming card, Nvidia removed the "Geforce GTX" suffix it adds to consumer gaming cards. A new generation, the RTX Turing GPUs were unveiled on August 20, 2018 that add ray-tracing cores to GPUs, improving their performance on lighting effects.<sup class="noprint Inline-Template Template-Fact" style="white-space:nowrap;">[<i><a href="/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources. (August 2018)">citation needed</span></a></i>]</sup> <a class="mw-redirect" href="/wiki/Polaris_11" title="Polaris 11">Polaris 11</a> and <a class="mw-redirect" href="/wiki/Polaris_10" title="Polaris 10">Polaris 10</a> GPUs from AMD are fabricated a 14-nanometer process. Their release results in a substantial increase in the performance per watt of AMD video cards.<sup class="reference" id="cite_ref-53"><a href="#cite_note-53">[53]</a></sup> AMD has also released for its high-end market the Vega GPUs, which also feature high-bandwidth memory like the Titan V.\n</p>, <p>Many companies have produced GPUs under a number of brand names. In 2009, <a class="mw-redirect" href="/wiki/Intel_Corporation" title="Intel Corporation">Intel</a>, <a href="/wiki/Nvidia" title="Nvidia">Nvidia</a> and <a href="/wiki/Advanced_Micro_Devices" title="Advanced Micro Devices">AMD</a>/<a href="/wiki/ATI_Technologies" title="ATI Technologies">ATI</a> were the market share leaders, with 49.4%, 27.8% and 20.6% market share respectively. However, those numbers include Intel\'s integrated graphics solutions as GPUs. Not counting those, <a href="/wiki/Nvidia" title="Nvidia">Nvidia</a> and <a href="/wiki/Advanced_Micro_Devices" title="Advanced Micro Devices">AMD</a> control nearly 100% of the market as of 2018. Their respective market shares are 66% and 33%. <sup class="reference" id="cite_ref-54"><a href="#cite_note-54">[54]</a></sup> In addition, <a href="/wiki/S3_Graphics" title="S3 Graphics">S3 Graphics</a><sup class="reference" id="cite_ref-55"><a href="#cite_note-55">[55]</a></sup> and <a href="/wiki/Matrox" title="Matrox">Matrox</a><sup class="reference" id="cite_ref-56"><a href="#cite_note-56">[56]</a></sup> produce GPUs.\nModern smartphones are also using mostly <a href="/wiki/Adreno" title="Adreno">Adreno</a> GPUs from <a href="/wiki/Qualcomm" title="Qualcomm">Qualcomm</a>, <a href="/wiki/PowerVR" title="PowerVR">PowerVR</a> GPUs from <a href="/wiki/Imagination_Technologies" title="Imagination Technologies">Imagination Technologies</a> and <a href="/wiki/Mali_(GPU)" title="Mali (GPU)">Mali GPUs</a> from <a class="mw-redirect" href="/wiki/ARM_Holdings" title="ARM Holdings">ARM</a>.\n</p>, <p>Modern GPUs use most of their <a href="/wiki/Transistor" title="Transistor">transistors</a> to do calculations related to <a href="/wiki/3D_computer_graphics" title="3D computer graphics">3D computer graphics</a>. In addition to the 3D hardware, today\'s GPUs include basic 2D acceleration and <a href="/wiki/Framebuffer" title="Framebuffer">framebuffer</a> capabilities (usually with a VGA compatibility mode). Newer cards like AMD/ATI HD5000-HD7000 even lack 2D acceleration; it has to be emulated by 3D hardware. GPUs were initially used to accelerate the memory-intensive work of <a href="/wiki/Texture_mapping" title="Texture mapping">texture mapping</a> and <a href="/wiki/Rendering_(computer_graphics)" title="Rendering (computer graphics)">rendering</a> polygons, later adding units to accelerate <a href="/wiki/Geometry" title="Geometry">geometric</a> calculations such as the <a href="/wiki/Rotation" title="Rotation">rotation</a> and <a href="/wiki/Translation_(geometry)" title="Translation (geometry)">translation</a> of <a href="/wiki/Vertex_(geometry)" title="Vertex (geometry)">vertices</a> into different <a href="/wiki/Coordinate_system" title="Coordinate system">coordinate systems</a>. Recent developments in GPUs include support for <a class="mw-redirect" href="/wiki/Programmable_shader" title="Programmable shader">programmable shaders</a> which can manipulate vertices and textures with many of the same operations supported by <a href="/wiki/Central_processing_unit" title="Central processing unit">CPUs</a>, <a href="/wiki/Oversampling" title="Oversampling">oversampling</a> and <a href="/wiki/Interpolation" title="Interpolation">interpolation</a> techniques to reduce <a href="/wiki/Aliasing" title="Aliasing">aliasing</a>, and very high-precision <a href="/wiki/Color_space" title="Color space">color spaces</a>. Because most of these computations involve <a href="/wiki/Matrix_(mathematics)" title="Matrix (mathematics)">matrix</a> and <a href="/wiki/Vector_calculus" title="Vector calculus">vector</a> operations, engineers and scientists have increasingly studied the use of GPUs for non-graphical calculations; they are especially suited to other <a href="/wiki/Embarrassingly_parallel" title="Embarrassingly parallel">embarrassingly parallel</a> problems.\n</p>, <p>With the emergence of deep learning, the importance of GPUs has increased. In research done by Indigo, it was found that while training deep learning neural networks, GPUs can be 250 times faster than CPUs. The explosive growth of Deep Learning in recent years has been attributed to the emergence of general purpose GPUs.<sup class="noprint Inline-Template Template-Fact" style="white-space:nowrap;">[<i><a href="/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources. (October 2017)">citation needed</span></a></i>]</sup> There has been some level of competition in this area with <a href="/wiki/Application-specific_integrated_circuit" title="Application-specific integrated circuit">ASICs</a>, most prominently the <a class="mw-redirect" href="/wiki/Tensor_Processing_Unit" title="Tensor Processing Unit">Tensor Processing Unit</a> (TPU) made by Google. However, these can require changes to existing code and GPUs are still very popular.\n</p>, <p>Most GPUs made since 1995 support the <a href="/wiki/YUV" title="YUV">YUV</a> <a href="/wiki/Color_space" title="Color space">color space</a> and <a href="/wiki/Hardware_overlay" title="Hardware overlay">hardware overlays</a>, important for <a href="/wiki/Digital_video" title="Digital video">digital video</a> playback, and many GPUs made since 2000 also support <a class="mw-redirect" href="/wiki/MPEG" title="MPEG">MPEG</a> primitives such as <a href="/wiki/Motion_compensation" title="Motion compensation">motion compensation</a> and <a class="mw-redirect" href="/wiki/Inverse_discrete_cosine_transform" title="Inverse discrete cosine transform">iDCT</a>. This process of hardware accelerated video decoding, where portions of the <a class="mw-redirect" href="/wiki/Video_decoding" title="Video decoding">video decoding</a> process and <a href="/wiki/Video_post-processing" title="Video post-processing">video post-processing</a> are offloaded to the GPU hardware, is commonly referred to as "GPU accelerated video decoding", "GPU assisted video decoding", "GPU hardware accelerated video decoding" or "GPU hardware assisted video decoding".\n</p>, <p>More recent graphics cards even decode <a href="/wiki/High-definition_video" title="High-definition video">high-definition video</a> on the card, offloading the central processing unit. The most common <a class="mw-redirect" href="/wiki/API" title="API">APIs</a> for GPU accelerated video decoding are <a href="/wiki/DirectX_Video_Acceleration" title="DirectX Video Acceleration">DxVA</a> for <a href="/wiki/Microsoft_Windows" title="Microsoft Windows">Microsoft Windows</a> operating system and <a href="/wiki/VDPAU" title="VDPAU">VDPAU</a>, <a class="mw-redirect" href="/wiki/VaAPI" title="VaAPI">VAAPI</a>, <a href="/wiki/X-Video_Motion_Compensation" title="X-Video Motion Compensation">XvMC</a>, and <a href="/wiki/X-Video_Bitstream_Acceleration" title="X-Video Bitstream Acceleration">XvBA</a> for Linux-based and UNIX-like operating systems. All except XvMC are capable of decoding videos encoded with <a href="/wiki/MPEG-1" title="MPEG-1">MPEG-1</a>, <a href="/wiki/MPEG-2" title="MPEG-2">MPEG-2</a>, <a href="/wiki/MPEG-4_Part_2" title="MPEG-4 Part 2">MPEG-4 ASP (MPEG-4 Part 2)</a>, <a class="mw-redirect" href="/wiki/MPEG-4_AVC" title="MPEG-4 AVC">MPEG-4 AVC</a> (H.264 / DivX 6), <a href="/wiki/VC-1" title="VC-1">VC-1</a>, <a class="mw-redirect" href="/wiki/WMV3" title="WMV3">WMV3</a>/<a class="mw-redirect" href="/wiki/WMV9" title="WMV9">WMV9</a>, <a href="/wiki/Xvid" title="Xvid">Xvid</a> / OpenDivX (DivX 4), and <a href="/wiki/DivX" title="DivX">DivX</a> 5 <a href="/wiki/Codec" title="Codec">codecs</a>, while XvMC is only capable of decoding MPEG-1 and MPEG-2.\n</p>, <p>The video decoding processes that can be accelerated by today\'s modern GPU hardware are:\n</p>, <p>In personal computers, there are two main forms of GPUs. Each has many synonyms:<sup class="reference" id="cite_ref-57"><a href="#cite_note-57">[57]</a></sup>\n</p>, <p>Most GPUs are designed for a specific usage, real-time 3D graphics or other mass calculations:\n</p>, <p>The GPUs of the most powerful class typically interface with the <a href="/wiki/Motherboard" title="Motherboard">motherboard</a> by means of an <a class="mw-redirect" href="/wiki/Expansion_slot" title="Expansion slot">expansion slot</a> such as <a href="/wiki/PCI_Express" title="PCI Express">PCI Express</a> (PCIe) or <a href="/wiki/Accelerated_Graphics_Port" title="Accelerated Graphics Port">Accelerated Graphics Port</a> (AGP) and can usually be replaced or upgraded with relative ease, assuming the motherboard is capable of supporting the upgrade. A few <a class="mw-redirect" href="/wiki/Graphics_cards" title="Graphics cards">graphics cards</a> still use <a class="mw-redirect" href="/wiki/Peripheral_Component_Interconnect" title="Peripheral Component Interconnect">Peripheral Component Interconnect</a> (PCI) slots, but their bandwidth is so limited that they are generally used only when a PCIe or AGP slot is not available.\n</p>, <p>A dedicated GPU is not necessarily removable, nor does it necessarily interface with the motherboard in a standard fashion. The term "dedicated" refers to the fact that dedicated graphics cards have <a class="mw-redirect" href="/wiki/RAM" title="RAM">RAM</a> that is dedicated to the card\'s use, not to the fact that <i>most</i> dedicated GPUs are removable. Further, this RAM is usually specially selected for the expected serial workload of the graphics card (see <a href="/wiki/GDDR_SDRAM" title="GDDR SDRAM">GDDR</a>). Sometimes, systems with dedicated, <i>discrete</i> GPUs were called "DIS" systems<sup class="reference" id="cite_ref-58"><a href="#cite_note-58">[58]</a></sup>, as opposed to "UMA" systems (see next section). Dedicated GPUs for portable computers are most commonly interfaced through a non-standard and often proprietary slot due to size and weight constraints. Such ports may still be considered PCIe or AGP in terms of their logical host interface, even if they are not physically interchangeable with their counterparts.\n</p>, <p>Technologies such as <a href="/wiki/Scalable_Link_Interface" title="Scalable Link Interface">SLI</a> by Nvidia and <a class="mw-redirect" href="/wiki/ATI_CrossFire" title="ATI CrossFire">CrossFire</a> by AMD allow multiple GPUs to draw images simultaneously for a single screen, increasing the processing power available for graphics.\n</p>, <p><i>Integrated graphics</i>, <i>shared graphics solutions</i>, <i>integrated graphics processors</i> (IGP) or <i>unified memory architecture</i> (UMA) utilize a portion of a computer\'s system RAM rather than dedicated graphics memory. IGPs can be integrated onto the motherboard as part of the chipset, or on the same die with the CPU (like <a class="mw-redirect" href="/wiki/AMD_APU" title="AMD APU">AMD APU</a> or <a class="mw-redirect" href="/wiki/Intel_HD_Graphics" title="Intel HD Graphics">Intel HD Graphics</a>). On certain motherboards <sup class="reference" id="cite_ref-59"><a href="#cite_note-59">[59]</a></sup> AMD\'s IGPs can use dedicated sideport memory. This is a separate fixed block of high performance memory that is dedicated for use by the GPU. In early 2007, computers with integrated graphics account for about 90% of all PC shipments.<sup class="reference" id="cite_ref-60"><a href="#cite_note-60">[60]</a></sup><sup class="noprint Inline-Template" style="white-space:nowrap;">[<i><a href="/wiki/Wikipedia:Manual_of_Style/Dates_and_numbers#Chronological_items" title="Wikipedia:Manual of Style/Dates and numbers"><span title="The date of the event predicted near this tag has passed. (February 2013)">needs update</span></a></i>]</sup> They are less costly to implement than dedicated graphics processing, but tend to be less capable. Historically, integrated processing was often considered unfit to play 3D games or run graphically intensive programs but could run less intensive programs such as Adobe Flash. Examples of such IGPs would be offerings from SiS and VIA circa 2004.<sup class="reference" id="cite_ref-61"><a href="#cite_note-61">[61]</a></sup> However, modern integrated graphics processors such as <a href="/wiki/AMD_Accelerated_Processing_Unit" title="AMD Accelerated Processing Unit">AMD Accelerated Processing Unit</a> and <a class="mw-redirect" href="/wiki/Intel_HD_Graphics" title="Intel HD Graphics">Intel HD Graphics</a> are more than capable of handling 2D graphics or low stress 3D graphics.\n</p>, <p>As a GPU is extremely memory intensive, integrated processing may find itself competing with the CPU for the relatively slow system RAM, as it has minimal or no dedicated video memory. IGPs can have up to 29.856 GB/s of memory bandwidth from system RAM, whereas a graphics card may have up to 264 GB/s of bandwidth between its <a class="mw-redirect" href="/wiki/RAM" title="RAM">RAM</a> and GPU core. This <a href="/wiki/Memory_bus" title="Memory bus">memory bus</a> bandwidth can limit the performance of the GPU.<sup class="noprint Inline-Template Template-Fact" style="white-space:nowrap;">[<i><a href="/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources. (March 2015)">citation needed</span></a></i>]</sup> Older integrated graphics chipsets lacked hardware <a href="/wiki/Transform,_clipping,_and_lighting" title="Transform, clipping, and lighting">transform and lighting</a>, but newer ones include it.<sup class="reference" id="cite_ref-62"><a href="#cite_note-62">[62]</a></sup><sup class="reference" id="cite_ref-63"><a href="#cite_note-63">[63]</a></sup>\n</p>, <p>This newer class of GPUs competes with integrated graphics in the low-end desktop and notebook markets. The most common implementations of this are ATI\'s <a href="/wiki/HyperMemory" title="HyperMemory">HyperMemory</a> and Nvidia\'s <a href="/wiki/TurboCache" title="TurboCache">TurboCache</a>.\n</p>, <p>Hybrid graphics cards are somewhat more expensive than integrated graphics, but much less expensive than dedicated graphics cards. These share memory with the system and have a small dedicated memory cache, to make up for the high <a href="/wiki/Memory_latency" title="Memory latency">latency</a> of the system RAM. Technologies within PCI Express can make this possible. While these solutions are sometimes advertised as having as much as 768MB of RAM, this refers to how much can be shared with the system memory.\n</p>, <p>It is becoming increasingly common to use a <a class="mw-redirect" href="/wiki/GPGPU" title="GPGPU">general purpose graphics processing unit (GPGPU)</a> as a modified form of <a href="/wiki/Stream_processing" title="Stream processing">stream processor</a> (or a <a href="/wiki/Vector_processor" title="Vector processor">vector processor</a>), running <a href="/wiki/Compute_kernel" title="Compute kernel">compute kernels</a>. This concept turns the massive computational power of a modern graphics accelerator\'s shader pipeline into general-purpose computing power, as opposed to being hard wired solely to do graphical operations. In certain applications requiring massive vector operations, this can yield several orders of magnitude higher performance than a conventional CPU. The two largest discrete (see "<a href="#Dedicated_graphics_cards">Dedicated graphics cards</a>" above) GPU designers, <a class="mw-redirect" href="/wiki/AMD" title="AMD">AMD</a> and <a href="/wiki/Nvidia" title="Nvidia">Nvidia</a>, are beginning to pursue this approach with an array of applications. Both Nvidia and AMD have teamed with <a href="/wiki/Stanford_University" title="Stanford University">Stanford University</a> to create a GPU-based client for the <a href="/wiki/Folding@home" title="Folding@home">Folding@home</a> distributed computing project, for protein folding calculations. In certain circumstances the GPU calculates forty times faster than the conventional CPUs traditionally used by such applications.<sup class="reference" id="cite_ref-64"><a href="#cite_note-64">[64]</a></sup><sup class="reference" id="cite_ref-65"><a href="#cite_note-65">[65]</a></sup>\n</p>, <p>GPGPU can be used for many types of <a href="/wiki/Embarrassingly_parallel" title="Embarrassingly parallel">embarrassingly parallel</a> tasks including <a href="/wiki/Ray_tracing_(graphics)" title="Ray tracing (graphics)">ray tracing</a>. They are generally suited to high-throughput type computations that exhibit <a class="mw-redirect" href="/wiki/Data-parallelism" title="Data-parallelism">data-parallelism</a> to exploit the wide vector width <a href="/wiki/SIMD" title="SIMD">SIMD</a> architecture of the GPU.\n</p>, <p>Furthermore, GPU-based high performance computers are starting to play a significant role in large-scale modelling. Three of the 10 most powerful supercomputers in the world take advantage of GPU acceleration.<sup class="reference" id="cite_ref-66"><a href="#cite_note-66">[66]</a></sup>\n</p>, <p>GPU supports API extensions to the <a href="/wiki/C_(programming_language)" title="C (programming language)">C</a> programming language such as <a href="/wiki/OpenCL" title="OpenCL">OpenCL</a> and <a href="/wiki/OpenMP" title="OpenMP">OpenMP</a>. Furthermore, each GPU vendor introduced its own API which only works with their cards, <a href="/wiki/AMD_APP_SDK" title="AMD APP SDK">AMD APP SDK</a> and <a href="/wiki/CUDA" title="CUDA">CUDA</a> from AMD and Nvidia, respectively. These technologies allow specified functions called <a href="/wiki/Compute_kernel" title="Compute kernel">compute kernels</a> from a normal C program to run on the GPU\'s stream processors. This makes it possible for C programs to take advantage of a GPU\'s ability to operate on large buffers in parallel, while still using the CPU when appropriate. CUDA is also the first API to allow CPU-based applications to directly access the resources of a GPU for more general purpose computing without the limitations of using a graphics API.<sup class="noprint Inline-Template Template-Fact" style="white-space:nowrap;">[<i><a href="/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="CUDA as first API (August 2017)">citation needed</span></a></i>]</sup>\n</p>, <p>Since 2005 there has been interest in using the performance offered by GPUs for <a href="/wiki/Evolutionary_computation" title="Evolutionary computation">evolutionary computation</a> in general, and for accelerating the <a class="mw-redirect" href="/wiki/Fitness_(genetic_algorithm)" title="Fitness (genetic algorithm)">fitness</a> evaluation in <a href="/wiki/Genetic_programming" title="Genetic programming">genetic programming</a> in particular. Most approaches compile <a href="/wiki/Linear_genetic_programming" title="Linear genetic programming">linear</a> or <a href="/wiki/Genetic_programming" title="Genetic programming">tree programs</a> on the host PC and transfer the executable to the GPU to be run. Typically the performance advantage is only obtained by running the single active program simultaneously on many example problems in parallel, using the GPU\'s <a href="/wiki/SIMD" title="SIMD">SIMD</a> architecture.<sup class="reference" id="cite_ref-67"><a href="#cite_note-67">[67]</a></sup><sup class="reference" id="cite_ref-68"><a href="#cite_note-68">[68]</a></sup> However, substantial acceleration can also be obtained by not compiling the programs, and instead transferring them to the GPU, to be interpreted there.<sup class="reference" id="cite_ref-69"><a href="#cite_note-69">[69]</a></sup><sup class="reference" id="cite_ref-70"><a href="#cite_note-70">[70]</a></sup> Acceleration can then be obtained by either interpreting multiple programs simultaneously, simultaneously running multiple example problems, or combinations of both. A modern GPU can readily simultaneously interpret hundreds of thousands of very small programs.\n</p>, <p>Some modern workstation GPUs, such as the Nvidia Quadro workstation cards using the Volta and Turing architectures, feature dedicating processing cores for tensor-based deep learning applications. In Nvidia\'s current series of GPUs these cores are called Tensor Cores<sup class="reference" id="cite_ref-71"><a href="#cite_note-71">[71]</a></sup> These GPUs usually have significant FLOPS performance increases, utilizing 4x4 matrix multiplication and division, resulting in hardware performance up to 128 TFLOPS in some applications.<sup class="reference" id="cite_ref-72"><a href="#cite_note-72">[72]</a></sup> These tensor cores are also supposed to appear in consumer cards running the Turing architecture, and possibly in the Navi series of consumer cards from AMD.<sup class="reference" id="cite_ref-73"><a href="#cite_note-73">[73]</a></sup>\n</p>, <p>An external GPU is a graphics processor located outside of the housing of the computer. External graphics processors are sometimes used with laptop computers. Laptops might have a substantial amount of RAM and a sufficiently powerful central processing unit (CPU), but often lack a powerful graphics processor, and instead have a less powerful but more energy-efficient on-board graphics chip. On-board graphics chips are often not powerful enough for playing the latest games, or for other graphically intensive tasks, such as editing video.\n</p>, <p>Therefore, it is desirable to be able to attach a GPU to some external bus of a notebook. <a href="/wiki/PCI_Express" title="PCI Express">PCI Express</a> is the only bus commonly used for this purpose. The port may be, for example, an <a href="/wiki/ExpressCard" title="ExpressCard">ExpressCard</a> or <a href="/wiki/PCI_Express#PCI_Express_Mini_Card" title="PCI Express">mPCIe</a> port (PCIe \xc3\x971, up to 5 or 2.5 Gbit/s respectively) or a <a href="/wiki/Thunderbolt_(interface)" title="Thunderbolt (interface)">Thunderbolt</a> 1, 2, or 3 port (PCIe \xc3\x974, up to 10, 20, or 40 Gbit/s respectively). Those ports are only available on certain notebook systems.<sup class="reference" id="cite_ref-74"><a href="#cite_note-74">[74]</a></sup><sup class="reference" id="cite_ref-75"><a href="#cite_note-75">[75]</a></sup>\n</p>, <p>Official vendor support for External GPUs has gained traction recently.  One notable milestone was Apple\xe2\x80\x99s decision to officially support External GPUs with mac OS High Sierra 10.13.4.<sup class="reference" id="cite_ref-76"><a href="#cite_note-76">[76]</a></sup>  There are also several major hardware vendors (HP, Alienware, Razer) releasing TB3 eGPU enclosures.<sup class="reference" id="cite_ref-77"><a href="#cite_note-77">[77]</a></sup> <sup class="reference" id="cite_ref-78"><a href="#cite_note-78">[78]</a></sup> <sup class="reference" id="cite_ref-79"><a href="#cite_note-79">[79]</a></sup> This support has continued to fuel eGPU implementations by enthusiasts.<sup class="reference" id="cite_ref-80"><a href="#cite_note-80">[80]</a></sup>\n</p>, <p>In 2013, 438.3 million GPUs were shipped globally and the forecast for 2014 was 414.2 million.<sup class="reference" id="cite_ref-81"><a href="#cite_note-81">[81]</a></sup>\n</p>]