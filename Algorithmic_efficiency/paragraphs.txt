\nIncomputerscience,algorithmicefficiencyisapropertyofanalgorithmwhichrelatestothenumberofcomputationalresourcesusedbythealgorithm.Analgorithmmustbeanalyzedtodetermineitsresourceusage,andtheefficiencyofanalgorithmcanbemeasuredbasedonusageofdifferentresources.Algorithmicefficiencycanbethoughtofasanalogoustoengineeringproductivityforarepeatingorcontinuousprocess.\nFormaximumefficiencywewishtominimizeresourceusage.However,differentresourcessuchastimeandspacecomplexitycannotbecompareddirectly,sowhichoftwoalgorithmsisconsideredtobemoreefficientoftendependsonwhichmeasureofefficiencyisconsideredmostimportant.\nForexample,bubblesortandtimsortarebothalgorithmstosortalistofitemsfromsmallesttolargest.Bubblesortsortsthelistintimeproportionaltothenumberofelementssquared(\n\n\n\n\n\n\n\nO\n\n\n\n(\n\nn\n\n2\n\n\n)\n\n\n\n\n\n{\\displaystyle\\scriptstyle{{\\mathcal{O}}\\left(n^{2}\\right)}}\n\n,seeBigOnotation),butonlyrequiresasmallamountofextramemorywhichisconstantwithrespecttothelengthofthelist(\n\n\n\n\n\n\n\nO\n\n\n\n(\n1\n)\n\n\n\n\n\n{\\textstyle\\scriptstyle{{\\mathcal{O}}\\left(1\\right)}}\n\n).Timsortsortsthelistintimelinearithmic(proportionaltoaquantitytimesitslogarithm)inthelist\'slength(\n\n\n\n\n\n\nO\n\n(\n\nn\nlog\n‚Å°\nn\n\n)\n\n\n\n\n\n\n{\\textstyle\\scriptstyle{\\mathcal{O\\left(n\\logn\\right)}}}\n\n),buthasaspacerequirementlinearinthelengthofthelist(\n\n\n\n\n\n\nO\n\n(\nn\n)\n\n\n\n\n\n\n{\\textstyle\\scriptstyle{\\mathcal{O\\left(n\\right)}}}\n\n).Iflargelistsmustbesortedathighspeedforagivenapplication,timsortisabetterchoice;however,ifminimizingthememoryfootprintofthesortingismoreimportant,bubblesortisabetterchoice.\nTheimportanceofefficiencywithrespecttotimewasemphasisedbyAdaLovelacein1843asapplyingtoCharlesBabbage\'smechanicalanalyticalengine:\n"Inalmosteverycomputationagreatvarietyofarrangementsforthesuccessionoftheprocessesispossible,andvariousconsiderationsmustinfluencetheselectionsamongstthemforthepurposesofacalculatingengine.Oneessentialobjectistochoosethatarrangementwhichshalltendtoreducetoaminimumthetimenecessaryforcompletingthecalculation"[1]Earlyelectroniccomputerswereseverelylimitedbothbythespeedofoperationsandtheamountofmemoryavailable.Insomecasesitwasrealizedthattherewasaspace\xe2\x80\x93timetrade-off,wherebyataskcouldbehandledeitherbyusingafastalgorithmwhichusedquitealotofworkingmemory,orbyusingasloweralgorithmwhichusedverylittleworkingmemory.Theengineeringtrade-offwasthentousethefastestalgorithmwhichwouldfitintheavailablememory.\nModerncomputersaresignificantlyfasterthantheearlycomputers,andhaveamuchlargeramountofmemoryavailable(GigabytesinsteadofKilobytes).Nevertheless,DonaldKnuthemphasisedthatefficiencyisstillanimportantconsideration:\n"Inestablishedengineeringdisciplinesa12%improvement,easilyobtained,isneverconsideredmarginalandIbelievethesameviewpointshouldprevailinsoftwareengineering"[2]Analgorithmisconsideredefficientifitsresourceconsumption,alsoknownascomputationalcost,isatorbelowsomeacceptablelevel.Roughlyspeaking,\'acceptable\'means:itwillruninareasonableamountoftimeorspaceonanavailablecomputer,typicallyasafunctionofthesizeoftheinput.Sincethe1950scomputershaveseendramaticincreasesinboththeavailablecomputationalpowerandintheavailableamountofmemory,socurrentacceptablelevelswouldhavebeenunacceptableeven10yearsago.Infact,thankstotheapproximatedoublingofcomputerpowerever2years,tasksthatareacceptablyefficientonmodernsmartphonesandembeddedsystemsmayhavebeenunacceptablyinefficientforindustrialservers10yearsago.\nComputermanufacturersfrequentlybringoutnewmodels,oftenwithhigherperformance.Softwarecostscanbequitehigh,soinsomecasesthesimplestandcheapestwayofgettinghigherperformancemightbetojustbuyafastercomputer,provideditiscompatiblewithanexistingcomputer.\nTherearemanywaysinwhichtheresourcesusedbyanalgorithmcanbemeasured:thetwomostcommonmeasuresarespeedandmemoryusage;othermeasurescouldincludetransmissionspeed,temporarydiskusage,long-termdiskusage,powerconsumption,totalcostofownership,responsetimetoexternalstimuli,etc.Manyofthesemeasuresdependonthesizeoftheinputtothealgorithm,i.e.theamountofdatatobeprocessed.Theymightalsodependonthewayinwhichthedataisarranged;forexample,somesortingalgorithmsperformpoorlyondatawhichisalreadysorted,orwhichissortedinreverseorder.\nInpractice,thereareotherfactorswhichcanaffecttheefficiencyofanalgorithm,suchasrequirementsforaccuracyand/orreliability.Asdetailedbelow,thewayinwhichanalgorithmisimplementedcanalsohaveasignificanteffectonactualefficiency,thoughmanyaspectsofthisrelatetooptimizationissues.\nInthetheoreticalanalysisofalgorithms,thenormalpracticeistoestimatetheircomplexityintheasymptoticsense.Themostcommonlyusednotationtodescriberesourceconsumptionor"complexity"isDonaldKnuth\'sBigOnotation,representingthecomplexityofanalgorithmasafunctionofthesizeoftheinput\n\n\n\n\nn\n\n\n\n{\\textstyle\\scriptstylen}\n\n.BigOnotationisanasymptoticmeasureoffunctioncomplexity,where\n\n\n\n\n\nf\n\n(\nn\n)\n\n\n=\n\n\n\nO\n\n\n\n(\n\ng\n\n(\nn\n)\n\n\n)\n\n\n\n\n\n{\\textstyle\\scriptstyle{f\\left(n\\right)\\,=\\,{\\mathcal{O}}\\left(g\\left(n\\right)\\right)}}\n\nroughlymeansthetimerequirementforanalgorithmisproportionalto\n\n\n\n\n\ng\n\n(\nn\n)\n\n\n\n\n\n{\\displaystyle\\scriptstyle{g\\left(n\\right)}}\n\n,omittinglower-ordertermsthatcontributelessthan\n\n\n\n\n\ng\n\n(\nn\n)\n\n\n\n\n\n{\\displaystyle\\scriptstyle{g\\left(n\\right)}}\n\ntothegrowthofthefunctionas\n\n\n\n\nn\n\n\n\n{\\displaystyle\\scriptstylen}\n\ngrowsarbitrarilylarge.Thisestimatemaybemisleadingwhen\n\n\n\n\nn\n\n\n\n{\\textstyle\\scriptstylen}\n\nissmall,butisgenerallysufficientlyaccuratewhen\n\n\n\n\nn\n\n\n\n{\\textstyle\\scriptstylen}\n\nislargeasthenotationisasymptotic.Forexample,bubblesortmaybefasterthanmergesortwhenonlyafewitemsaretobesorted;howevereitherimplementationislikelytomeetperformancerequirementsforasmalllist.Typically,programmersareinterestedinalgorithmsthatscaleefficientlytolargeinputsizes,andmergesortispreferredoverbubblesortforlistsoflengthencounteredinmostdata-intensiveprograms.\nSomeexamplesofBigOnotationappliedtoalgorithms\'asymptotictimecomplexityinclude:\nFornewversionsofsoftwareortoprovidecomparisonswithcompetitivesystems,benchmarksaresometimesused,whichassistwithgauginganalgorithmsrelativeperformance.Ifanewsortalgorithmisproduced,forexample,itcanbecomparedwithitspredecessorstoensurethatatleastitisefficientasbeforewithknowndata,takingintoconsiderationanyfunctionalimprovements.Benchmarkscanbeusedbycustomerswhencomparingvariousproductsfromalternativesupplierstoestimatewhichproductwillbestsuittheirspecificrequirementsintermsoffunctionalityandperformance.Forexample,inthemainframeworldcertainproprietarysortproductsfromindependentsoftwarecompaniessuchasSyncsortcompetewithproductsfromthemajorsupplierssuchasIBMforspeed.\nSomebenchmarksprovideopportunitiesforproducingananalysiscomparingtherelativespeedofvariouscompiledandinterpretedlanguagesforexample[3][4]\nandTheComputerLanguageBenchmarksGamecomparestheperformanceofimplementationsoftypicalprogrammingproblemsinseveralprogramminglanguages.\nEvencreating"doityourself"benchmarkscandemonstratetherelativeperformanceofdifferentprogramminglanguages,usingavarietyofuserspecifiedcriteria.Thisisquitesimple,asa"Ninelanguageperformanceroundup"byChristopherW.Cowell-Shahdemonstratesbyexample.[5]\nImplementationissuescanalsohaveaneffectonefficiency,suchasthechoiceofprogramminglanguage,orthewayinwhichthealgorithmisactuallycoded,[6]orthechoiceofacompilerforaparticularlanguage,orthecompilationoptionsused,oreventheoperatingsystembeingused.Inmanycasesalanguageimplementedbyaninterpretermaybemuchslowerthanalanguageimplementedbyacompiler.[3]Seethearticlesonjust-in-timecompilationandinterpretedlanguages.\nThereareotherfactorswhichmayaffecttimeorspaceissues,butwhichmaybeoutsideofaprogrammer\'scontrol;theseincludedataalignment,datagranularity,cachelocality,cachecoherency,garbagecollection,instruction-levelparallelism,multi-threading(ateitherahardwareorsoftwarelevel),simultaneousmultitasking,andsubroutinecalls.[7]\nSomeprocessorshavecapabilitiesforvectorprocessing,whichallowasingleinstructiontooperateonmultipleoperands;itmayormaynotbeeasyforaprogrammerorcompilertousethesecapabilities.Algorithmsdesignedforsequentialprocessingmayneedtobecompletelyredesignedtomakeuseofparallelprocessing,ortheycouldbeeasilyreconfigured.Asparallelanddistributedcomputinggrowinimportanceinthelate2010\'s,moreinvestmentsarebeingmadeintoefficienthigh-levelApplicationprogramminginterfacesforparallelanddistributedcomputingsystemssuchasCUDA,TensorFlow,Hadoop,OpenMPandMPI.\nAnotherproblemwhichcanariseinprogrammingisthatprocessorscompatiblewiththesameinstructionset(suchasx86-64orARM)mayimplementaninstructionindifferentways,sothatinstructionswhicharerelativelyfastonsomemodelsmayberelativelyslowonothermodels.Thisoftenpresentschallengestooptimizingcompilers,whichmusthaveagreatamountofknowledgeofthespecificCPUandotherhardwareavailableonthecompilationtargettobestoptimizeaprogramforperformance.Intheextremecase,acompilermaybeforcedtoemulateinstructionsnotsupportedonacompilationtargetplatform,forcingittogeneratecodeorlinkanexternallibrarycalltoproducearesultthatisotherwiseincomputableonthatplatform,evenifitisnativelysupportedandmoreefficientinhardwareonotherplatforms.Thisisoftenthecaseinembeddedsystemswithrespecttofloating-pointarithmetic,wheresmallandlow-powermicrocontrollersoftenlackhardwaresupportforfloating-pointarithmeticandthusrequirecomputationallyexpensivesoftwareroutinestoproducefloatingpointcalculations.\nMeasuresarenormallyexpressedasafunctionofthesizeoftheinput\n\n\n\n\n\nn\n\n\n\n\n{\\displaystyle\\scriptstyle{n}}\n\n.\nThetwomostcommonmeasuresare:\nForcomputerswhosepowerissuppliedbyabattery(e.g.laptopsandsmartphones),orforverylong/largecalculations(e.g.supercomputers),othermeasuresofinterestare:\nAsof2018[update],powerconsumptionisgrowingasanimportantmetricforcomputationaltasksofalltypesandatallscalesrangingfromembeddedInternetofthingsdevicestosystem-on-chipdevicestoserverfarms.Thistrendisoftenreferredtoasgreencomputing.\nLesscommonmeasuresofcomputationalefficiencymayalsoberelevantinsomecases:\nAnalyzethealgorithm,typicallyusingtimecomplexityanalysistogetanestimateoftherunningtimeasafunctionofthesizeoftheinputdata.TheresultisnormallyexpressedusingBigOnotation.Thisisusefulforcomparingalgorithms,especiallywhenalargeamountofdataistobeprocessed.Moredetailedestimatesareneededtocomparealgorithmperformancewhentheamountofdataissmall,althoughthisislikelytobeoflessimportance.Algorithmswhichincludeparallelprocessingmaybemoredifficulttoanalyze.\nUseabenchmarktotimetheuseofanalgorithm.ManyprogramminglanguageshaveanavailablefunctionwhichprovidesCPUtimeusage.Forlong-runningalgorithmstheelapsedtimecouldalsobeofinterest.Resultsshouldgenerallybeaveragedoverseveraltests.\nRun-basedprofilingcanbeverysensitivetohardwareconfigurationandthepossibilityofotherprogramsortasksrunningatthesametimeinamulti-processingandmulti-programmingenvironment.\nThissortoftestalsodependsheavilyontheselectionofaparticularprogramminglanguage,compiler,andcompileroptions,soalgorithmsbeingcomparedmustallbeimplementedunderthesameconditions.\nThissectionisconcernedwiththeuseofmemoryresources(registers,cache,RAM,virtualmemory,secondarymemory)whilethealgorithmisbeingexecuted.Asfortimeanalysisabove,analyzethealgorithm,typicallyusingspacecomplexityanalysistogetanestimateoftherun-timememoryneededasafunctionasthesizeoftheinputdata.TheresultisnormallyexpressedusingBigOnotation.\nThereareuptofouraspectsofmemoryusagetoconsider:\nEarlyelectroniccomputers,andearlyhomecomputers,hadrelativelysmallamountsofworkingmemory.Forexample,the1949ElectronicDelayStorageAutomaticCalculator(EDSAC)hadamaximumworkingmemoryof102417-bitwords,whilethe1980SinclairZX80cameinitiallywith10248-bitbytesofworkingmemory.Inthelate2010s,itistypicalforpersonalcomputerstohavebetween4and32GBofRAM,anincreaseofover300milliontimesasmuchmemory.\nCurrentcomputerscanhaverelativelylargeamountsofmemory(possiblyGigabytes),sohavingtosqueezeanalgorithmintoaconfinedamountofmemoryismuchlessofaproblemthanitusedtobe.Butthepresenceoffourdifferentcategoriesofmemorycanbesignificant:\nAnalgorithmwhosememoryneedswillfitincachememorywillbemuchfasterthananalgorithmwhichfitsinmainmemory,whichinturnwillbeverymuchfasterthananalgorithmwhichhastoresorttovirtualmemory.Becauseofthis,cachereplacementpoliciesareextremelyimportanttohigh-performancecomputing,asarecache-awareprogramminganddataalignment.Tofurthercomplicatetheissue,somesystemshaveuptothreelevelsofcachememory,withvaryingeffectivespeeds.Differentsystemswillhavedifferentamountsofthesevarioustypesofmemory,sotheeffectofalgorithmmemoryneedscanvarygreatlyfromonesystemtoanother.\nIntheearlydaysofelectroniccomputing,ifanalgorithmanditsdatawouldn\'tfitinmainmemorythenthealgorithmcouldn\'tbeused.Nowadaystheuseofvirtualmemoryappearstoprovidelotsofmemory,butatthecostofperformance.Ifanalgorithmanditsdatawillfitincachememory,thenveryhighspeedcanbeobtained;inthiscaseminimizingspacewillalsohelpminimizetime.Thisiscalledtheprincipleoflocality,andcanbesubdividedintolocalityofreference,spatiallocalityandtemporallocality.Analgorithmwhichwillnotfitcompletelyincachememorybutwhichexhibitslocalityofreferencemayperformreasonablywell.\nSoftwareefficiencyhalvesevery18months,compensatingMoore\'sLaw\nInubiquitoussystems,halvingtheinstructionsexecutedcandoublethebatterylifeandbigdatasetsbringbigopportunitiesforbettersoftwareandalgorithms:ReducingthenumberofoperationsfromNxNtoNxlog(N)hasadramaticeffectwhenNislarge...forN=30billion,thischangeisasgoodas50yearsoftechnologyimprovements.\nThefollowingcompetitionsinviteentriesforthebestalgorithmsbasedonsomearbitrarycriteriadecidedbythejudges:\n