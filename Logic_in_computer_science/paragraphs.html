[<p><b>Logic in computer science</b> covers the overlap between the field of <a href="/wiki/Logic" title="Logic">logic</a> and that of <a href="/wiki/Computer_science" title="Computer science">computer science</a>. The topic can essentially be divided into three main areas:\n</p>, <p>Logic plays a fundamental role in computer science.  Some of the key areas of logic that are particularly significant are <a href="/wiki/Computability_theory" title="Computability theory">computability theory</a> (formerly called recursion theory), <a href="/wiki/Modal_logic" title="Modal logic">modal logic</a> and <a href="/wiki/Category_theory" title="Category theory">category theory</a>. The <a href="/wiki/Theory_of_computation" title="Theory of computation">theory of computation</a> is based on concepts defined by logicians and mathematicians such as <a href="/wiki/Alonzo_Church" title="Alonzo Church">Alonzo Church</a> and <a href="/wiki/Alan_Turing" title="Alan Turing">Alan Turing</a>.<sup class="reference" id="cite_ref-1"><a href="#cite_note-1">[1]</a></sup><sup class="reference" id="cite_ref-2"><a href="#cite_note-2">[2]</a></sup>  Church first showed the existence of algorithmically unsolvable problems using his notion of lambda-definability.  Turing gave the first compelling analysis of what can be called a mechanical procedure and <a href="/wiki/Kurt_G%C3%B6del" title="Kurt G\xc3\xb6del">Kurt G\xc3\xb6del</a> asserted that he found Turing\'s analysis "perfect."<sup class="reference" id="cite_ref-3"><a href="#cite_note-3">[3]</a></sup>\nIn addition some other major areas of theoretical overlap between logic and computer science are:\n</p>, <p>One of the first applications to use the term <a class="mw-redirect" href="/wiki/Artificial_Intelligence" title="Artificial Intelligence">Artificial Intelligence</a> was the Logic Theorist system developed by <a href="/wiki/Allen_Newell" title="Allen Newell">Allen Newell</a>, J.C. Shaw, and <a href="/wiki/Herbert_A._Simon" title="Herbert A. Simon">Herbert Simon</a> in 1956. One of the things that a logician does is to take a set of statements in logic and deduce the conclusions (additional statements) that must be true by the laws of logic. For example, If given a logical system that states "All humans are mortal" and "Socrates is human" a valid conclusion is "Socrates is mortal".  Of course this is a trivial example. In actual logical systems the statements can be numerous and complex. It was realized early on that this kind of analysis could be significantly aided by the use of computers. The Logic Theorist validated the theoretical work of <a href="/wiki/Bertrand_Russell" title="Bertrand Russell">Bertrand Russell</a> and <a href="/wiki/Alfred_North_Whitehead" title="Alfred North Whitehead">Alfred North Whitehead</a> in their influential work on mathematical logic called <a href="/wiki/Principia_Mathematica" title="Principia Mathematica">Principia Mathematica</a>. In addition, subsequent systems have been utilized by logicians to validate and discover new logical theorems and proofs.<sup class="reference" id="cite_ref-7"><a href="#cite_note-7">[7]</a></sup>\n</p>, <p>There has always been a strong influence from mathematical logic on the field of <a class="mw-redirect" href="/wiki/Artificial_Intelligence" title="Artificial Intelligence">Artificial Intelligence (AI)</a>. From the beginning of the field it was realized that technology to automate logical inferences could have great potential to solve problems and draw conclusions from facts. Ron Brachman has described <a href="/wiki/First-order_logic" title="First-order logic">first-order logic</a> (FOL) as the metric by which all AI knowledge representation formalisms should be evaluated. There is no more general or powerful known method for describing and analyzing information than FOL. The reason FOL itself is simply not used as a computer language is that it is actually too expressive, in the sense that FOL can easily express statements that no computer, no matter how powerful, could ever solve. For this reason every form of knowledge representation is in some sense a trade off between expressivity and computability. The more expressive the language is, the closer it is to FOL, the more likely it is to be slower and prone to an infinite loop.<sup class="reference" id="cite_ref-8"><a href="#cite_note-8">[8]</a></sup>\n</p>, <p>For example, IF THEN rules used in <a href="/wiki/Expert_system" title="Expert system">Expert Systems</a> approximate to a very limited subset of FOL. Rather than arbitrary formulas with the full range of logical operators the starting point is simply what logicians refer to as <a class="mw-redirect" href="/wiki/Modus_Ponens" title="Modus Ponens">Modus Ponens</a>. As a result, <a href="/wiki/Rule-based_system" title="Rule-based system">rule based systems</a> can support high-performance computation, especially if they take advantage of optimization algorithms and compilation.<sup class="reference" id="cite_ref-9"><a href="#cite_note-9">[9]</a></sup>\n</p>, <p>Another major area of research for logical theory was software engineering. Research projects such as the <a href="/wiki/Knowledge_Based_Software_Assistant" title="Knowledge Based Software Assistant">Knowledge-Based Software Assistant</a> and Programmer\'s Apprentice programs applied logical theory to validate the correctness of software specifications. They also used them to transform the specifications into efficient code on diverse platforms and to prove the equivalence between the implementation and the specification.<sup class="reference" id="cite_ref-10"><a href="#cite_note-10">[10]</a></sup>  This formal transformation driven approach is often far more effort than traditional software development. However, in specific domains with appropriate formalisms and reusable templates the approach has proven viable for commercial products. The appropriate domains are usually those such as weapons systems, security systems, and real time financial systems where failure of the system has excessively high human or financial cost. An example of such a domain is <a class="mw-redirect" href="/wiki/Very-large-scale_integration" title="Very-large-scale integration">Very Large Scale Integrated (VLSI) Design</a>\xe2\x80\x94the process for designing the chips used for the CPU\'s and other critical components of digital devices. An error in a chip is catastrophic. Unlike software, chips can\'t be patched or updated. As a result, there is commercial justification for using formal methods to prove that the implementation corresponds to the specification.<sup class="reference" id="cite_ref-11"><a href="#cite_note-11">[11]</a></sup>\n</p>, <p>Another important application of logic to computer technology has been in the area of <a href="/wiki/Frame_language" title="Frame language">frame languages</a> and automatic classifiers. <a href="/wiki/Frame_language" title="Frame language">Frame languages</a> such ais <a href="/wiki/KL-ONE" title="KL-ONE">KL-ONE</a> have a rigid semantics. Definitions in KL-ONE can be directly mapped to set theory and the predicate calculus. This allows specialized theorem provers called classifiers to analyze the various declarations between sets, subsets, and relations in a given model. In this way the model can be validated and any inconsistent definitions flagged. The classifier can also infer new information, for example define new sets based on existing information and change the definition of existing sets based on new data. The level of flexibility is ideal for handling the ever changing world of the Internet. Classifier technology is built on top of languages such as the <a href="/wiki/Web_Ontology_Language" title="Web Ontology Language">Web Ontology Language</a> to allow a logical semantic level on to the existing Internet. This layer of is called the <a class="mw-redirect" href="/wiki/Semantic_web" title="Semantic web">Semantic web</a>.<sup class="reference" id="cite_ref-12"><a href="#cite_note-12">[12]</a></sup><sup class="reference" id="cite_ref-13"><a href="#cite_note-13">[13]</a></sup>\n</p>, <p><a href="/wiki/Temporal_logic" title="Temporal logic">Temporal logic</a> is used for reasoning in <a class="mw-redirect" href="/wiki/Concurrency_(computing)" title="Concurrency (computing)">concurrent systems</a>.<sup class="reference" id="cite_ref-14"><a href="#cite_note-14">[14]</a></sup>\n</p>]