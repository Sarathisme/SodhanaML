Machinelearning(ML)isthestudyofalgorithmsandmathematicalmodelsthatcomputersystemsusetoprogressivelyimprovetheirperformanceonaspecifictask.Machinelearningalgorithmsbuildamathematicalmodelofsampledata,knownas"trainingdata",inordertomakepredictionsordecisionswithoutbeingexplicitlyprogrammedtoperformthetask.[1][2]:2Machinelearningalgorithmsareusedintheapplicationsofemailfiltering,detectionofnetworkintruders,andcomputervision,whereitisinfeasibletodevelopanalgorithmofspecificinstructionsforperformingthetask.Machinelearningiscloselyrelatedtocomputationalstatistics,whichfocusesonmakingpredictionsusingcomputers.Thestudyofmathematicaloptimizationdeliversmethods,theoryandapplicationdomainstothefieldofmachinelearning.Dataminingisafieldofstudywithinmachinelearning,andfocusesonexploratorydataanalysisthroughunsupervisedlearning.[3][4]Initsapplicationacrossbusinessproblems,machinelearningisalsoreferredtoaspredictiveanalytics.\nThenamemachinelearningwascoinedin1959byArthurSamuel.[5]TomM.Mitchellprovidedawidelyquoted,moreformaldefinitionofthealgorithmsstudiedinthemachinelearningfield:"AcomputerprogramissaidtolearnfromexperienceEwithrespecttosomeclassoftasksTandperformancemeasurePifitsperformanceattasksinT,asmeasuredbyP,improveswithexperienceE."[6]Thisdefinitionofthetasksinwhichmachinelearningisconcernedoffersafundamentallyoperationaldefinitionratherthandefiningthefieldincognitiveterms.ThisfollowsAlanTuring\'sproposalinhispaper"ComputingMachineryandIntelligence",inwhichthequestion"Canmachinesthink?"isreplacedwiththequestion"Canmachinesdowhatwe(asthinkingentities)cando?".[7]InTuring\'sproposalthevariouscharacteristicsthatcouldbepossessedbyathinkingmachineandthevariousimplicationsinconstructingoneareexposed.\n\nMachinelearningtasksareclassifiedintoseveralbroadcategories.Insupervisedlearning,thealgorithmbuildsamathematicalmodelofasetofdatathatcontainsboththeinputsandthedesiredoutputs.Forexample,ifthetaskweredeterminingwhetheranimagecontainedacertainobject,thetrainingdataforasupervisedlearningalgorithmwouldincludeimageswithandwithoutthatobject(theinput),andeachimagewouldhavealabel(theoutput)designatingwhetheritcontainedtheobject.Inspecialcases,theinputmaybeonlypartiallyavailable,orrestrictedtospecialfeedback.[clarificationneeded]Semi-supervisedlearningalgorithmsdevelopmathematicalmodelsfromincompletetrainingdata,whereaportionofthesampleinputsaremissingthedesiredoutput.\nClassificationalgorithmsandregressionalgorithmsaretypesofsupervisedlearning.Classificationalgorithmsareusedwhentheoutputsarerestrictedtoalimitedsetofvalues.Foraclassificationalgorithmthatfiltersemails,theinputwouldbeanincomingemail,andtheoutputwouldbethenameofthefolderinwhichtofiletheemail.Foranalgorithmthatidentifiesspamemails,theoutputwouldbethepredictionofeither"spam"or"notspam",representedbytheBooleanvaluesoneandzero.Regressionalgorithmsarenamedfortheircontinuousoutputs,meaningtheymayhaveanyvaluewithinarange.Examplesofacontinuousvaluearethetemperature,length,orpriceofanobject.\nInunsupervisedlearning,thealgorithmbuildsamathematicalmodelofasetofdatawhichcontainsonlyinputsandnodesiredoutputs.Unsupervisedlearningalgorithmsareusedtofindstructureinthedata,likegroupingorclusteringofdatapoints.Unsupervisedlearningcandiscoverpatternsinthedata,andcangrouptheinputsintocategories,asinfeaturelearning.Dimensionalityreductionistheprocessofreducingthenumberof"features",orinputs,inasetofdata.\nActivelearningalgorithmsaccessthedesiredoutputs(traininglabels)foralimitedsetofinputsbasedonabudget,andoptimizethechoiceofinputsforwhichitwillacquiretraininglabels.Whenusedinteractively,thesecanbepresentedtoahumanuserforlabeling.Reinforcementlearningalgorithmsaregivenfeedbackintheformofpositiveornegativereinforcementinadynamicenvironment,andareusedinautonomousvehiclesorinlearningtoplayagameagainstahumanopponent.[2]:3Otherspecializedalgorithmsinmachinelearningincludetopicmodeling,wherethecomputerprogramisgivenasetofnaturallanguagedocumentsandfindsotherdocumentsthatcoversimilartopics.Machinelearningalgorithmscanbeusedtofindtheunobservableprobabilitydensityfunctionindensityestimationproblems.Metalearningalgorithmslearntheirowninductivebiasbasedonpreviousexperience.Indevelopmentalrobotics,robotlearningalgorithmsgeneratetheirownsequencesoflearningexperiences,alsoknownasacurriculum,tocumulativelyacquirenewskillsthroughself-guidedexplorationandsocialinteractionwithhumans.Theserobotsuseguidancemechanismssuchasactivelearning,maturation,motorsynergies,andimitation.[clarificationneeded]\nArthurSamuel,anAmericanpioneerinthefieldofcomputergamingandartificialintelligence,coinedtheterm"MachineLearning"in1959whileatIBM[8].\nAsascientificendeavour,machinelearninggrewoutofthequestforartificialintelligence.AlreadyintheearlydaysofAIasanacademicdiscipline,someresearcherswereinterestedinhavingmachineslearnfromdata.Theyattemptedtoapproachtheproblemwithvarioussymbolicmethods,aswellaswhatwerethentermed"neuralnetworks";theseweremostlyperceptronsandothermodelsthatwerelaterfoundtobereinventionsofthegeneralizedlinearmodelsofstatistics.[9]Probabilisticreasoningwasalsoemployed,especiallyinautomatedmedicaldiagnosis.[10]:488\nHowever,anincreasingemphasisonthelogical,knowledge-basedapproachcausedariftbetweenAIandmachinelearning.Probabilisticsystemswereplaguedbytheoreticalandpracticalproblemsofdataacquisitionandrepresentation.[10]:488By1980,expertsystemshadcometodominateAI,andstatisticswasoutoffavor.[11]Workonsymbolic/knowledge-basedlearningdidcontinuewithinAI,leadingtoinductivelogicprogramming,butthemorestatisticallineofresearchwasnowoutsidethefieldofAIproper,inpatternrecognitionandinformationretrieval.[10]:708\xe2\x80\x93710;755NeuralnetworksresearchhadbeenabandonedbyAIandcomputersciencearoundthesametime.Thisline,too,wascontinuedoutsidetheAI/CSfield,as"connectionism",byresearchersfromotherdisciplinesincludingHopfield,RumelhartandHinton.Theirmainsuccesscameinthemid-1980swiththereinventionofbackpropagation.[10]:25\nMachinelearning,reorganizedasaseparatefield,startedtoflourishinthe1990s.Thefieldchangeditsgoalfromachievingartificialintelligencetotacklingsolvableproblemsofapracticalnature.ItshiftedfocusawayfromthesymbolicapproachesithadinheritedfromAI,andtowardmethodsandmodelsborrowedfromstatisticsandprobabilitytheory.[11]Italsobenefitedfromtheincreasingavailabilityofdigitizedinformation,andtheabilitytodistributeitviatheInternet.\nMachinelearninganddataminingoftenemploythesamemethodsandoverlapsignificantly,butwhilemachinelearningfocusesonprediction,basedonknownpropertieslearnedfromthetrainingdata,dataminingfocusesonthediscoveryof(previously)unknownpropertiesinthedata(thisistheanalysisstepofknowledgediscoveryindatabases).Dataminingusesmanymachinelearningmethods,butwithdifferentgoals;ontheotherhand,machinelearningalsoemploysdataminingmethodsas"unsupervisedlearning"orasapreprocessingsteptoimprovelearneraccuracy.Muchoftheconfusionbetweenthesetworesearchcommunities(whichdooftenhaveseparateconferencesandseparatejournals,ECMLPKDDbeingamajorexception)comesfromthebasicassumptionstheyworkwith:inmachinelearning,performanceisusuallyevaluatedwithrespecttotheabilitytoreproduceknownknowledge,whileinknowledgediscoveryanddatamining(KDD)thekeytaskisthediscoveryofpreviouslyunknownknowledge.Evaluatedwithrespecttoknownknowledge,anuninformed(unsupervised)methodwilleasilybeoutperformedbyothersupervisedmethods,whileinatypicalKDDtask,supervisedmethodscannotbeusedduetotheunavailabilityoftrainingdata.\nMachinelearningalsohasintimatetiestooptimization:manylearningproblemsareformulatedasminimizationofsomelossfunctiononatrainingsetofexamples.Lossfunctionsexpressthediscrepancybetweenthepredictionsofthemodelbeingtrainedandtheactualprobleminstances(forexample,inclassification,onewantstoassignalabeltoinstances,andmodelsaretrainedtocorrectlypredictthepre-assignedlabelsofasetofexamples).Thedifferencebetweenthetwofieldsarisesfromthegoalofgeneralization:whileoptimizationalgorithmscanminimizethelossonatrainingset,machinelearningisconcernedwithminimizingthelossonunseensamples.[12]\nMachinelearningandstatisticsarecloselyrelatedfields.AccordingtoMichaelI.Jordan,theideasofmachinelearning,frommethodologicalprinciplestotheoreticaltools,havehadalongpre-historyinstatistics.[13]Healsosuggestedthetermdatascienceasaplaceholdertocalltheoverallfield.[13]\nLeoBreimandistinguishedtwostatisticalmodellingparadigms:datamodelandalgorithmicmodel,[14]wherein"algorithmicmodel"meansmoreorlessthemachinelearningalgorithmslikeRandomforest.\nSomestatisticianshaveadoptedmethodsfrommachinelearning,leadingtoacombinedfieldthattheycallstatisticallearning.[15]\nAcoreobjectiveofalearneristogeneralizefromitsexperience.[2][16]Generalizationinthiscontextistheabilityofalearningmachinetoperformaccuratelyonnew,unseenexamples/tasksafterhavingexperiencedalearningdataset.Thetrainingexamplescomefromsomegenerallyunknownprobabilitydistribution(consideredrepresentativeofthespaceofoccurrences)andthelearnerhastobuildageneralmodelaboutthisspacethatenablesittoproducesufficientlyaccuratepredictionsinnewcases.\nThecomputationalanalysisofmachinelearningalgorithmsandtheirperformanceisabranchoftheoreticalcomputerscienceknownascomputationallearningtheory.Becausetrainingsetsarefiniteandthefutureisuncertain,learningtheoryusuallydoesnotyieldguaranteesoftheperformanceofalgorithms.Instead,probabilisticboundsontheperformancearequitecommon.Thebias\xe2\x80\x93variancedecompositionisonewaytoquantifygeneralizationerror.\nForthebestperformanceinthecontextofgeneralization,thecomplexityofthehypothesisshouldmatchthecomplexityofthefunctionunderlyingthedata.Ifthehypothesisislesscomplexthanthefunction,thenthemodelhasunderfitthedata.Ifthecomplexityofthemodelisincreasedinresponse,thenthetrainingerrordecreases.Butifthehypothesisistoocomplex,thenthemodelissubjecttooverfittingandgeneralizationwillbepoorer.[17]\nInadditiontoperformancebounds,computationallearningtheoristsstudythetimecomplexityandfeasibilityoflearning.Incomputationallearningtheory,acomputationisconsideredfeasibleifitcanbedoneinpolynomialtime.Therearetwokindsoftimecomplexityresults.Positiveresultsshowthatacertainclassoffunctionscanbelearnedinpolynomialtime.Negativeresultsshowthatcertainclassescannotbelearnedinpolynomialtime.\nThetypesofmachinelearningalgorithmsdifferintheirapproach,thetypeofdatatheyinputandoutput,andthetypeoftaskorproblemthattheyareintendedtosolve.\nSupervisedlearningalgorithmsbuildamathematicalmodelofasetofdatathatcontainsboththeinputsandthedesiredoutputs.[18]Thedataisknownastrainingdata,andconsistsofasetoftrainingexamples.Eachtrainingexamplehasoneormoreinputsandadesiredoutput,alsoknownasasupervisorysignal.Inthecaseofsemi-supervisedlearningalgorithms,someofthetrainingexamplesaremissingthedesiredoutput.Inthemathematicalmodel,eachtrainingexampleisrepresentedbyanarrayorvector,andthetrainingdatabyamatrix.Throughiterativeoptimizationofanobjectivefunction,supervisedlearningalgorithmslearnafunctionthatcanbeusedtopredicttheoutputassociatedwithnewinputs.[19]Anoptimalfunctionwillallowthealgorithmtocorrectlydeterminetheoutputforinputsthatwerenotapartofthetrainingdata.Analgorithmthatimprovestheaccuracyofitsoutputsorpredictionsovertimeissaidtohavelearnedtoperformthattask.[6]\nSupervisedlearningalgorithmsincludeclassificationandregression.[20]Classificationalgorithmsareusedwhentheoutputsarerestrictedtoalimitedsetofvalues,andregressionalgorithmsareusedwhentheoutputsmayhaveanynumericalvaluewithinarange.Similaritylearningisanareaofsupervisedmachinelearningcloselyrelatedtoregressionandclassification,butthegoalistolearnfromexamplesusingasimilarityfunctionthatmeasureshowsimilarorrelatedtwoobjectsare.Ithasapplicationsinranking,recommendationsystems,visualidentitytracking,faceverification,andspeakerverification.\nUnsupervisedlearningalgorithmstakeasetofdatathatcontainsonlyinputs,andfindstructureinthedata,likegroupingorclusteringofdatapoints.Thealgorithmsthereforelearnfromtestdatathathasnotbeenlabeled,classifiedorcategorized.Insteadofrespondingtofeedback,unsupervisedlearningalgorithmsidentifycommonalitiesinthedataandreactbasedonthepresenceorabsenceofsuchcommonalitiesineachnewpieceofdata.Acentralapplicationofunsupervisedlearningisinthefieldofdensityestimationinstatistics,[21]thoughunsupervisedlearningencompassesotherdomainsinvolvingsummarizingandexplainingdatafeatures.\nClusteranalysisistheassignmentofasetofobservationsintosubsets(calledclusters)sothatobservationswithinthesameclusteraresimilaraccordingtooneormorepredesignatedcriteria,whileobservationsdrawnfromdifferentclustersaredissimilar.Differentclusteringtechniquesmakedifferentassumptionsonthestructureofthedata,oftendefinedbysomesimilaritymetricandevaluated,forexample,byinternalcompactness,orthesimilaritybetweenmembersofthesamecluster,andseparation,thedifferencebetweenclusters.Othermethodsarebasedonestimateddensityandgraphconnectivity.\nReinforcementlearningisanareaofmachinelearningconcernedwithhowsoftwareagentsoughttotakeactionsinanenvironmentsoastomaximizesomenotionofcumulativereward.Duetoitsgenerality,thefieldisstudiedinmanyotherdisciplines,suchasgametheory,controltheory,operationsresearch,informationtheory,simulation-basedoptimization,multi-agentsystems,swarmintelligence,statisticsandgeneticalgorithms.[22][23]Inmachinelearning,theenvironmentistypicallyrepresentedasaMarkovDecisionProcess(MDP).Manyreinforcementlearningalgorithmsusedynamicprogrammingtechniques.[22][23][24]ReinforcementlearningalgorithmsdonotassumeknowledgeofanexactmathematicalmodeloftheMDP,andareusedwhenexactmodelsareinfeasible.[22][23]Reinforcementlearningalgorithmsareusedinautonomousvehiclesorinlearningtoplayagameagainstahumanopponent.\nVariousprocesses,techniquesandmethodscanbeappliedtooneormoretypesofmachinelearningalgorithmstoenhancetheirperformance.\nSeverallearningalgorithmsaimatdiscoveringbetterrepresentationsoftheinputsprovidedduringtraining.[25]Classicexamplesincludeprincipalcomponentsanalysisandclusteranalysis.Featurelearningalgorithms,alsocalledrepresentationlearningalgorithms,oftenattempttopreservetheinformationintheirinputbutalsotransformitinawaythatmakesituseful,oftenasapre-processingstepbeforeperformingclassificationorpredictions.Thistechniqueallowsreconstructionoftheinputscomingfromtheunknowndata-generatingdistribution,whilenotbeingnecessarilyfaithfultoconfigurationsthatareimplausibleunderthatdistribution.Thisreplacesmanualfeatureengineering,andallowsamachinetobothlearnthefeaturesandusethemtoperformaspecifictask.\nFeaturelearningcanbeeithersupervisedorunsupervised.Insupervisedfeaturelearning,featuresarelearnedusinglabeledinputdata.Examplesincludeartificialneuralnetworks,multilayerperceptrons,andsuperviseddictionarylearning.Inunsupervisedfeaturelearning,featuresarelearnedwithunlabeledinputdata.Examplesincludedictionarylearning,independentcomponentanalysis,autoencoders,matrixfactorization[26]andvariousformsofclustering.[27][28][29]\nManifoldlearningalgorithmsattempttodosoundertheconstraintthatthelearnedrepresentationislow-dimensional.Sparsecodingalgorithmsattempttodosoundertheconstraintthatthelearnedrepresentationissparse,meaningthatthemathematicalmodelhasmanyzeros.Multilinearsubspacelearningalgorithmsaimtolearnlow-dimensionalrepresentationsdirectlyfromtensorrepresentationsformultidimensionaldata,withoutreshapingthemintohigher-dimensionalvectors.[30]Deeplearningalgorithmsdiscovermultiplelevelsofrepresentation,orahierarchyoffeatures,withhigher-level,moreabstractfeaturesdefinedintermsof(orgenerating)lower-levelfeatures.Ithasbeenarguedthatanintelligentmachineisonethatlearnsarepresentationthatdisentanglestheunderlyingfactorsofvariationthatexplaintheobserveddata.[31]\nFeaturelearningismotivatedbythefactthatmachinelearningtaskssuchasclassificationoftenrequireinputthatismathematicallyandcomputationallyconvenienttoprocess.However,real-worlddatasuchasimages,video,andsensorydatahasnotyieldedtoattemptstoalgorithmicallydefinespecificfeatures.Analternativeistodiscoversuchfeaturesorrepresentationsthroughexamination,withoutrelyingonexplicitalgorithms.\nSparsedictionarylearningisafeaturelearningmethodwhereatrainingexampleisrepresentedasalinearcombinationofbasisfunctions,andisassumedtobeasparsematrix.ThemethodisstronglyNP-hardanddifficulttosolveapproximately.[32]ApopularheuristicmethodforsparsedictionarylearningistheK-SVDalgorithm.Sparsedictionarylearninghasbeenappliedinseveralcontexts.Inclassification,theproblemistodeterminetowhichclassesapreviouslyunseentrainingexamplebelongs.Foradictionarywhereeachclasshasalreadybeenbuilt,anewtrainingexampleisassociatedwiththeclassthatisbestsparselyrepresentedbythecorrespondingdictionary.Sparsedictionarylearninghasalsobeenappliedinimagede-noising.Thekeyideaisthatacleanimagepatchcanbesparselyrepresentedbyanimagedictionary,butthenoisecannot.[33]\nIndatamining,anomalydetection,alsoknownasoutlierdetection,istheidentificationofrareitems,eventsorobservationswhichraisesuspicionsbydifferingsignificantlyfromthemajorityofthedata.[34]Typically,theanomalousitemsrepresentanissuesuchasbankfraud,astructuraldefect,medicalproblemsorerrorsinatext.Anomaliesarereferredtoasoutliers,novelties,noise,deviationsandexceptions.[35]\nInparticular,inthecontextofabuseandnetworkintrusiondetection,theinterestingobjectsareoftennotrareobjects,butunexpectedburstsinactivity.Thispatterndoesnotadheretothecommonstatisticaldefinitionofanoutlierasarareobject,andmanyoutlierdetectionmethods(inparticular,unsupervisedalgorithms)willfailonsuchdata,unlessithasbeenaggregatedappropriately.Instead,aclusteranalysisalgorithmmaybeabletodetectthemicro-clustersformedbythesepatterns.[36]\nThreebroadcategoriesofanomalydetectiontechniquesexist.[37]Unsupervisedanomalydetectiontechniquesdetectanomaliesinanunlabeledtestdatasetundertheassumptionthatthemajorityoftheinstancesinthedatasetarenormal,bylookingforinstancesthatseemtofitleasttotheremainderofthedataset.Supervisedanomalydetectiontechniquesrequireadatasetthathasbeenlabeledas"normal"and"abnormal"andinvolvestrainingaclassifier(thekeydifferencetomanyotherstatisticalclassificationproblemsistheinherentunbalancednatureofoutlierdetection).Semi-supervisedanomalydetectiontechniquesconstructamodelrepresentingnormalbehaviorfromagivennormaltrainingdataset,andthentestthelikelihoodofatestinstancetobegeneratedbythemodel.\nDecisiontreelearningusesadecisiontreeasapredictivemodeltogofromobservationsaboutanitem(representedinthebranches)toconclusionsabouttheitem\'stargetvalue(representedintheleaves).Itisoneofthepredictivemodelingapproachesusedinstatistics,dataminingandmachinelearning.Treemodelswherethetargetvariablecantakeadiscretesetofvaluesarecalledclassificationtrees;inthesetreestructures,leavesrepresentclasslabelsandbranchesrepresentconjunctionsoffeaturesthatleadtothoseclasslabels.Decisiontreeswherethetargetvariablecantakecontinuousvalues(typicallyrealnumbers)arecalledregressiontrees.Indecisionanalysis,adecisiontreecanbeusedtovisuallyandexplicitlyrepresentdecisionsanddecisionmaking.Indatamining,adecisiontreedescribesdata,buttheresultingclassificationtreecanbeaninputfordecisionmaking.\nAssociationrulelearningisarule-basedmachinelearningmethodfordiscoveringrelationshipsbetweenvariablesinlargedatabases.Itisintendedtoidentifystrongrulesdiscoveredindatabasesusingsomemeasureof"interestingness".[38]Thisrule-basedapproachgeneratesnewrulesasitanalyzesmoredata.Theultimategoal,assumingthesetofdataislargeenough,istohelpamachinemimicthehumanbrain\xe2\x80\x99sfeatureextractionandabstractassociationcapabilitiesfordatathathasnotbeencategorized.[39]\nRule-basedmachinelearningisageneraltermforanymachinelearningmethodthatidentifies,learns,orevolves"rules"tostore,manipulateorapplyknowledge.Thedefiningcharacteristicofarule-basedmachinelearningalgorithmistheidentificationandutilizationofasetofrelationalrulesthatcollectivelyrepresenttheknowledgecapturedbythesystem.Thisisincontrasttoothermachinelearningalgorithmsthatcommonlyidentifyasingularmodelthatcanbeuniversallyappliedtoanyinstanceinordertomakeaprediction.[40]Rule-basedmachinelearningapproachesincludelearningclassifiersystems,associationrulelearning,andartificialimmunesystems.\nBasedontheconceptofstrongrules,RakeshAgrawal,TomaszImieli\xc5\x84skiandArunSwamiintroducedassociationrulesfordiscoveringregularitiesbetweenproductsinlarge-scaletransactiondatarecordedbypoint-of-sale(POS)systemsinsupermarkets.[41]Forexample,therule\n\n\n\n{\n\no\nn\ni\no\nn\ns\n,\np\no\nt\na\nt\no\ne\ns\n\n}\n⇒\n{\n\nb\nu\nr\ng\ne\nr\n\n}\n\n\n{\\displaystyle\\{\\mathrm{onions,potatoes}\\}\\Rightarrow\\{\\mathrm{burger}\\}}\n\nfoundinthesalesdataofasupermarketwouldindicatethatifacustomerbuysonionsandpotatoestogether,theyarelikelytoalsobuyhamburgermeat.Suchinformationcanbeusedasthebasisfordecisionsaboutmarketingactivitiessuchaspromotionalpricingorproductplacements.Inadditiontomarketbasketanalysis,associationrulesareemployedtodayinapplicationareasincludingWebusagemining,intrusiondetection,continuousproduction,andbioinformatics.Incontrastwithsequencemining,associationrulelearningtypicallydoesnotconsidertheorderofitemseitherwithinatransactionoracrosstransactions.\nLearningclassifiersystems(LCS)areafamilyofrule-basedmachinelearningalgorithmsthatcombineadiscoverycomponent,typicallyageneticalgorithm,withalearningcomponent,performingeithersupervisedlearning,reinforcementlearning,orunsupervisedlearning.Theyseektoidentifyasetofcontext-dependentrulesthatcollectivelystoreandapplyknowledgeinapiecewisemannerinordertomakepredictions.[42]\nInductivelogicprogramming(ILP)isanapproachtorule-learningusinglogicprogrammingasauniformrepresentationforinputexamples,backgroundknowledge,andhypotheses.Givenanencodingoftheknownbackgroundknowledgeandasetofexamplesrepresentedasalogicaldatabaseoffacts,anILPsystemwillderiveahypothesizedlogicprogramthatentailsallpositiveandnonegativeexamples.Inductiveprogrammingisarelatedfieldthatconsidersanykindofprogramminglanguagesforrepresentinghypotheses(andnotonlylogicprogramming),suchasfunctionalprograms.\nInductivelogicprogrammingisparticularlyusefulinbioinformaticsandnaturallanguageprocessing.GordonPlotkinandEhudShapirolaidtheinitialtheoreticalfoundationforinductivemachinelearninginalogicalsetting.[43][44][45]Shapirobuilttheirfirstimplementation(ModelInferenceSystem)in1981:aPrologprogramthatinductivelyinferredlogicprogramsfrompositiveandnegativeexamples.[46]Theterminductiveherereferstophilosophicalinduction,suggestingatheorytoexplainobservedfacts,ratherthanmathematicalinduction,provingapropertyforallmembersofawell-orderedset.\nArtificialneuralnetworks(ANNs),orconnectionistsystems,arecomputingsystemsvaguelyinspiredbythebiologicalneuralnetworksthatconstituteanimalbrains.[47]Theneuralnetworkitselfisnotanalgorithm,butratheraframeworkformanydifferentmachinelearningalgorithmstoworktogetherandprocesscomplexdatainputs.[48]Suchsystems"learn"toperformtasksbyconsideringexamples,generallywithoutbeingprogrammedwithanytask-specificrules.\nAnANNisamodelbasedonacollectionofconnectedunitsornodescalled"artificialneurons",whichlooselymodeltheneuronsinabiologicalbrain.Eachconnection,likethesynapsesinabiologicalbrain,cantransmitinformation,a"signal",fromoneartificialneurontoanother.Anartificialneuronthatreceivesasignalcanprocessitandthensignaladditionalartificialneuronsconnectedtoit.IncommonANNimplementations,thesignalataconnectionbetweenartificialneuronsisarealnumber,andtheoutputofeachartificialneuroniscomputedbysomenon-linearfunctionofthesumofitsinputs.Theconnectionsbetweenartificialneuronsarecalled"edges".Artificialneuronsandedgestypicallyhaveaweightthatadjustsaslearningproceeds.Theweightincreasesordecreasesthestrengthofthesignalataconnection.Artificialneuronsmayhaveathresholdsuchthatthesignalisonlysentiftheaggregatesignalcrossesthatthreshold.Typically,artificialneuronsareaggregatedintolayers.Differentlayersmayperformdifferentkindsoftransformationsontheirinputs.Signalstravelfromthefirstlayer(theinputlayer),tothelastlayer(theoutputlayer),possiblyaftertraversingthelayersmultipletimes.\nTheoriginalgoaloftheANNapproachwastosolveproblemsinthesamewaythatahumanbrainwould.However,overtime,attentionmovedtoperformingspecifictasks,leadingtodeviationsfrombiology.Artificialneuralnetworkshavebeenusedonavarietyoftasks,includingcomputervision,speechrecognition,machinetranslation,socialnetworkfiltering,playingboardandvideogamesandmedicaldiagnosis.\nDeeplearningconsistsofmultiplehiddenlayersinanartificialneuralnetwork.Thisapproachtriestomodelthewaythehumanbrainprocesseslightandsoundintovisionandhearing.Somesuccessfulapplicationsofdeeplearningarecomputervisionandspeechrecognition.[49]\nSupportvectormachines(SVMs),alsoknownassupportvectornetworks,areasetofrelatedsupervisedlearningmethodsusedforclassificationandregression.Givenasetoftrainingexamples,eachmarkedasbelongingtooneoftwocategories,anSVMtrainingalgorithmbuildsamodelthatpredictswhetheranewexamplefallsintoonecategoryortheother.[50]AnSVMtrainingalgorithmisanon-probabilistic,binary,linearclassifier,althoughmethodssuchasPlattscalingexisttouseSVMinaprobabilisticclassificationsetting.Inadditiontoperforminglinearclassification,SVMscanefficientlyperformanon-linearclassificationusingwhatiscalledthekerneltrick,implicitlymappingtheirinputsintohigh-dimensionalfeaturespaces.\nABayesiannetwork,beliefnetworkordirectedacyclicgraphicalmodelisaprobabilisticgraphicalmodelthatrepresentsasetofrandomvariablesandtheirconditionalindependencewithadirectedacyclicgraph(DAG).Forexample,aBayesiannetworkcouldrepresenttheprobabilisticrelationshipsbetweendiseasesandsymptoms.Givensymptoms,thenetworkcanbeusedtocomputetheprobabilitiesofthepresenceofvariousdiseases.Efficientalgorithmsexistthatperforminferenceandlearning.Bayesiannetworksthatmodelsequencesofvariables,likespeechsignalsorproteinsequences,arecalleddynamicBayesiannetworks.GeneralizationsofBayesiannetworksthatcanrepresentandsolvedecisionproblemsunderuncertaintyarecalledinfluencediagrams.\nAgeneticalgorithm(GA)isasearchalgorithmandheuristictechniquethatmimicstheprocessofnaturalselection,usingmethodssuchasmutationandcrossovertogeneratenewgenotypesinthehopeoffindinggoodsolutionstoagivenproblem.Inmachinelearning,geneticalgorithmswereusedinthe1980sand1990s.[51][52]Conversely,machinelearningtechniqueshavebeenusedtoimprovetheperformanceofgeneticandevolutionaryalgorithms.[53]\nApplicationsformachinelearninginclude:\nIn2006,theonlinemoviecompanyNetflixheldthefirst"NetflixPrize"competitiontofindaprogramtobetterpredictuserpreferencesandimprovetheaccuracyonitsexistingCinematchmovierecommendationalgorithmbyatleast10%.AjointteammadeupofresearchersfromAT&TLabs-ResearchincollaborationwiththeteamsBigChaosandPragmaticTheorybuiltanensemblemodeltowintheGrandPrizein2009for$1 million.[59]Shortlyaftertheprizewasawarded,Netflixrealizedthatviewers\'ratingswerenotthebestindicatorsoftheirviewingpatterns("everythingisarecommendation")andtheychangedtheirrecommendationengineaccordingly.[60]In2010TheWallStreetJournalwroteaboutthefirmRebellionResearchandtheiruseofmachinelearningtopredictthefinancialcrisis.[61]In2012,co-founderofSunMicrosystems,VinodKhosla,predictedthat80%ofmedicaldoctorsjobswouldbelostinthenexttwodecadestoautomatedmachinelearningmedicaldiagnosticsoftware.[62]In2014,itwasreportedthatamachinelearningalgorithmhadbeenappliedinthefieldofarthistorytostudyfineartpaintings,andthatitmayhaverevealedpreviouslyunrecognizedinfluencesbetweenartists.[63]\nAlthoughmachinelearninghasbeentransformativeinsomefields,effectivemachinelearningisdifficultbecausefindingpatternsishardandoftennotenoughtrainingdataareavailable;asaresult,manymachine-learningprogramsoftenfailtodelivertheexpectedvalue.[64][65][66]Reasonsforthisarenumerous:lackof(suitable)data,lackofaccesstothedata,databias,privacyproblems,badlychosentasksandalgorithms,wrongtoolsandpeople,lackofresources,andevaluationproblems.[67]\nIn2018,aself-drivingcarfromUberfailedtodetectapedestrian,whogotkilledintheaccident.[68]AttemptstousemachinelearninginhealthcarewiththeIBMWatsonsystemfailedtodeliverevenafteryearsoftimeandbillionsofinvestment.[69][70]\nMachinelearningapproachesinparticularcansufferfromdifferentdatabiases.Inhealthcaredata,measurementerrorscanoftenresultinbiasofmachinelearningapplications.[71]Amachinelearningsystemtrainedonyourcurrentcustomersonlymaynotbeabletopredicttheneedsofnewcustomergroupsthatarenotrepresentedinthetrainingdata.Whentrainedonman-madedata,machinelearningislikelytopickupthesameconstitutionalandunconsciousbiasesalreadypresentinsociety.[72]Languagemodelslearnedfromdatahavebeenshowntocontainhuman-likebiases.[73][74]Machinelearningsystemsusedforcriminalriskassessmenthavebeenfoundtobebiasedagainstblackpeople.[75][76]In2015,Googlephotoswouldoftentagblackpeopleasgorillas,[77]andin2018thisstillwasnotwellresolved,butGooglereportedlywasstillusingtheworkaroundtoremoveallgorillafromthetrainingdata,andthuswasnotabletorecognizerealgorillasatall.[78]Similarissueswithrecognizingnon-whitepeoplehavebeenfoundinmanyothersystems.[79]In2016,MicrosofttestedachatbotthatlearnedfromTwitter,anditquicklypickedupracistandsexistlanguage.[80]Becauseofsuchchallenges,theeffectiveuseofmachinelearningmaytakelongertobeadoptedinotherdomains.[81]\nClassificationmachinelearningmodelscanbevalidatedbyaccuracyestimationtechniquesliketheHoldoutmethod,whichsplitsthedatainatrainingandtestset(conventionally2/3trainingsetand1/3testsetdesignation)andevaluatestheperformanceofthetrainingmodelonthetestset.Incomparison,theN-fold-cross-validationmethodrandomlysplitsthedatainksubsetswherethek-1instancesofthedataareusedtotrainthemodelwhilethekthinstanceisusedtotestthepredictiveabilityofthetrainingmodel.Inadditiontotheholdoutandcross-validationmethods,bootstrap,whichsamplesninstanceswithreplacementfromthedataset,canbeusedtoassessmodelaccuracy.[82]\nInadditiontooverallaccuracy,investigatorsfrequentlyreportsensitivityandspecificitymeaningTruePositiveRate(TPR)andTrueNegativeRate(TNR)respectively.Similarly,investigatorssometimesreporttheFalsePositiveRate(FPR)aswellastheFalseNegativeRate(FNR).However,theseratesareratiosthatfailtorevealtheirnumeratorsanddenominators.TheTotalOperatingCharacteristic(TOC)isaneffectivemethodtoexpressamodel\'sdiagnosticability.TOCshowsthenumeratorsanddenominatorsofthepreviouslymentionedrates,thusTOCprovidesmoreinformationthanthecommonlyusedReceiverOperatingCharacteristic(ROC)andROC\'sassociatedAreaUndertheCurve(AUC).[83]\nMachinelearningposesahostofethicalquestions.Systemswhicharetrainedondatasetscollectedwithbiasesmayexhibitthesebiasesuponuse(algorithmicbias),thusdigitizingculturalprejudices.[84]Forexample,usingjobhiringdatafromafirmwithracisthiringpoliciesmayleadtoamachinelearningsystemduplicatingthebiasbyscoringjobapplicantsagainstsimilaritytoprevioussuccessfulapplicants.[85][86]Responsiblecollectionofdataanddocumentationofalgorithmicrulesusedbyasystemthusisacriticalpartofmachinelearning.\nBecauselanguagecontainsbiases,machinestrainedonlanguagecorporawillnecessarilyalsolearnbias.[87]\nOtherformsofethicalchallenges,notrelatedtopersonalbiases,aremoreseeninhealthcare.Thereareconcernsamonghealthcareprofessionalsthatthesesystemsmightnotbedesignedinthepublic\'sinterest,butasincomegeneratingmachines.ThisisespeciallytrueintheUnitedStateswherethereisaperpetualethicaldilemmaofimprovinghealthcare,butalsoincreasingprofits.Forexample,thealgorithmscouldbedesignedtoprovidepatientswithunnecessarytestsormedicationinwhichthealgorithm\'sproprietaryownersholdstakesin.Thereishugepotentialformachinelearninginhealthcaretoprovideprofessionalsagreattooltodiagnose,medicate,andevenplanrecoverypathsforpatients,butthiswillnothappenuntilthepersonalbiasesmentionedpreviously,andthese"greed"biasesareaddressed.[88]\nSoftwaresuitescontainingavarietyofmachinelearningalgorithmsincludethefollowing :\n