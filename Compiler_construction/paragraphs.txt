\nAcompilerisacomputerprogramthattransformscomputercodewritteninoneprogramminglanguage(thesourcelanguage)intoanotherprogramminglanguage(thetargetlanguage).Compilersareatypeoftranslatorthatsupportdigitaldevices,primarilycomputers.Thenamecompilerisprimarilyusedforprogramsthattranslatesourcecodefromahigh-levelprogramminglanguagetoalowerlevellanguage(e.g.,assemblylanguage,objectcode,ormachinecode)tocreateanexecutableprogram.[1]\nHowever,therearemanydifferenttypesofcompilers.IfthecompiledprogramcanrunonacomputerwhoseCPUoroperatingsystemisdifferentfromtheoneonwhichthecompilerruns,thecompilerisacross-compiler.Abootstrapcompileriswritteninthelanguagethatitintendstocompile.Aprogramthattranslatesfromalow-levellanguagetoahigherleveloneisadecompiler.Aprogramthattranslatesbetweenhigh-levellanguagesisusuallycalledasource-to-sourcecompilerortranspiler.Alanguagerewriterisusuallyaprogramthattranslatestheformofexpressionswithoutachangeoflanguage.Thetermcompiler-compilerreferstotoolsusedtocreateparsersthatperformsyntaxanalysis.\nAcompilerislikelytoperformmanyorallofthefollowingoperations:preprocessing,lexicalanalysis,parsing,semanticanalysis(syntax-directedtranslation),conversionofinputprogramstoanintermediaterepresentation,codeoptimizationandcodegeneration.Compilersimplementtheseoperationsinphasesthatpromoteefficientdesignandcorrecttransformationsofsourceinputtotargetoutput.Programfaultscausedbyincorrectcompilerbehaviorcanbeverydifficulttotrackdownandworkaround;therefore,compilerimplementersinvestsignificantefforttoensurecompilercorrectness.[2]\nCompilersarenottheonlytranslatorsusedtotransformsourceprograms.Aninterpreteriscomputersoftwarethattransformsandthenexecutestheindicatedoperations.Thetranslationprocessinfluencesthedesignofcomputerlanguageswhichleadstoapreferenceofcompilationorinterpretation.Inpractice,aninterpretercanbeimplementedforcompiledlanguagesandcompilerscanbeimplementedforinterpretedlanguages.\nTheoreticalcomputingconceptsdevelopedbyscientists,mathematicians,andengineersformedthebasisofdigitalmoderncomputingdevelopmentduringWorldWarII.Primitivebinarylanguagesevolvedbecausedigitaldevicesonlyunderstandonesandzerosandthecircuitpatternsintheunderlyingmachinearchitecture.Inthelate1940s,assemblylanguageswerecreatedtoofferamoreworkableabstractionofthecomputerarchitectures.Limitedmemorycapacityofearlycomputersledtosubstantialtechnicalchallengeswhenthefirstcompilersweredesigned.Therefore,thecompilationprocessneededtobedividedintoseveralsmallprograms.Thefrontendprogramsproducetheanalysisproductsusedbythebackendprogramstogeneratetargetcode.Ascomputertechnologyprovidedmoreresources,compilerdesignscouldalignbetterwiththecompilationprocess.\nThehumanmindcandesignbettersolutionsasthelanguagemovesfromthemachinetoahigherlevel.Sothedevelopmentofhigh-levellanguagesfollowednaturallyfromthecapabilitiesofferedbythedigitalcomputers.High-levellanguagesareformallanguagesthatarestrictlydefinedbytheirsyntaxandsemanticswhichformthehigh-levellanguagearchitecture.Elementsoftheseformallanguagesinclude:\nThesentencesinalanguagemaybedefinedbyasetofrulescalledagrammar.[3]\nBackus\xe2\x80\x93Naurform(BNF)describesthesyntaxof"sentences"ofalanguageandwasusedforthesyntaxofAlgol60byJohnBackus.[4]Theideasderivefromthecontext-freegrammarconceptsbyNoamChomsky,alinguist.[5]"BNFanditsextensionshavebecomestandardtoolsfordescribingthesyntaxofprogrammingnotations,andinmanycasespartsofcompilersaregeneratedautomaticallyfromaBNFdescription."[6]\nInthe1940s,KonradZusedesignedanalgorithmicprogramminglanguagecalledPlankalk\xc3\xbcl("PlanCalculus").Whilenoactualimplementationoccurreduntilthe1970s,itpresentedconceptslaterseeninAPLdesignedbyKenIversoninthelate1950s.[7]APLisalanguageformathematicalcomputations.\nHigh-levellanguagedesignduringtheformativeyearsofdigitalcomputingprovidedusefulprogrammingtoolsforavarietyofapplications:\nCompilertechnologyevolvedfromtheneedforastrictlydefinedtransformationofthehigh-levelsourceprogramintoalow-leveltargetprogramforthedigitalcomputer.Thecompilercouldbeviewedasafrontendtodealwithanalysisofthesourcecodeandabackendtosynthesizetheanalysisintothetargetcode.Optimizationbetweenthefrontendandbackendcouldproducemoreefficienttargetcode.[11]\nSomeearlymilestonesinthedevelopmentofcompilertechnology:\nEarlyoperatingsystemsandsoftwarewerewritteninassemblylanguage.Inthe60sandearly70s,theuseofhigh-levellanguagesforsystemprogrammingwasstillcontroversialduetoresourcelimitations.However,severalresearchandindustryeffortsbegantheshifttowardhigh-levelsystemsprogramminglanguages,forexample,BCPL,BLISS,B,andC.\nBCPL(BasicCombinedProgrammingLanguage)designedin1966byMartinRichardsattheUniversityofCambridgewasoriginallydevelopedasacompilerwritingtool.[16]Severalcompilershavebeenimplemented,Richards\'bookprovidesinsightstothelanguageanditscompiler.[17]BCPLwasnotonlyaninfluentialsystemsprogramminglanguagethatisstillusedinresearch[18]butalsoprovidedabasisforthedesignofBandClanguages.\nBLISS(BasicLanguageforImplementationofSystemSoftware)wasdevelopedforaDigitalEquipmentCorporation(DEC)PDP-10computerbyW.A.Wulf\'sCarnegieMellonUniversity(CMU)researchteam.TheCMUteamwentontodevelopBLISS-11compileroneyearlaterin1970.\nMultics(MultiplexedInformationandComputingService),atime-sharingoperatingsystemproject,involvedMIT,BellLabs,GeneralElectric(laterHoneywell)andwasledbyFernandoCorbat\xc3\xb3fromMIT.[19]MulticswaswritteninthePL/IlanguagedevelopedbyIBMandIBMUserGroup.[20]IBM\'sgoalwastosatisfybusiness,scientific,andsystemsprogrammingrequirements.TherewereotherlanguagesthatcouldhavebeenconsideredbutPL/Iofferedthemostcompletesolutioneventhoughithadnotbeenimplemented.[21]ForthefirstfewyearsoftheMuliticsproject,asubsetofthelanguagecouldbecompiledtoassemblylanguagewiththeEarlyPL/I(EPL)compilerbyDougMcIloryandBobMorrisfromBellLabs.[22]EPLsupportedtheprojectuntilaboot-strappingcompilerforthefullPL/Icouldbedeveloped.[23]\nBellLabslefttheMulticsprojectin1969:"Overtime,hopewasreplacedbyfrustrationasthegroupeffortinitiallyfailedtoproduceaneconomicallyusefulsystem."[24]Continuedparticipationwoulddriveupprojectsupportcosts.Soresearchersturnedtootherdevelopmentefforts.AsystemprogramminglanguageBbasedonBCPLconceptswaswrittenbyDennisRitchieandKenThompson.Ritchiecreatedaboot-strappingcompilerforBandwroteUnics(UniplexedInformationandComputingService)operatingsystemforaPDP-7inB.UnicseventuallybecamespelledUnix.\nBellLabsstarteddevelopmentandexpansionofCbasedonBandBCPL.TheBCPLcompilerhadbeentransportedtoMulticsbyBellLabsandBCPLwasapreferredlanguageatBellLabs.[25]Initially,afront-endprogramtoBellLabs\'BcompilerwasusedwhileaCcompilerwasdeveloped.In1971,anewPDP-11providedtheresourcetodefineextensionstoBandrewritethecompiler.By1973thedesignofClanguagewasessentiallycompleteandtheUnixkernelforaPDP-11wasrewritteninC.SteveJohnsonstarteddevelopmentofPortableCCompiler(PCC)tosupportretargetingofCcompilerstonewmachines.[26][27]\nObject-orientedprogramming(OOP)offeredsomeinterestingpossibilitiesforapplicationdevelopmentandmaintenance.OOPconceptsgofurtherbackbutwerepartofLISPandSimulalanguagescience.[28]AtBellLabs,thedevelopmentofC++becameinterestedinOOP.[29]C++wasfirstusedin1980forsystemsprogramming.TheinitialdesignleveragedClanguagesystemsprogrammingcapabilitieswithSimulaconcepts.Object-orientedfacilitieswereaddedin1983.[30]TheCfrontprogramimplementedaC++front-endforC84languagecompiler.InsubsequentyearsseveralC++compilersweredevelopedasC++popularitygrew.\nInmanyapplicationdomains,theideaofusingahigher-levellanguagequicklycaughton.Becauseoftheexpandingfunctionalitysupportedbynewerprogramminglanguagesandtheincreasingcomplexityofcomputerarchitectures,compilersbecamemorecomplex.\nDARPA(DefenseAdvancedResearchProjectsAgency)sponsoredacompilerprojectwithWulf\'sCMUresearchteamin1970.TheProductionQualityCompiler-CompilerPQCCdesignwouldproduceaProductionQualityCompiler(PQC)fromformaldefinitionsofsourcelanguageandthetarget.[31]PQCCtriedtoextendthetermcompiler-compilerbeyondthetraditionalmeaningasaparsergenerator(e.g.,Yacc)withoutmuchsuccess.PQCCmightmoreproperlybereferredtoasacompilergenerator.\nPQCCresearchintocodegenerationprocesssoughttobuildatrulyautomaticcompiler-writingsystem.TheeffortdiscoveredanddesignedthephasestructureofthePQC.TheBLISS-11compilerprovidedtheinitialstructure.[32]Thephasesincludedanalyses(frontend),intermediatetranslationtovirtualmachine(middleend),andtranslationtothetarget(backend).TCOLwasdevelopedforthePQCCresearchtohandlelanguagespecificconstructsintheintermediaterepresentation.[33]VariationsofTCOLsupportedvariouslanguages.ThePQCCprojectinvestigatedtechniquesofautomatedcompilerconstruction.Thedesignconceptsprovedusefulinoptimizingcompilersandcompilersfortheobject-orientedprogramminglanguageAda.\nTheAdaStonemanDocumentformalizedtheprogramsupportenvironment(APSE)alongwiththekernel(KAPSE)andminimal(MAPSE).AnAdainterpreterNYU/EDsupporteddevelopmentandstandardizationeffortswithAmericanNationalStandardsInstitute(ANSI)andtheInternationalStandardsOrganization(ISO).InitialAdacompilerdevelopmentbytheU.S.MilitaryServicesincludedthecompilersinacompleteintegrateddesignenvironmentalongthelinesoftheStonemanDocument.ArmyandNavyworkedontheAdaLanguageSystem(ALS)projecttargetedtoDEC/VAXarchitecturewhiletheAirForcestartedontheAdaIntegratedEnvironment(AIE)targetedtoIBM370series.Whiletheprojectsdidnotprovidethedesiredresults,theydidcontributetotheoveraleffortonAdadevelopment.[34]\nOtherAdacompilereffortsgotunderwayinBritainatUniversityofYorkandinGermanyatUniversityofKarlsruhe.IntheU.S.,Verdix(lateracquiredbyRational)deliveredtheVerdixAdaDevelopmentSystem(VADS)totheArmy.VADSprovidedasetofdevelopmenttoolsincludingacompiler.Unix/VADScouldbehostedonavarietyofUnixplatformssuchasDECUltrixandtheSun3/60SolaristargetedtoMotorola68020inanArmyCECOMevaluation.[35]ThereweresoonmanyAdacompilersavailablethatpassedtheAdaValidationtests.TheFreeSoftwareFoundationGNUprojectdevelopedtheGNUCompilerCollection(GCC)whichprovidesacorecapabilitytosupportmultiplelanguagesandtargets.TheAdaversionGNATisoneofthemostwidelyusedAdacompilers.GNATisfreebutthereisalsocommercialsupport,forexample,AdaCore,wasfoundedin1994toprovidecommercialsoftwaresolutionsforAda.GNATProincludestheGNUGCCbasedGNATwithatoolsuitetoprovideanintegrateddevelopmentenvironment.\nHigh-levellanguagescontinuedtodrivecompilerresearchanddevelopment.Focusareasincludedoptimizationandautomaticcodegeneration.Trendsinprogramminglanguagesanddevelopmentenvironmentsinfluencedcompilertechnology.Morecompilersbecameincludedinlanguagedistributions(PERL,JavaDevelopmentKit)andasacomponentofanIDE(VADS,Eclipse,AdaPro).Theinterrelationshipandinterdependenceoftechnologiesgrew.Theadventofwebservicespromotedgrowthofweblanguagesandscriptinglanguages.ScriptstracebacktotheearlydaysofCommandLineInterfaces(CLI)wheretheusercouldentercommandstobeexecutedbythesystem.UserShellconceptsdevelopedwithlanguagestowriteshellprograms.EarlyWindowsdesignsofferedasimplebatchprogrammingcapability.Theconventionaltransformationoftheselanguageusedaninterpreter.Whilenotwidelyused,BashandBatchcompilershavebeenwritten.Morerecentlysophisticatedinterpretedlanguagesbecamepartofthedeveloperstoolkit.ModernscriptinglanguagesincludePHP,Python,RubyandLua.(Luaiswidelyusedingamedevelopment.)Allofthesehaveinterpreterandcompilersupport.[36]\n"Whenthefieldofcompilingbeganinthelate50s,itsfocuswaslimitedtothetranslationofhigh-levellanguageprogramsintomachinecode...Thecompilerfieldisincreasinglyintertwinedwithotherdisciplinesincludingcomputerarchitecture,programminglanguages,formalmethods,softwareengineering,andcomputersecurity."[37]The"CompilerResearch:TheNext50Years"articlenotedtheimportanceofobject-orientedlanguagesandJava.Securityandparallelcomputingwerecitedamongthefutureresearchtargets.\nAcompilerimplementsaformaltransformationfromahigh-levelsourceprogramtoalow-leveltargetprogram.Compilerdesigncandefineanendtoendsolutionortackleadefinedsubsetthatinterfaceswithothercompilationtoolse.g.preprocessors,assemblers,linkers.Designrequirementsincluderigorouslydefinedinterfacesbothinternallybetweencompilercomponentsandexternallybetweensupportingtoolsets.\nIntheearlydays,theapproachtakentocompilerdesignwasdirectlyaffectedbythecomplexityofthecomputerlanguagetobeprocessed,theexperienceoftheperson(s)designingit,andtheresourcesavailable.Resourcelimitationsledtotheneedtopassthroughthesourcecodemorethanonce.\nAcompilerforarelativelysimplelanguagewrittenbyonepersonmightbeasingle,monolithicpieceofsoftware.However,asthesourcelanguagegrowsincomplexitythedesignmaybesplitintoanumberofinterdependentphases.Separatephasesprovidedesignimprovementsthatfocusdevelopmentonthefunctionsinthecompilationprocess.\nClassifyingcompilersbynumberofpasseshasitsbackgroundinthehardwareresourcelimitationsofcomputers.Compilinginvolvesperforminglotsofworkandearlycomputersdidnothaveenoughmemorytocontainoneprogramthatdidallofthiswork.Socompilersweresplitupintosmallerprogramswhicheachmadeapassoverthesource(orsomerepresentationofit)performingsomeoftherequiredanalysisandtranslations.\nTheabilitytocompileinasinglepasshasclassicallybeenseenasabenefitbecauseitsimplifiesthejobofwritingacompilerandone-passcompilersgenerallyperformcompilationsfasterthanmulti-passcompilers.Thus,partlydrivenbytheresourcelimitationsofearlysystems,manyearlylanguageswerespecificallydesignedsothattheycouldbecompiledinasinglepass(e.g.,Pascal).\nInsomecasesthedesignofalanguagefeaturemayrequireacompilertoperformmorethanonepassoverthesource.Forinstance,consideradeclarationappearingonline20ofthesourcewhichaffectsthetranslationofastatementappearingonline10.Inthiscase,thefirstpassneedstogatherinformationaboutdeclarationsappearingafterstatementsthattheyaffect,withtheactualtranslationhappeningduringasubsequentpass.\nThedisadvantageofcompilinginasinglepassisthatitisnotpossibletoperformmanyofthesophisticatedoptimizationsneededtogeneratehighqualitycode.Itcanbedifficulttocountexactlyhowmanypassesanoptimizingcompilermakes.Forinstance,differentphasesofoptimizationmayanalyseoneexpressionmanytimesbutonlyanalyseanotherexpressiononce.\nSplittingacompilerupintosmallprogramsisatechniqueusedbyresearchersinterestedinproducingprovablycorrectcompilers.Provingthecorrectnessofasetofsmallprogramsoftenrequireslesseffortthanprovingthecorrectnessofalarger,single,equivalentprogram.\nRegardlessoftheexactnumberofphasesinthecompilerdesign,thephasescanbeassignedtooneofthreestages.Thestagesincludeafrontend,amiddleend,andabackend.\nThisfront/middle/back-endapproachmakesitpossibletocombinefrontendsfordifferentlanguageswithbackendsfordifferentCPUswhilesharingtheoptimizationsofthemiddleend.[38]PracticalexamplesofthisapproacharetheGNUCompilerCollection,LLVM,[39]andtheAmsterdamCompilerKit,whichhavemultiplefront-ends,sharedoptimizationsandmultipleback-ends.\nThefrontendanalyzesthesourcecodetobuildaninternalrepresentationoftheprogram,calledtheintermediaterepresentation(IR).Italsomanagesthesymboltable,adatastructuremappingeachsymbolinthesourcecodetoassociatedinformationsuchaslocation,typeandscope.\nWhilethefrontendcanbeasinglemonolithicfunctionorprogram,asinascannerlessparser,itismorecommonlyimplementedandanalyzedasseveralphases,whichmayexecutesequentiallyorconcurrently.Thismethodisfavoredduetoitsmodularityandseparationofconcerns.Mostcommonlytoday,thefrontendisbrokenintothreephases:lexicalanalysis(alsoknownaslexing),syntaxanalysis(alsoknownasscanningorparsing),andsemanticanalysis.Lexingandparsingcomprisethesyntacticanalysis(wordsyntaxandphrasesyntax,respectively),andinsimplecasesthesemodules(thelexerandparser)canbeautomaticallygeneratedfromagrammarforthelanguage,thoughinmorecomplexcasestheserequiremanualmodification.Thelexicalgrammarandphrasegrammarareusuallycontext-freegrammars,whichsimplifiesanalysissignificantly,withcontext-sensitivityhandledatthesemanticanalysisphase.Thesemanticanalysisphaseisgenerallymorecomplexandwrittenbyhand,butcanbepartiallyorfullyautomatedusingattributegrammars.Thesephasesthemselvescanbefurtherbrokendown:lexingasscanningandevaluating,andparsingasbuildingaconcretesyntaxtree(CST,parsetree)andthentransformingitintoanabstractsyntaxtree(AST,syntaxtree).Insomecasesadditionalphasesareused,notablylinereconstructionandpreprocessing,butthesearerare.\nThemainphasesofthefrontendincludethefollowing:\nThemiddleendperformsoptimizationsontheintermediaterepresentationinordertoimprovetheperformanceandthequalityoftheproducedmachinecode.[43]ThemiddleendcontainsthoseoptimizationsthatareindependentoftheCPUarchitecturebeingtargeted.\nThemainphasesofthemiddleendincludethefollowing:\nCompileranalysisistheprerequisiteforanycompileroptimization,andtheytightlyworktogether.Forexample,dependenceanalysisiscrucialforlooptransformation.\nThescopeofcompileranalysisandoptimizationsvarygreatly;theirscopemayrangefromoperatingwithinabasicblock,towholeprocedures,oreventhewholeprogram.Thereisatrade-offbetweenthegranularityoftheoptimizationsandthecostofcompilation.Forexample,peepholeoptimizationsarefasttoperformduringcompilationbutonlyaffectasmalllocalfragmentofthecode,andcanbeperformedindependentlyofthecontextinwhichthecodefragmentappears.Incontrast,interproceduraloptimizationrequiresmorecompilationtimeandmemoryspace,butenableoptimizationswhichareonlypossiblebyconsideringthebehaviorofmultiplefunctionssimultaneously.\nInterproceduralanalysisandoptimizationsarecommoninmoderncommercialcompilersfromHP,IBM,SGI,Intel,Microsoft,andSunMicrosystems.ThefreesoftwareGCCwascriticizedforalongtimeforlackingpowerfulinterproceduraloptimizations,butitischanginginthisrespect.AnotheropensourcecompilerwithfullanalysisandoptimizationinfrastructureisOpen64,whichisusedbymanyorganizationsforresearchandcommercialpurposes.\nDuetotheextratimeandspaceneededforcompileranalysisandoptimizations,somecompilersskipthembydefault.Usershavetousecompilationoptionstoexplicitlytellthecompilerwhichoptimizationsshouldbeenabled.\nThebackendisresponsiblefortheCPUarchitecturespecificoptimizationsandforcodegeneration.\nThemainphasesofthebackendincludethefollowing:\nCompilercorrectnessisthebranchofsoftwareengineeringthatdealswithtryingtoshowthatacompilerbehavesaccordingtoitslanguagespecification.[45][self-publishedsource?][non-primarysourceneeded]Techniquesincludedevelopingthecompilerusingformalmethodsandusingrigoroustesting(oftencalledcompilervalidation)onanexistingcompiler.\nHigher-levelprogramminglanguagesusuallyappearwithatypeoftranslationinmind:eitherdesignedascompiledlanguageorinterpretedlanguage.However,inpracticethereisrarelyanythingaboutalanguagethatrequiresittobeexclusivelycompiledorexclusivelyinterpreted,althoughitispossibletodesignlanguagesthatrelyonre-interpretationatruntime.Thecategorizationusuallyreflectsthemostpopularorwidespreadimplementationsofalanguage\xe2\x80\x94forinstance,BASICissometimescalledaninterpretedlanguage,andCacompiledone,despitetheexistenceofBASICcompilersandCinterpreters.\nInterpretationdoesnotreplacecompilationcompletely.Itonlyhidesitfromtheuserandmakesitgradual.Eventhoughaninterpretercanitselfbeinterpreted,adirectlyexecutedprogramisneededsomewhereatthebottomofthestack(seemachinelanguage).\nFurther,compilerscancontaininterpretersforoptimizationreasons.Forexample,whereanexpressioncanbeexecutedduringcompilationandtheresultsinsertedintotheoutputprogram,thenitpreventsithavingtoberecalculatedeachtimetheprogramruns,whichcangreatlyspeedupthefinalprogram.Moderntrendstowardjust-in-timecompilationandbytecodeinterpretationattimesblurthetraditionalcategorizationsofcompilersandinterpretersevenfurther.\nSomelanguagespecificationsspelloutthatimplementationsmustincludeacompilationfacility;forexample,CommonLisp.However,thereisnothinginherentinthedefinitionofCommonLispthatstopsitfrombeinginterpreted.Otherlanguageshavefeaturesthatareveryeasytoimplementinaninterpreter,butmakewritingacompilermuchharder;forexample,APL,SNOBOL4,andmanyscriptinglanguagesallowprogramstoconstructarbitrarysourcecodeatruntimewithregularstringoperations,andthenexecutethatcodebypassingittoaspecialevaluationfunction.Toimplementthesefeaturesinacompiledlanguage,programsmustusuallybeshippedwitharuntimelibrarythatincludesaversionofthecompileritself.\nOneclassificationofcompilersisbytheplatformonwhichtheirgeneratedcodeexecutes.Thisisknownasthetargetplatform.\nAnativeorhostedcompilerisonewhoseoutputisintendedtodirectlyrunonthesametypeofcomputerandoperatingsystemthatthecompileritselfrunson.Theoutputofacrosscompilerisdesignedtorunonadifferentplatform.Crosscompilersareoftenusedwhendevelopingsoftwareforembeddedsystemsthatarenotintendedtosupportasoftwaredevelopmentenvironment.\nTheoutputofacompilerthatproducescodeforavirtualmachine(VM)mayormaynotbeexecutedonthesameplatformasthecompilerthatproducedit.Forthisreasonsuchcompilersarenotusuallyclassifiedasnativeorcrosscompilers.\nThelowerlevellanguagethatisthetargetofacompilermayitselfbeahigh-levelprogramminglanguage.C,oftenviewedassomesortofportableassembler,canalsobethetargetlanguageofacompiler.E.g.:Cfront,theoriginalcompilerforC++usedCastargetlanguage.TheCcreatedbysuchacompilerisusuallynotintendedtobereadandmaintainedbyhumans.SoindentstyleandprettyCintermediatecodeareirrelevant.SomefeaturesofCturnitintoagoodtargetlanguage.E.g.:Ccodewith#linedirectivescanbegeneratedtosupportdebuggingoftheoriginalsource.\nWhileacommoncompilertypeoutputsmachinecode,therearemanyothertypes:\n