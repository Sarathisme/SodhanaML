Incomputing,hardwareaccelerationistheuseofcomputerhardwarespeciallymadetoperformsomefunctionsmoreefficientlythanispossibleinsoftwarerunningonageneral-purposeCPU.Anytransformationofdataorroutinethatcanbecomputed,canbecalculatedpurelyinsoftwarerunningonagenericCPU,purelyincustom-madehardware,orinsomemixofboth.Anoperationcanbecomputedfasterinapplication-specifichardwaredesignedorprogrammedtocomputetheoperationthanspecifiedinsoftwareandperformedonageneral-purposecomputerprocessor.Eachapproachhasadvantagesanddisadvantages.Theimplementationofcomputingtasksinhardwaretodecreaselatencyandincreasethroughputisknownashardwareacceleration.\nTypicaladvantagesofsoftwareincludemorerapiddevelopment(leadingtofastertimestomarket),lowernon-recurringengineeringcosts,heightenedportability,andeaseofupdatingfeaturesorpatchingbugs,atthecostofoverheadtocomputegeneraloperations.Advantagesofhardwareincludespeedup,reducedpowerconsumption,[1]lowerlatency,increasedparallelism[2]andbandwidth,andbetterutilizationofareaandfunctionalcomponentsavailableonanintegratedcircuit;atthecostoflowerabilitytoupdatedesignsonceetchedontosiliconandhighercostsoffunctionalverificationandtimestomarket.Inthehierarchyofdigitalcomputingsystemsrangingfromgeneral-purposeprocessorstofullycustomizedhardware,thereisatradeoffbetweenflexibilityandefficiency,withefficiencyincreasingbyordersofmagnitudewhenanygivenapplicationisimplementedhigherupthathierarchy.[3][4]Thishierarchyincludesgeneral-purposeprocessorssuchasCPUs,morespecializedprocessorssuchasGPUs,fixed-functionimplementedonfield-programmablegatearrays(FPGAs),andfixed-functionimplementedonapplication-specificintegratedcircuit(ASICs).\nHardwareaccelerationisadvantageousforperformance,andpracticalwhenthefunctionsarefixedsoupdatesarenotasneededasinsoftwaresolutions.WiththeadventofreprogrammablelogicdevicessuchasFPGAs,therestrictionofhardwareaccelerationtofullyfixedalgorithmshaseasedsince2010,allowinghardwareaccelerationtobeappliedtoproblemdomainsrequiringmodificationtoalgorithmsandprocessingcontrolflow.[5][6][7]\nIntegratedcircuitscanbecreatedtoperformarbitraryoperationsonanaloganddigitalsignals.Mostoftenincomputing,signalsaredigitalandcanbeinterpretedasbinarynumberdata.Computerhardwareandsoftwareoperateoninformationinbinaryrepresentationtoperformcomputing;thisisaccomplishedbycalculatingbooleanfunctionsonthebitsofinputandoutputtingtheresulttosomeoutputdevicedownstreamforstorageorfurtherprocessing.\nEithersoftwareorhardwarecancomputeanycomputablefunction.Customhardwareoffershigherperformanceperwattforthesamefunctionsthatcanbespecifiedinsoftware.Hardwaredescriptionlanguages(HDLs)suchasVerilogandVHDLcanmodelthesamesemanticsassoftwareandsynthesizethedesignintoanetlistthatcanbeprogrammedtoanFPGAorcomposedintologicgatesofanapplication-specificintegratedcircuit.\nThevastmajorityofsoftware-basedcomputingoccursonmachinesimplementingthevonNeumannarchitecture,collectivelyknownasstored-programcomputers.Computerprogramsarestoredasdataandexecutedbyprocessors,typicallyoneormoreCPUcores.Suchprocessorsmustfetchanddecodeinstructionsaswellasdataoperandsfrommemoryaspartoftheinstructioncycletoexecutetheinstructionsconstitutingthesoftwareprogram.RelyingonacommoncacheforcodeanddataleadstothevonNeumannbottleneck,afundamentallimitationonthethroughputofsoftwareonprocessorsimplementingthevonNeumannarchitecture.EveninthemodifiedHarvardarchitecture,whereinstructionsanddatahaveseparatecachesinthememoryhierarchy,thereisoverheadtodecodinginstructionopcodesandmultiplexingavailableexecutionunitsonamicroprocessorormicrocontroller,leadingtolowcircuitutilization.Intel\'shyper-threadingtechnologyprovidessimultaneousmultithreadingbyexploitingunder-utilizationofavailableprocessorfunctionalunitsandinstructionlevelparallelismbetweendifferenthardwarethreads.\nHardwareexecutionunitsdonotingeneralrelyonthevonNeumannormodifiedHarvardarchitecturesanddonotneedtoperformtheinstructionfetchanddecodestepsofaninstructioncycleandincurthosestages\'overhead.Ifneededcalculationsarespecifiedinaregistertransferlevelhardwaredesign,thetimeandcircuitareacoststhatwouldbeincurredbyinstructionfetchanddecodingstagescanbereclaimedandputtootheruses.\nThisreclamationsavestime,powerandcircuitareaincomputation.Thereclaimedresourcescanbeusedforincreasedparallelcomputation,otherfunctions,communicationormemory,aswellasincreasedinput/outputcapabilities.Thiscomesattheopportunitycostoflessgeneral-purposeutility.\nGreaterRTLcustomizationofhardwaredesignsallowsemergingarchitecturessuchasin-memorycomputing,transporttriggeredarchitectures(TTA)andnetworks-on-chip(NoC)tofurtherbenefitfromincreasedlocalityofdatatoexecutioncontext,therebyreducingcomputingandcommunicationlatencybetweenmodulesandfunctionalunits.\nCustomhardwareislimitedinparallelprocessingcapabilityonlybytheareaandlogicblocksavailableontheintegratedcircuitdie.[8]Therefore,hardwareismuchmorefreetooffermassiveparallelismthansoftwareongeneral-purposeprocessors,offeringapossibilityofimplementingtheparallelrandom-accessmachine(PRAM)model.\nItiscommontobuildmulticoreandmanycoreprocessingunitsoutofmicroprocessorIPcoreschematicsonasingleFPGAorASIC.[9][10][11][12][13]Similarly,specializedfunctionalunitscanbecomposedinparallelasindigitalsignalprocessingwithoutbeingembeddedinaprocessorIPcore.Therefore,hardwareaccelerationisoftenemployedforrepetitive,fixedtasksinvolvinglittleconditionalbranching,especiallyonlargeamountsofdata.ThisishowNvidia\'sCUDAlineofGPUsareimplemented.\nAsdevicemobilityhasincreased,therelativeperformanceofspecificaccelerationprotocolshasrequirednewmetricizations,consideringthecharacteristicssuchasphysicalhardwaredimensions,powerconsumptionandoperationsthroughput.Thesecanbesummarizedintothreecategories:taskefficiency,implementationefficiency,andflexibility.Appropriatemetricsconsidertheareaofthehardwarealongwithboththecorrespondingoperationsthroughputandenergyconsumed.[14]\n\nSupposewewishtocomputethesumof\n\n\n\n\n2\n\n20\n\n\n=\n1\n,\n048\n,\n576\n\n\n{\\displaystyle2^{20}=1,048,576}\n\nintegers.Assuminglargeintegersareavailableasbignumlargeenoughtoholdthesum,thiscanbedoneinsoftwarebyspecifying(here,inC++):Thisalgorithmrunsinlineartime,\n\n\n\n\n\nO\n\n\n\n(\nn\n)\n\n\n\n{\\textstyle{\\mathcal{O}}\\left(n\\right)}\n\ninBigOnotation.Inhardware,withsufficientareaonchip,calculationcanbeparallelizedtotakeonly20timestepsusingtheprefixsumalgorithm.[15]Thealgorithmrequiresonlylogarithmictime,\n\n\n\n\n\nO\n\n\n\n(\n\nlog\n‚Å°\n\nn\n\n\n)\n\n\n\n{\\textstyle{\\mathcal{O}}\\left(\\log{n}\\right)}\n\n,and\n\n\n\n\n\nO\n\n\n\n(\n1\n)\n\n\n\n{\\textstyle{\\mathcal{O}}\\left(1\\right)}\n\nspaceasanin-placealgorithm:Thisexampletakesadvantageofthegreaterparallelresourcesavailableinapplication-specifichardwarethanmostsoftwareandgeneral-purposecomputingparadigmsandarchitectures.\nHardwareaccelerationcanbeappliedtostreamprocessing.\nExamplesofhardwareaccelerationincludebitblitaccelerationfunctionalityingraphicsprocessingunits(GPUs),useofmemristorsforacceleratingneuralnetworks[16]andregularexpressionhardwareaccelerationforspamcontrolintheserverindustry,intendedtopreventregularexpressiondenialofservice(ReDoS)attacks.[17]Thehardwarethatperformstheaccelerationmaybepartofageneral-purposeCPU,oraseparateunit.Inthesecondcase,itisreferredtoasahardwareaccelerator,oroftenmorespecificallyasa3Daccelerator,cryptographicaccelerator,etc.\nTraditionally,processorsweresequential(instructionsareexecutedonebyone),andweredesignedtorungeneralpurposealgorithmscontrolledbyinstructionfetch(forexamplemovingtemporaryresultstoandfromaregisterfile).Hardwareacceleratorsimprovetheexecutionofaspecificalgorithmbyallowinggreaterconcurrency,havingspecificdatapathsfortheirtemporaryvariables,andreducingtheoverheadofinstructioncontrolinthefetch-decode-executecycle.\nModernprocessorsaremulti-coreandoftenfeatureparallel"single-instruction;multipledata"(SIMD)units.Evenso,hardwareaccelerationstillyieldsbenefits.Hardwareaccelerationissuitableforanycomputation-intensivealgorithmwhichisexecutedfrequentlyinataskorprogram.Dependinguponthegranularity,hardwareaccelerationcanvaryfromasmallfunctionalunit,toalargefunctionalblock(likemotionestimationinMPEG-2).\n