Automatedplanningandscheduling,sometimesdenotedassimplyAIPlanning,[1]isabranchofartificialintelligencethatconcernstherealizationofstrategiesoractionsequences,typicallyforexecutionbyintelligentagents,autonomousrobotsandunmannedvehicles.Unlikeclassicalcontrolandclassificationproblems,thesolutionsarecomplexandmustbediscoveredandoptimizedinmultidimensionalspace.Planningisalsorelatedtodecisiontheory.\nInknownenvironmentswithavailablemodels,planningcanbedoneoffline.Solutionscanbefoundandevaluatedpriortoexecution.Indynamicallyunknownenvironments,thestrategyoftenneedstoberevisedonline.Modelsandpoliciesmustbeadapted.Solutionsusuallyresorttoiterativetrialanderrorprocessescommonlyseeninartificialintelligence.Theseincludedynamicprogramming,reinforcementlearningandcombinatorialoptimization.Languagesusedtodescribeplanningandschedulingareoftencalledactionlanguages.\nGivenadescriptionofthepossibleinitialstatesoftheworld,adescriptionofthedesiredgoals,andadescriptionofasetofpossibleactions,theplanningproblemistosynthesiseaplanthatisguaranteed(whenappliedtoanyoftheinitialstates)togenerateastatewhichcontainsthedesiredgoals(suchastateiscalledagoalstate).\nThedifficultyofplanningisdependentonthesimplifyingassumptionsemployed.Severalclassesofplanningproblemscanbeidentifieddependingonthepropertiestheproblemshaveinseveraldimensions.\nThesimplestpossibleplanningproblem,knownastheClassicalPlanningProblem,isdeterminedby:\nSincetheinitialstateisknownunambiguously,andallactionsaredeterministic,thestateoftheworldafteranysequenceofactionscanbeaccuratelypredicted,andthequestionofobservabilityisirrelevantforclassicalplanning.\nFurther,planscanbedefinedassequencesofactions,becauseitisalwaysknowninadvancewhichactionswillbeneeded.\nWithnondeterministicactionsorothereventsoutsidethecontroloftheagent,thepossibleexecutionsformatree,andplanshavetodeterminetheappropriateactionsforeverynodeofthetree.\nDiscrete-timeMarkovdecisionprocesses(MDP)areplanningproblemswith:\nWhenfullobservabilityisreplacedbypartialobservability,planningcorrespondstopartiallyobservableMarkovdecisionprocess(POMDP).\nIftherearemorethanoneagent,wehavemulti-agentplanning,whichiscloselyrelatedtogametheory.\nInAIPlanning,plannerstypicallyinputadomainmodel(adescriptionofasetofpossibleactionswhichmodelthedomain)aswellasthespecificproblemtobesolvedspecifiedbytheinitialstateandgoal,incontrasttothoseinwhichthereisnoinputdomainspecified.Suchplannersarecalled"DomainIndependent"toemphasisthefactthattheycansolveplanningproblemsfromawiderangeofdomains.Typicalexamplesofdomainsareblockstacking,logistics,workflowmanagement,androbottaskplanning.Henceasingledomainindependentplannercanbeusedtosolveplanningproblemsinallthesevariousdomains.Ontheotherhand,arouteplanneristypicalofadomainspecificplanner.\nThemostcommonlyusedlanguagesforrepresentingplanningdomainsandspecificplanningproblems,suchasSTRIPSandPDDLforClassicalPlanning,arebasedonstatevariables.Eachpossiblestateoftheworldisanassignmentofvaluestothestatevariables,andactionsdeterminehowthevaluesofthestatevariableschangewhenthatactionistaken.Sinceasetofstatevariablesinduceastatespacethathasasizethatisexponentialintheset,planning,similarlytomanyothercomputationalproblems,suffersfromthecurseofdimensionalityandthecombinatorialexplosion.\nAnalternativelanguagefordescribingplanningproblemsisthatofhierarchicaltasknetworks,inwhichasetoftasksisgiven,andeachtaskcanbeeitherrealizedbyaprimitiveactionordecomposedintoasetofothertasks.Thisdoesnotnecessarilyinvolvestatevariables,althoughinmorerealisticapplicationsstatevariablessimplifythedescriptionoftasknetworks.\nTemporalplanningcanbesolvedwithmethodssimilartoclassicalplanning.Themaindifferenceis,becauseofthepossibilityofseveral,temporallyoverlappingactionswithadurationbeingtakenconcurrently,\nthatthedefinitionofastatehastoincludeinformationaboutthecurrentabsolutetimeandhowfartheexecutionofeachactiveactionhasproceeded.Further,inplanningwithrationalorrealtime,thestatespacemaybeinfinite,unlikeinclassicalplanningorplanningwithintegertime.Temporalplanningiscloselyrelatedtoschedulingproblems.\nTemporalplanningcanalsobeunderstoodintermsoftimedautomata.\nProbabilisticplanningcanbesolvedwithiterativemethodssuchasvalueiterationandpolicyiteration,whenthestatespaceissufficientlysmall.\nWithpartialobservability,probabilisticplanningissimilarlysolvedwithiterativemethods,butusingarepresentationofthevaluefunctionsdefinedforthespaceofbeliefsinsteadofstates.\nInpreference-basedplanning,theobjectiveisnotonlytoproduceaplanbutalsotosatisfyuser-specifiedpreferences.Adifferencetothemorecommonreward-basedplanning,forexamplecorrespondingtoMDPs,preferencesdon\'tnecessarilyhaveaprecisenumericalvalue.\nDeterministicplanningwasintroducedwiththeSTRIPSplanningsystem,whichisahierarchicalplanner.Actionnamesareorderedinasequenceandthisisaplanfortherobot.Hierarchicalplanningcanbecomparedwithanautomaticgeneratedbehaviortree.[2]Thedisadvantageis,thatanormalbehaviortreeisnotsoexpressivelikeacomputerprogram.Thatmeans,thenotationofabehaviorgraphcontainsactioncommands,butnoloopsorif-then-statements.Conditionalplanningovercomesthebottleneckandintroducesanelaboratednotationwhichissimilartoacontrolflow,knownfromotherprogramminglanguageslikePascal.Itisverysimilartoprogramsynthesis,thatmeansaplannergeneratessourcecodewhichcanbeexecutedbyaninterpreter.[3]\nAnearlyexampleofaconditionalplanneris\xe2\x80\x9cWarplan-C\xe2\x80\x9dwhichwasintroducedinthemid1970s.[4]Untilnow,thequestionwasnotansweredwhatthedifferenceisbetweenanormalsequenceandacomplicatedplan,whichcontainsif-then-statements.Ithastodowithuncertaintyatruntimeofaplan.Theideais,thataplancanreacttosensorsignalswhichareunknownfortheplanner.Theplannergeneratestwochoicesinadvance.Forexample,ifanobjectwasdetected,thenactionAisexecuted,ifanobjectismissing,thenactionBisexecuted.[5]Amajoradvantageofconditionalplanningistheabilitytohandlepartialplans.[6]Anagentisnotforcedtoplaneverythingfromstarttofinishbutcandividetheproblemintochunks.Thishelpstoreducethestatespaceandsolvesmuchmorecomplexproblems.\n